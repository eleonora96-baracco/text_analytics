{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8293d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f851c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df168f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.layers import Embedding \n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from keras.layers import LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3583b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f7bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6574e0",
   "metadata": {},
   "source": [
    "## Bags of words embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa99c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('train.csv',encoding ='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f952fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>lang_abv</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5130fd2cb5</td>\n",
       "      <td>and these comments were considered in formulat...</td>\n",
       "      <td>The rules developed in the interim were put to...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b72532a0b</td>\n",
       "      <td>These are issues that we wrestle with in pract...</td>\n",
       "      <td>Practice groups are not permitted to work on t...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5622f0c60b</td>\n",
       "      <td>you know they can't really defend themselves l...</td>\n",
       "      <td>They can't defend themselves because of their ...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fdcd1bd867</td>\n",
       "      <td>From Cockpit Country to St. Ann's Bay</td>\n",
       "      <td>From St. Ann's Bay to Cockpit Country.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7cfb3d272c</td>\n",
       "      <td>Look, it's your skin, but you're going to be i...</td>\n",
       "      <td>The boss will fire you if he sees you slacking...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>2b78e2a914</td>\n",
       "      <td>The results of even the most well designed epi...</td>\n",
       "      <td>All studies have the same amount of uncertaint...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>7e9943d152</td>\n",
       "      <td>But there are two kinds of  the pleasure of do...</td>\n",
       "      <td>But there are two kinds of the pleasure of doi...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>5085923e6c</td>\n",
       "      <td>The important thing is to realize that it's wa...</td>\n",
       "      <td>It cannot be moved, now or ever.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>fc8e2fd1fe</td>\n",
       "      <td>At the west end is a detailed model of the who...</td>\n",
       "      <td>The model temple complex is at the east end.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>44301dfb14</td>\n",
       "      <td>For himself he chose Atat??rk, or Father of th...</td>\n",
       "      <td>Ataturk was the father of the Turkish nation.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6870 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                            premise  \\\n",
       "0      5130fd2cb5  and these comments were considered in formulat...   \n",
       "1      5b72532a0b  These are issues that we wrestle with in pract...   \n",
       "3      5622f0c60b  you know they can't really defend themselves l...   \n",
       "7      fdcd1bd867              From Cockpit Country to St. Ann's Bay   \n",
       "8      7cfb3d272c  Look, it's your skin, but you're going to be i...   \n",
       "...           ...                                                ...   \n",
       "12115  2b78e2a914  The results of even the most well designed epi...   \n",
       "12116  7e9943d152  But there are two kinds of  the pleasure of do...   \n",
       "12117  5085923e6c  The important thing is to realize that it's wa...   \n",
       "12118  fc8e2fd1fe  At the west end is a detailed model of the who...   \n",
       "12119  44301dfb14  For himself he chose Atat??rk, or Father of th...   \n",
       "\n",
       "                                              hypothesis lang_abv language  \\\n",
       "0      The rules developed in the interim were put to...       en  English   \n",
       "1      Practice groups are not permitted to work on t...       en  English   \n",
       "3      They can't defend themselves because of their ...       en  English   \n",
       "7                 From St. Ann's Bay to Cockpit Country.       en  English   \n",
       "8      The boss will fire you if he sees you slacking...       en  English   \n",
       "...                                                  ...      ...      ...   \n",
       "12115  All studies have the same amount of uncertaint...       en  English   \n",
       "12116  But there are two kinds of the pleasure of doi...       en  English   \n",
       "12117                   It cannot be moved, now or ever.       en  English   \n",
       "12118       The model temple complex is at the east end.       en  English   \n",
       "12119      Ataturk was the father of the Turkish nation.       en  English   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          2  \n",
       "3          0  \n",
       "7          2  \n",
       "8          1  \n",
       "...      ...  \n",
       "12115      2  \n",
       "12116      0  \n",
       "12117      2  \n",
       "12118      2  \n",
       "12119      0  \n",
       "\n",
       "[6870 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# english data set\n",
    "df_en = dt.loc[dt['lang_abv'] == 'en']\n",
    "df_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "617d3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#english x\n",
    "x = df_en.premise.values +' '+ df_en.hypothesis.values\n",
    "#english y \n",
    "y = df_en.label.values\n",
    "# split train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f93e654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd1a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok = [word_tokenize(sentence) for sentence in x_train]\n",
    "X_train_tok = [[word.lower() for word in s]for s in X_train_tok]\n",
    "X_train_tok = [[word for word in s if word.isalpha()]for s in X_train_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd0209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for l in X_train_tok:\n",
    "    for i in l:\n",
    "        text.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37cebe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = set(text)\n",
    "text1 =list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67c3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constants.\n",
    "max_features = len(text1)+2\n",
    "embedding_dim = 128\n",
    "sequence_length = 100\n",
    "\n",
    "\n",
    "def custom_slpit(input_data):\n",
    "    return tf.strings.split(input_data)\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    vocabulary = text1,\n",
    "    output_mode=\"int\",\n",
    "    ngrams = None,\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "#vectorize_layer.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "889f7a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'high',\n",
       " 'slaughtering',\n",
       " 'failings',\n",
       " 'cry',\n",
       " 'esb',\n",
       " 'winning',\n",
       " 'fooling',\n",
       " 'near',\n",
       " 'cockpit',\n",
       " 'cesare',\n",
       " 'bur',\n",
       " 'hondo',\n",
       " 'reviews',\n",
       " 'aswan',\n",
       " 'alsacien',\n",
       " 'ebb',\n",
       " 'tarpley',\n",
       " 'conversation',\n",
       " 'winter',\n",
       " 'greuze',\n",
       " 'sikhs',\n",
       " 'letting',\n",
       " 'wrongly',\n",
       " 'salads',\n",
       " 'appetite',\n",
       " 'newshour',\n",
       " 'sons',\n",
       " 'learning',\n",
       " 'resigned',\n",
       " 'dislocation',\n",
       " 'barton',\n",
       " 'live',\n",
       " 'equate',\n",
       " 'prancing',\n",
       " 'charges',\n",
       " 'rapid',\n",
       " 'bradley',\n",
       " 'diego',\n",
       " 'molokai',\n",
       " 'welcomed',\n",
       " 'chicken',\n",
       " 'gracious',\n",
       " 'ranging',\n",
       " 'dejima',\n",
       " 'scary',\n",
       " 'records',\n",
       " 'pondering',\n",
       " 'someday',\n",
       " 'thrill',\n",
       " 'handed',\n",
       " 'allow',\n",
       " 'neighboring',\n",
       " 'string',\n",
       " 'electrical',\n",
       " 'people',\n",
       " 'analytical',\n",
       " 'artistic',\n",
       " 'john',\n",
       " 'confront',\n",
       " 'or',\n",
       " 'admits',\n",
       " 'instincts',\n",
       " 'sailing',\n",
       " 'providers',\n",
       " 'dali',\n",
       " 'nations',\n",
       " 'bowed',\n",
       " 'gazing',\n",
       " 'roman',\n",
       " 'blend',\n",
       " 'mailers',\n",
       " 'domination',\n",
       " 'miss',\n",
       " 'ocean',\n",
       " 'unavailability',\n",
       " 'tuileries',\n",
       " 'complaints',\n",
       " 'mailbox',\n",
       " 'conditioning',\n",
       " 'uphold',\n",
       " 'equal',\n",
       " 'video',\n",
       " 'gallery',\n",
       " 'bangers',\n",
       " 'washing',\n",
       " 'gases',\n",
       " 'nation',\n",
       " 'traded',\n",
       " 'subscribers',\n",
       " 'defense',\n",
       " 'peculiar',\n",
       " 'handwriting',\n",
       " 'successfully',\n",
       " 'wave',\n",
       " 'nervous',\n",
       " 'thereon',\n",
       " 'brookes',\n",
       " 'rao',\n",
       " 'generalized',\n",
       " 'declared',\n",
       " 'catching',\n",
       " 'archives',\n",
       " 'methodology',\n",
       " 'stabilize',\n",
       " 'tse',\n",
       " 'censure',\n",
       " 'awry',\n",
       " 'characteristics',\n",
       " 'ugly',\n",
       " 'used',\n",
       " 'defendants',\n",
       " 'song',\n",
       " 'diametrically',\n",
       " 'kaufman',\n",
       " 'minor',\n",
       " 'largest',\n",
       " 'blood',\n",
       " 'diamond',\n",
       " 'ford',\n",
       " 'hitting',\n",
       " 'sue',\n",
       " 'envelope',\n",
       " 'formentor',\n",
       " 'import',\n",
       " 'create',\n",
       " 'knox',\n",
       " 'dick',\n",
       " 'victoria',\n",
       " 'heroic',\n",
       " 'landing',\n",
       " 'cuban',\n",
       " 'inefficient',\n",
       " 'witches',\n",
       " 'supremacy',\n",
       " 'inventors',\n",
       " 'parental',\n",
       " 'hcfa',\n",
       " 'hud',\n",
       " 'ordered',\n",
       " 'carnelian',\n",
       " 'nyc',\n",
       " 'sainte',\n",
       " 'citations',\n",
       " 'handling',\n",
       " 'gratitude',\n",
       " 'stuck',\n",
       " 'ii',\n",
       " 'fgd',\n",
       " 'kebabs',\n",
       " 'geico',\n",
       " 'showed',\n",
       " 'era',\n",
       " 'allies',\n",
       " 'visiting',\n",
       " 'pitre',\n",
       " 'representing',\n",
       " 'diamonds',\n",
       " 'imply',\n",
       " 'expand',\n",
       " 'sinatra',\n",
       " 'variegated',\n",
       " 'faces',\n",
       " 'plunged',\n",
       " 'what',\n",
       " 'lawmakers',\n",
       " 'addictive',\n",
       " 'factors',\n",
       " 'malfunction',\n",
       " 'bled',\n",
       " 'picky',\n",
       " 'older',\n",
       " 'trouble',\n",
       " 'securing',\n",
       " 'brighter',\n",
       " 'kosovo',\n",
       " 'servant',\n",
       " 'elderly',\n",
       " 'confused',\n",
       " 'terms',\n",
       " 'secure',\n",
       " 'aides',\n",
       " 'pleasantly',\n",
       " 'dependency',\n",
       " 'forcing',\n",
       " 'saint',\n",
       " 'bothering',\n",
       " 'gras',\n",
       " 'politically',\n",
       " 'canadian',\n",
       " 'louis',\n",
       " 'subjects',\n",
       " 'agent',\n",
       " 'suspension',\n",
       " 'holyrood',\n",
       " 'intermittently',\n",
       " 'indulge',\n",
       " 'water',\n",
       " 'look',\n",
       " 'surprisingly',\n",
       " 'sorts',\n",
       " 'salesladies',\n",
       " 'patents',\n",
       " 'whoever',\n",
       " 'scolds',\n",
       " 'granada',\n",
       " 'departure',\n",
       " 'crooks',\n",
       " 'evidence',\n",
       " 'allocated',\n",
       " 'knowing',\n",
       " 'criminals',\n",
       " 'gautama',\n",
       " 'menorca',\n",
       " 'mari',\n",
       " 'drowning',\n",
       " 'adaptation',\n",
       " 'handy',\n",
       " 'burst',\n",
       " 'dating',\n",
       " 'hear',\n",
       " 'caucasian',\n",
       " 'fee',\n",
       " 'sovereign',\n",
       " 'ramses',\n",
       " 'february',\n",
       " 'boosting',\n",
       " 'household',\n",
       " 'assumptions',\n",
       " 'test',\n",
       " 'courthouse',\n",
       " 'chennai',\n",
       " 'vehicle',\n",
       " 'rivoli',\n",
       " 'worries',\n",
       " 'pistol',\n",
       " 'reject',\n",
       " 'nodded',\n",
       " 'rallies',\n",
       " 'condition',\n",
       " 'pour',\n",
       " 'purchaser',\n",
       " 'supreme',\n",
       " 'typical',\n",
       " 'filled',\n",
       " 'county',\n",
       " 'claimed',\n",
       " 'determination',\n",
       " 'band',\n",
       " 'tournament',\n",
       " 'belonged',\n",
       " 'envy',\n",
       " 'camped',\n",
       " 'compellingly',\n",
       " 'massacre',\n",
       " 'movies',\n",
       " 'surrounded',\n",
       " 'coloured',\n",
       " 'modern',\n",
       " 'stimulated',\n",
       " 'crose',\n",
       " 'mobility',\n",
       " 'large',\n",
       " 'propelled',\n",
       " 'lit',\n",
       " 'baltimore',\n",
       " 'subside',\n",
       " 'coalition',\n",
       " 'microhockey',\n",
       " 'comparison',\n",
       " 'amnesty',\n",
       " 'heyday',\n",
       " 'selected',\n",
       " 'generic',\n",
       " 'outputs',\n",
       " 'volley',\n",
       " 'bathrooms',\n",
       " 'bits',\n",
       " 'speed',\n",
       " 'mcdonald',\n",
       " 'matching',\n",
       " 'stephanopoulos',\n",
       " 'craft',\n",
       " 'cheerfully',\n",
       " 'explored',\n",
       " 'charming',\n",
       " 'stranded',\n",
       " 'toxicity',\n",
       " 'volunteer',\n",
       " 'unlikely',\n",
       " 'buddhism',\n",
       " 'repudiated',\n",
       " 'holland',\n",
       " 'perfect',\n",
       " 'ricky',\n",
       " 'angeles',\n",
       " 'bay',\n",
       " 'manufacturers',\n",
       " 'occasional',\n",
       " 'porch',\n",
       " 'scores',\n",
       " 'san',\n",
       " 'available',\n",
       " 'tales',\n",
       " 'graceful',\n",
       " 'doubts',\n",
       " 'bus',\n",
       " 'produced',\n",
       " 'santa',\n",
       " 'marching',\n",
       " 'bien',\n",
       " 'variety',\n",
       " 'sat',\n",
       " 'issue',\n",
       " 'punta',\n",
       " 'symphony',\n",
       " 'agree',\n",
       " 'equity',\n",
       " 'enlightened',\n",
       " 'severe',\n",
       " 'valid',\n",
       " 'converting',\n",
       " 'domain',\n",
       " 'shuddered',\n",
       " 'j',\n",
       " 'swine',\n",
       " 'dodged',\n",
       " 'affords',\n",
       " 'tailored',\n",
       " 'dichotomy',\n",
       " 'defending',\n",
       " 'relegated',\n",
       " 'cardiac',\n",
       " 'acreage',\n",
       " 'undertaken',\n",
       " 'equation',\n",
       " 'parkland',\n",
       " 'rockefeller',\n",
       " 'raucous',\n",
       " 'address',\n",
       " 'smelledof',\n",
       " 'felipe',\n",
       " 'tireless',\n",
       " 'maharashtra',\n",
       " 'inspiration',\n",
       " 'flat',\n",
       " 'taiping',\n",
       " 'flavor',\n",
       " 'realized',\n",
       " 'pelee',\n",
       " 'capital',\n",
       " 'vietnam',\n",
       " 'parachute',\n",
       " 'expertise',\n",
       " 'enduring',\n",
       " 'wrote',\n",
       " 'distributors',\n",
       " 'apse',\n",
       " 'christ',\n",
       " 'auto',\n",
       " 'seventeen',\n",
       " 'rocs',\n",
       " 'jann',\n",
       " 'stroll',\n",
       " 'imports',\n",
       " 'umbrella',\n",
       " 'stunning',\n",
       " 'thick',\n",
       " 'restaurants',\n",
       " 'poisoned',\n",
       " 'pigs',\n",
       " 'bounty',\n",
       " 'shave',\n",
       " 'thankful',\n",
       " 'italians',\n",
       " 'luxor',\n",
       " 'carmo',\n",
       " 'spite',\n",
       " 'personification',\n",
       " 'liqueur',\n",
       " 'adjusting',\n",
       " 'additions',\n",
       " 'trace',\n",
       " 'escort',\n",
       " 'organization',\n",
       " 'bournemouth',\n",
       " 'passes',\n",
       " 'shown',\n",
       " 'lotion',\n",
       " 'zombie',\n",
       " 'privacy',\n",
       " 'scutari',\n",
       " 'clarence',\n",
       " 'outnumber',\n",
       " 'explaining',\n",
       " 'mattered',\n",
       " 'william',\n",
       " 'argue',\n",
       " 'galax',\n",
       " 'replacement',\n",
       " 'photographed',\n",
       " 'lewinsky',\n",
       " 'bases',\n",
       " 'strides',\n",
       " 'celebrity',\n",
       " 'e',\n",
       " 'kalinga',\n",
       " 'admitted',\n",
       " 'uninteresting',\n",
       " 'regimens',\n",
       " 'tinted',\n",
       " 'briefly',\n",
       " 'abstains',\n",
       " 'husbands',\n",
       " 'seeking',\n",
       " 'nasire',\n",
       " 'refers',\n",
       " 'managed',\n",
       " 'declined',\n",
       " 'usual',\n",
       " 'bahadur',\n",
       " 'laborde',\n",
       " 'poked',\n",
       " 'fresh',\n",
       " 'palm',\n",
       " 'studio',\n",
       " 'enrolls',\n",
       " 'facets',\n",
       " 'elections',\n",
       " 'month',\n",
       " 'art',\n",
       " 'opportunities',\n",
       " 'chairmen',\n",
       " 'six',\n",
       " 'mask',\n",
       " 'searching',\n",
       " 'hang',\n",
       " 'saltwater',\n",
       " 'informational',\n",
       " 'legged',\n",
       " 'aid',\n",
       " 'shultz',\n",
       " 'midnight',\n",
       " 'outweigh',\n",
       " 'mark',\n",
       " 'offenders',\n",
       " 'newcomers',\n",
       " 'wayang',\n",
       " 'ambient',\n",
       " 'fannie',\n",
       " 'designer',\n",
       " 'impressed',\n",
       " 'importer',\n",
       " 'cheapest',\n",
       " 'behavior',\n",
       " 'prescription',\n",
       " 'canada',\n",
       " 'trading',\n",
       " 'reporter',\n",
       " 'james',\n",
       " 'kkk',\n",
       " 'alternative',\n",
       " 'each',\n",
       " 'civic',\n",
       " 'utilizing',\n",
       " 'sweetly',\n",
       " 'fec',\n",
       " 'philadelphia',\n",
       " 'cool',\n",
       " 'commercial',\n",
       " 'hazard',\n",
       " 'terminus',\n",
       " 'lodi',\n",
       " 'technical',\n",
       " 'windows',\n",
       " 'monastery',\n",
       " 'god',\n",
       " 'pointed',\n",
       " 'therein',\n",
       " 'barely',\n",
       " 'shuttered',\n",
       " 'baptists',\n",
       " 'liberals',\n",
       " 'room',\n",
       " 'outbreak',\n",
       " 'conglomerates',\n",
       " 'monks',\n",
       " 'mill',\n",
       " 'photo',\n",
       " 'experiencing',\n",
       " 'famed',\n",
       " 'remission',\n",
       " 'che',\n",
       " 'proving',\n",
       " 'forbidding',\n",
       " 'changed',\n",
       " 'soaker',\n",
       " 'trips',\n",
       " 'tack',\n",
       " 'pokemon',\n",
       " 'rowlett',\n",
       " 'allenby',\n",
       " 'solved',\n",
       " 'voluntarily',\n",
       " 'dressing',\n",
       " 'cheesecake',\n",
       " 'depicts',\n",
       " 'ingoing',\n",
       " 'turks',\n",
       " 'shock',\n",
       " 'channel',\n",
       " 'hand',\n",
       " 'cios',\n",
       " 'mover',\n",
       " 'charity',\n",
       " 'investment',\n",
       " 'welcome',\n",
       " 'formlessness',\n",
       " 'periodically',\n",
       " 'clerk',\n",
       " 'height',\n",
       " 'proceed',\n",
       " 'compatible',\n",
       " 'perilously',\n",
       " 'eupalinos',\n",
       " 'czarek',\n",
       " 'implies',\n",
       " 'sitting',\n",
       " 'prosecutor',\n",
       " 'consumer',\n",
       " 'cares',\n",
       " 'version',\n",
       " 'talented',\n",
       " 'compressable',\n",
       " 'deity',\n",
       " 'humans',\n",
       " 'itself',\n",
       " 'average',\n",
       " 'chloroform',\n",
       " 'nothing',\n",
       " 'diplomacy',\n",
       " 'retroactive',\n",
       " 'ultimate',\n",
       " 'farouk',\n",
       " 'compensate',\n",
       " 'racing',\n",
       " 'shutterbugs',\n",
       " 'narrow',\n",
       " 'volunteers',\n",
       " 'coastal',\n",
       " 'differently',\n",
       " 'projection',\n",
       " 'observers',\n",
       " 'tenfold',\n",
       " 'mediocre',\n",
       " 'repaired',\n",
       " 'bid',\n",
       " 'gpra',\n",
       " 'variegatus',\n",
       " 'huguenot',\n",
       " 'extravagant',\n",
       " 'area',\n",
       " 'watermelon',\n",
       " 'welt',\n",
       " 'pontoon',\n",
       " 'dana',\n",
       " 'default',\n",
       " 'changes',\n",
       " 'subsidies',\n",
       " 'envious',\n",
       " 'reversal',\n",
       " 'submit',\n",
       " 'dangerous',\n",
       " 'keen',\n",
       " 'advertising',\n",
       " 'meantime',\n",
       " 'revolver',\n",
       " 'shuttering',\n",
       " 'bears',\n",
       " 'overtly',\n",
       " 'emeralds',\n",
       " 'bedesten',\n",
       " 'tigers',\n",
       " 'persian',\n",
       " 'and',\n",
       " 'card',\n",
       " 'cucci',\n",
       " 'fool',\n",
       " 'telling',\n",
       " 'dublin',\n",
       " 'journal',\n",
       " 'spices',\n",
       " 'chase',\n",
       " 'ferocious',\n",
       " 'propose',\n",
       " 'wright',\n",
       " 'picked',\n",
       " 'enlisted',\n",
       " 'mae',\n",
       " 'hannibal',\n",
       " 'bhansi',\n",
       " 'unsafe',\n",
       " 'spanish',\n",
       " 'hippodrome',\n",
       " 'association',\n",
       " 'manoa',\n",
       " 'convene',\n",
       " 'submitted',\n",
       " 'autopilot',\n",
       " 'pans',\n",
       " 'sooner',\n",
       " 'charmers',\n",
       " 'vibrant',\n",
       " 'nist',\n",
       " 'welsh',\n",
       " 'suggest',\n",
       " 'tool',\n",
       " 'laughed',\n",
       " 'azaleas',\n",
       " 'dozen',\n",
       " 'flesh',\n",
       " 'winners',\n",
       " 'recline',\n",
       " 'assumption',\n",
       " 'demonstrations',\n",
       " 'rubbed',\n",
       " 'ideas',\n",
       " 'procured',\n",
       " 'governor',\n",
       " 'mines',\n",
       " 'pollster',\n",
       " 'armbands',\n",
       " 'streamlined',\n",
       " 'worrying',\n",
       " 'nurse',\n",
       " 'injured',\n",
       " 'sadistic',\n",
       " 'theory',\n",
       " 'phrase',\n",
       " 'encouraged',\n",
       " 'appropriated',\n",
       " 'twenties',\n",
       " 'armada',\n",
       " 'napoleon',\n",
       " 'needs',\n",
       " 'luisa',\n",
       " 'thira',\n",
       " 'childless',\n",
       " 'once',\n",
       " 'tegh',\n",
       " 'misdemeanor',\n",
       " 'force',\n",
       " 'considering',\n",
       " 'opposition',\n",
       " 'lunch',\n",
       " 'carroll',\n",
       " 'rip',\n",
       " 'horror',\n",
       " 'husband',\n",
       " 'la',\n",
       " 'sta',\n",
       " 'sustained',\n",
       " 'developed',\n",
       " 'west',\n",
       " 'responsable',\n",
       " 'crevices',\n",
       " 'reductions',\n",
       " 'experiments',\n",
       " 'complaint',\n",
       " 'perpetual',\n",
       " 'wanting',\n",
       " 'islands',\n",
       " 'usps',\n",
       " 'galilean',\n",
       " 'having',\n",
       " 'during',\n",
       " 'boots',\n",
       " 'troupe',\n",
       " 'candle',\n",
       " 'managers',\n",
       " 'combat',\n",
       " 'else',\n",
       " 'modem',\n",
       " 'availability',\n",
       " 'jets',\n",
       " 'eligible',\n",
       " 'bertrand',\n",
       " 'interpenetrating',\n",
       " 'stroke',\n",
       " 'rationalized',\n",
       " 'clubs',\n",
       " 'automatically',\n",
       " 'income',\n",
       " 'parts',\n",
       " 'selimiye',\n",
       " 'sides',\n",
       " 'front',\n",
       " 'repent',\n",
       " 'secrets',\n",
       " 'other',\n",
       " 'reading',\n",
       " 'taken',\n",
       " 'merry',\n",
       " 'streams',\n",
       " 'legs',\n",
       " 'collectibles',\n",
       " 'announcing',\n",
       " 'received',\n",
       " 'bringing',\n",
       " 'delicacy',\n",
       " 'mumbai',\n",
       " 'reserves',\n",
       " 'blame',\n",
       " 'tadminster',\n",
       " 'palestrina',\n",
       " 'methodologies',\n",
       " 'yellow',\n",
       " 'sabina',\n",
       " 'hastings',\n",
       " 'taj',\n",
       " 'canals',\n",
       " 'wyoming',\n",
       " 'jagged',\n",
       " 'basically',\n",
       " 'constitute',\n",
       " 'pertaining',\n",
       " 'whilst',\n",
       " 'shaved',\n",
       " 'texan',\n",
       " 'dominant',\n",
       " 'rapidly',\n",
       " 'units',\n",
       " 'decadent',\n",
       " 'los',\n",
       " 'kid',\n",
       " 'undefended',\n",
       " 'newhoff',\n",
       " 'contradict',\n",
       " 'gobind',\n",
       " 'legal',\n",
       " 'collect',\n",
       " 'funding',\n",
       " 'alert',\n",
       " 'goddess',\n",
       " 'drop',\n",
       " 'intel',\n",
       " 'tragedy',\n",
       " 'hurriya',\n",
       " 'supported',\n",
       " 'fond',\n",
       " 'econometric',\n",
       " 'proportion',\n",
       " 'dirty',\n",
       " 'responsibilities',\n",
       " 'textile',\n",
       " 'gang',\n",
       " 'tomatoes',\n",
       " 'consist',\n",
       " 'epicentres',\n",
       " 'details',\n",
       " 'advocating',\n",
       " 'referendums',\n",
       " 'good',\n",
       " 'economically',\n",
       " 'orchestra',\n",
       " 'chatterbox',\n",
       " 'liggett',\n",
       " 'dolomites',\n",
       " 'joy',\n",
       " 'wealth',\n",
       " 'showroom',\n",
       " 'misconduct',\n",
       " 'verge',\n",
       " 'perfectly',\n",
       " 'acclamation',\n",
       " 'attendance',\n",
       " 'premiums',\n",
       " 'abundance',\n",
       " 'page',\n",
       " 'succeed',\n",
       " 'situated',\n",
       " 'staffing',\n",
       " 'lasted',\n",
       " 'mare',\n",
       " 'wgn',\n",
       " 'was',\n",
       " 'lectures',\n",
       " 'role',\n",
       " 'selangor',\n",
       " 'indignantly',\n",
       " 'grams',\n",
       " 'competitors',\n",
       " 'scavengers',\n",
       " 'harshly',\n",
       " 'ready',\n",
       " 'falls',\n",
       " 'venerated',\n",
       " 'flapping',\n",
       " 'home',\n",
       " 'bankers',\n",
       " 'cleaning',\n",
       " 'capita',\n",
       " 'scripture',\n",
       " 'all',\n",
       " 'doing',\n",
       " 'interpretation',\n",
       " 'dear',\n",
       " 'agreement',\n",
       " 'two',\n",
       " 'candidates',\n",
       " 'tinos',\n",
       " 'hoi',\n",
       " 'emperors',\n",
       " 'handing',\n",
       " 'outlawing',\n",
       " 'dealt',\n",
       " 'chain',\n",
       " 'consequences',\n",
       " 'oak',\n",
       " 'sped',\n",
       " 'preparation',\n",
       " 'rafting',\n",
       " 'presenting',\n",
       " 'vary',\n",
       " 'farmer',\n",
       " 'entirely',\n",
       " 'tighter',\n",
       " 'strain',\n",
       " 'procedures',\n",
       " 'conform',\n",
       " 'bundle',\n",
       " 'clinicians',\n",
       " 'realization',\n",
       " 'formed',\n",
       " 'theaters',\n",
       " 'indicted',\n",
       " 'inadvertently',\n",
       " 'relates',\n",
       " 'questioning',\n",
       " 'these',\n",
       " 'shivered',\n",
       " 'strips',\n",
       " 'arch',\n",
       " 'muckraking',\n",
       " 'rainy',\n",
       " 'delicious',\n",
       " 'criticism',\n",
       " 'manchester',\n",
       " 'filters',\n",
       " 'voters',\n",
       " 'prison',\n",
       " 'affirm',\n",
       " 'whites',\n",
       " 'route',\n",
       " 'principle',\n",
       " 'bounds',\n",
       " 'crawling',\n",
       " 'moniz',\n",
       " 'crashed',\n",
       " 'translated',\n",
       " 'flatter',\n",
       " 'contrast',\n",
       " 'loyalty',\n",
       " 'miniseries',\n",
       " 'demolish',\n",
       " 'gallup',\n",
       " 'performers',\n",
       " 'wheat',\n",
       " 'corporate',\n",
       " 'perestrelo',\n",
       " 'veneto',\n",
       " 'fitted',\n",
       " 'conflicts',\n",
       " 'nose',\n",
       " 'results',\n",
       " 'laced',\n",
       " 'referencing',\n",
       " 'whiskey',\n",
       " 'hawaiian',\n",
       " 'sprout',\n",
       " 'context',\n",
       " 'publique',\n",
       " 'oval',\n",
       " 'atop',\n",
       " 'conservative',\n",
       " 'starvation',\n",
       " 'unanimous',\n",
       " 'layman',\n",
       " 'senders',\n",
       " 'furnished',\n",
       " 'opens',\n",
       " 'rock',\n",
       " 'everyone',\n",
       " 'magical',\n",
       " 'morgan',\n",
       " 'villages',\n",
       " 'versace',\n",
       " 'economic',\n",
       " 'mower',\n",
       " 'evaluated',\n",
       " 'chrysolite',\n",
       " 'requesters',\n",
       " 'companies',\n",
       " 'swimming',\n",
       " 'himalayas',\n",
       " 'absalom',\n",
       " 'kale',\n",
       " 'heart',\n",
       " 'creature',\n",
       " 'retired',\n",
       " 'piercing',\n",
       " 'flipper',\n",
       " 'vosges',\n",
       " 'highway',\n",
       " 'calculable',\n",
       " 'exercise',\n",
       " 'del',\n",
       " 'kemal',\n",
       " 'appreciated',\n",
       " 'neglected',\n",
       " 'karl',\n",
       " 'restaurant',\n",
       " 'luxurious',\n",
       " 'mechanical',\n",
       " 'vacationed',\n",
       " 'children',\n",
       " 'coroner',\n",
       " 'doesnt',\n",
       " 'whistling',\n",
       " 'statute',\n",
       " 'heroin',\n",
       " 'loft',\n",
       " 'zoning',\n",
       " 'won',\n",
       " 'testify',\n",
       " 'crusaders',\n",
       " 'grove',\n",
       " 'merchants',\n",
       " 'redeeming',\n",
       " 'website',\n",
       " 'columbia',\n",
       " 'mar',\n",
       " 'unaffected',\n",
       " 'tiberias',\n",
       " 'sim',\n",
       " 'instruction',\n",
       " 'bait',\n",
       " 'hurtled',\n",
       " 'punishment',\n",
       " 'adamant',\n",
       " 'nine',\n",
       " 'bars',\n",
       " 'officials',\n",
       " 'thompson',\n",
       " 'algebra',\n",
       " 'callers',\n",
       " 'brought',\n",
       " 'bat',\n",
       " 'fairly',\n",
       " 'planning',\n",
       " 'risks',\n",
       " 'deranged',\n",
       " 'bucks',\n",
       " 'hotter',\n",
       " 'morality',\n",
       " 'fair',\n",
       " 'francis',\n",
       " 'wished',\n",
       " 'shopping',\n",
       " 'madrid',\n",
       " 'tran',\n",
       " 'libert',\n",
       " 'patronized',\n",
       " 'tested',\n",
       " 'fill',\n",
       " 'asking',\n",
       " 'omb',\n",
       " 'expanding',\n",
       " 'alluded',\n",
       " 'political',\n",
       " 'retailers',\n",
       " 'dona',\n",
       " 'cassis',\n",
       " 'kendal',\n",
       " 'shockingly',\n",
       " 'yours',\n",
       " 'erotica',\n",
       " 'drives',\n",
       " 'busily',\n",
       " 'shoot',\n",
       " 'naples',\n",
       " 'cared',\n",
       " 'nefarious',\n",
       " 'rhetoric',\n",
       " 'expenditures',\n",
       " 'insects',\n",
       " 'eviction',\n",
       " 'mangrove',\n",
       " 'tracy',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "67a9a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorize_layer(x_train)\n",
    "X_test = vectorize_layer(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de038c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4809, 100), dtype=int64, numpy=\n",
       "array([[ 7984,  3153,  6349, ...,     0,     0,     0],\n",
       "       [ 8477,  6907, 10470, ...,     0,     0,     0],\n",
       "       [    1,  7683,  6883, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [    1,  4948,  1913, ...,     0,     0,     0],\n",
       "       [ 4948, 10470,  6349, ...,     0,     0,     0],\n",
       "       [ 8400,  8305,   786, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb44f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to OHE \n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test  = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3700ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A integer input for vocab indices.\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "predictions = layers.Dense(3, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs, predictions)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "366aba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121/121 [==============================] - 5s 31ms/step - loss: 1.0998 - accuracy: 0.3436 - val_loss: 1.0990 - val_accuracy: 0.3482\n",
      "Epoch 2/3\n",
      "121/121 [==============================] - 3s 29ms/step - loss: 1.0908 - accuracy: 0.3665 - val_loss: 1.1223 - val_accuracy: 0.2983\n",
      "Epoch 3/3\n",
      "121/121 [==============================] - 3s 29ms/step - loss: 0.8675 - accuracy: 0.6270 - val_loss: 1.3879 - val_accuracy: 0.2775\n"
     ]
    }
   ],
   "source": [
    "cnn = model.fit(X_train, y_train, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ac6689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_pred = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4189188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.13925278990781173\n",
      "F1-score [0.13320463 0.20287253 0.19230769]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.10      0.13       720\n",
      "           1       0.24      0.18      0.20       637\n",
      "           2       0.27      0.15      0.19       704\n",
      "\n",
      "   micro avg       0.24      0.14      0.18      2061\n",
      "   macro avg       0.24      0.14      0.18      2061\n",
      "weighted avg       0.24      0.14      0.17      2061\n",
      " samples avg       0.14      0.14      0.14      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, cnn_pred))\n",
    "print('F1-score %s' % f1_score(y_test, cnn_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5867c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(100,), dtype=\"int64\") \n",
    "x   =  Embedding(max_features, embedding_dim)(input)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Conv1D(100, 3, padding='valid',activation='relu', strides=1)(x)\n",
    "x   =  GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model1 = Model(inputs=input, outputs=x)\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e031d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121/121 [==============================] - 4s 27ms/step - loss: 1.1001 - accuracy: 0.3512 - val_loss: 1.0984 - val_accuracy: 0.3482\n",
      "Epoch 2/3\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 1.0863 - accuracy: 0.3907 - val_loss: 1.0913 - val_accuracy: 0.3462\n",
      "Epoch 3/3\n",
      "121/121 [==============================] - 3s 26ms/step - loss: 1.0335 - accuracy: 0.4926 - val_loss: 1.1674 - val_accuracy: 0.3233\n"
     ]
    }
   ],
   "source": [
    "cnn1 = model1.fit(X_train, y_train, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bc14964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_pred1 = np.round(model1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab86ec01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.14313440077632217\n",
      "F1-score [0.25892857 0.         0.25608466]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.24      0.26       720\n",
      "           1       0.00      0.00      0.00       637\n",
      "           2       0.50      0.17      0.26       704\n",
      "\n",
      "   micro avg       0.34      0.14      0.20      2061\n",
      "   macro avg       0.26      0.14      0.17      2061\n",
      "weighted avg       0.27      0.14      0.18      2061\n",
      " samples avg       0.14      0.14      0.14      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, cnn_pred1))\n",
    "print('F1-score %s' % f1_score(y_test, cnn_pred1,average=None,zero_division = 0))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, cnn_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6268a8d",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eea569d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(sequence_length, )) \n",
    "x   =  Embedding(max_features, embedding_dim)(input)\n",
    "x   =  LSTM(100, return_sequences=True,name='lstm_layer')(x)\n",
    "x   =  GlobalMaxPool1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eecaee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=input, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f45fd2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121/121 [==============================] - 11s 80ms/step - loss: 1.0989 - accuracy: 0.3447 - val_loss: 1.0983 - val_accuracy: 0.3482\n",
      "Epoch 2/3\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 1.0783 - accuracy: 0.3967 - val_loss: 1.0708 - val_accuracy: 0.3960\n",
      "Epoch 3/3\n",
      "121/121 [==============================] - 9s 77ms/step - loss: 0.9836 - accuracy: 0.5186 - val_loss: 1.1507 - val_accuracy: 0.3368\n"
     ]
    }
   ],
   "source": [
    "lstm = model.fit(X_train, y_train, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6ac8ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "576a8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.13148956817079088\n",
      "F1-score [0.0809816  0.13768961 0.31793961]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.05      0.08       720\n",
      "           1       0.27      0.09      0.14       637\n",
      "           2       0.42      0.25      0.32       704\n",
      "\n",
      "   micro avg       0.37      0.13      0.19      2061\n",
      "   macro avg       0.35      0.13      0.18      2061\n",
      "weighted avg       0.35      0.13      0.18      2061\n",
      " samples avg       0.13      0.13      0.13      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, lstm_pred))\n",
    "print('F1-score %s' % f1_score(y_test, lstm_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0079ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(sequence_length,))\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = Embedding(max_features, embedding_dim)(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "# Add a classifier\n",
    "x = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ed12da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 29s 194ms/step - loss: 1.0999 - accuracy: 0.3416 - val_loss: 1.0985 - val_accuracy: 0.3482\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 22s 184ms/step - loss: 1.0949 - accuracy: 0.3663 - val_loss: 1.1186 - val_accuracy: 0.2588\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 22s 184ms/step - loss: 1.0189 - accuracy: 0.4749 - val_loss: 1.2199 - val_accuracy: 0.2277\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 23s 188ms/step - loss: 0.8657 - accuracy: 0.5820 - val_loss: 1.5448 - val_accuracy: 0.2058\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 22s 185ms/step - loss: 0.7193 - accuracy: 0.6577 - val_loss: 2.0297 - val_accuracy: 0.2006\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 22s 183ms/step - loss: 0.5813 - accuracy: 0.7180 - val_loss: 2.3735 - val_accuracy: 0.1975\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 22s 178ms/step - loss: 0.4810 - accuracy: 0.7764 - val_loss: 2.6921 - val_accuracy: 0.2027\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 22s 184ms/step - loss: 0.3771 - accuracy: 0.8253 - val_loss: 3.1927 - val_accuracy: 0.2058\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 24s 194ms/step - loss: 0.2971 - accuracy: 0.8695 - val_loss: 3.6751 - val_accuracy: 0.2214\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 25s 204ms/step - loss: 0.2282 - accuracy: 0.8965 - val_loss: 4.0472 - val_accuracy: 0.2256\n"
     ]
    }
   ],
   "source": [
    "lstm = model.fit(X_train, y_train, epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1c5dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 4s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "156ae378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.22998544395924309\n",
      "F1-score [0.22617354 0.21061644 0.25823806]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.22      0.23       720\n",
      "           1       0.23      0.19      0.21       637\n",
      "           2       0.25      0.27      0.26       704\n",
      "\n",
      "   micro avg       0.24      0.23      0.23      2061\n",
      "   macro avg       0.24      0.23      0.23      2061\n",
      "weighted avg       0.24      0.23      0.23      2061\n",
      " samples avg       0.23      0.23      0.23      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, lstm_pred))\n",
    "print('F1-score %s' % f1_score(y_test, lstm_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71ba69",
   "metadata": {},
   "source": [
    "## Pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0519e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5ff769fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorize_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "599d115a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '[UNK]': 1,\n",
       " 'high': 2,\n",
       " 'slaughtering': 3,\n",
       " 'failings': 4,\n",
       " 'cry': 5,\n",
       " 'esb': 6,\n",
       " 'winning': 7,\n",
       " 'fooling': 8,\n",
       " 'near': 9,\n",
       " 'cockpit': 10,\n",
       " 'cesare': 11,\n",
       " 'bur': 12,\n",
       " 'hondo': 13,\n",
       " 'reviews': 14,\n",
       " 'aswan': 15,\n",
       " 'alsacien': 16,\n",
       " 'ebb': 17,\n",
       " 'tarpley': 18,\n",
       " 'conversation': 19,\n",
       " 'winter': 20,\n",
       " 'greuze': 21,\n",
       " 'sikhs': 22,\n",
       " 'letting': 23,\n",
       " 'wrongly': 24,\n",
       " 'salads': 25,\n",
       " 'appetite': 26,\n",
       " 'newshour': 27,\n",
       " 'sons': 28,\n",
       " 'learning': 29,\n",
       " 'resigned': 30,\n",
       " 'dislocation': 31,\n",
       " 'barton': 32,\n",
       " 'live': 33,\n",
       " 'equate': 34,\n",
       " 'prancing': 35,\n",
       " 'charges': 36,\n",
       " 'rapid': 37,\n",
       " 'bradley': 38,\n",
       " 'diego': 39,\n",
       " 'molokai': 40,\n",
       " 'welcomed': 41,\n",
       " 'chicken': 42,\n",
       " 'gracious': 43,\n",
       " 'ranging': 44,\n",
       " 'dejima': 45,\n",
       " 'scary': 46,\n",
       " 'records': 47,\n",
       " 'pondering': 48,\n",
       " 'someday': 49,\n",
       " 'thrill': 50,\n",
       " 'handed': 51,\n",
       " 'allow': 52,\n",
       " 'neighboring': 53,\n",
       " 'string': 54,\n",
       " 'electrical': 55,\n",
       " 'people': 56,\n",
       " 'analytical': 57,\n",
       " 'artistic': 58,\n",
       " 'john': 59,\n",
       " 'confront': 60,\n",
       " 'or': 61,\n",
       " 'admits': 62,\n",
       " 'instincts': 63,\n",
       " 'sailing': 64,\n",
       " 'providers': 65,\n",
       " 'dali': 66,\n",
       " 'nations': 67,\n",
       " 'bowed': 68,\n",
       " 'gazing': 69,\n",
       " 'roman': 70,\n",
       " 'blend': 71,\n",
       " 'mailers': 72,\n",
       " 'domination': 73,\n",
       " 'miss': 74,\n",
       " 'ocean': 75,\n",
       " 'unavailability': 76,\n",
       " 'tuileries': 77,\n",
       " 'complaints': 78,\n",
       " 'mailbox': 79,\n",
       " 'conditioning': 80,\n",
       " 'uphold': 81,\n",
       " 'equal': 82,\n",
       " 'video': 83,\n",
       " 'gallery': 84,\n",
       " 'bangers': 85,\n",
       " 'washing': 86,\n",
       " 'gases': 87,\n",
       " 'nation': 88,\n",
       " 'traded': 89,\n",
       " 'subscribers': 90,\n",
       " 'defense': 91,\n",
       " 'peculiar': 92,\n",
       " 'handwriting': 93,\n",
       " 'successfully': 94,\n",
       " 'wave': 95,\n",
       " 'nervous': 96,\n",
       " 'thereon': 97,\n",
       " 'brookes': 98,\n",
       " 'rao': 99,\n",
       " 'generalized': 100,\n",
       " 'declared': 101,\n",
       " 'catching': 102,\n",
       " 'archives': 103,\n",
       " 'methodology': 104,\n",
       " 'stabilize': 105,\n",
       " 'tse': 106,\n",
       " 'censure': 107,\n",
       " 'awry': 108,\n",
       " 'characteristics': 109,\n",
       " 'ugly': 110,\n",
       " 'used': 111,\n",
       " 'defendants': 112,\n",
       " 'song': 113,\n",
       " 'diametrically': 114,\n",
       " 'kaufman': 115,\n",
       " 'minor': 116,\n",
       " 'largest': 117,\n",
       " 'blood': 118,\n",
       " 'diamond': 119,\n",
       " 'ford': 120,\n",
       " 'hitting': 121,\n",
       " 'sue': 122,\n",
       " 'envelope': 123,\n",
       " 'formentor': 124,\n",
       " 'import': 125,\n",
       " 'create': 126,\n",
       " 'knox': 127,\n",
       " 'dick': 128,\n",
       " 'victoria': 129,\n",
       " 'heroic': 130,\n",
       " 'landing': 131,\n",
       " 'cuban': 132,\n",
       " 'inefficient': 133,\n",
       " 'witches': 134,\n",
       " 'supremacy': 135,\n",
       " 'inventors': 136,\n",
       " 'parental': 137,\n",
       " 'hcfa': 138,\n",
       " 'hud': 139,\n",
       " 'ordered': 140,\n",
       " 'carnelian': 141,\n",
       " 'nyc': 142,\n",
       " 'sainte': 143,\n",
       " 'citations': 144,\n",
       " 'handling': 145,\n",
       " 'gratitude': 146,\n",
       " 'stuck': 147,\n",
       " 'ii': 148,\n",
       " 'fgd': 149,\n",
       " 'kebabs': 150,\n",
       " 'geico': 151,\n",
       " 'showed': 152,\n",
       " 'era': 153,\n",
       " 'allies': 154,\n",
       " 'visiting': 155,\n",
       " 'pitre': 156,\n",
       " 'representing': 157,\n",
       " 'diamonds': 158,\n",
       " 'imply': 159,\n",
       " 'expand': 160,\n",
       " 'sinatra': 161,\n",
       " 'variegated': 162,\n",
       " 'faces': 163,\n",
       " 'plunged': 164,\n",
       " 'what': 165,\n",
       " 'lawmakers': 166,\n",
       " 'addictive': 167,\n",
       " 'factors': 168,\n",
       " 'malfunction': 169,\n",
       " 'bled': 170,\n",
       " 'picky': 171,\n",
       " 'older': 172,\n",
       " 'trouble': 173,\n",
       " 'securing': 174,\n",
       " 'brighter': 175,\n",
       " 'kosovo': 176,\n",
       " 'servant': 177,\n",
       " 'elderly': 178,\n",
       " 'confused': 179,\n",
       " 'terms': 180,\n",
       " 'secure': 181,\n",
       " 'aides': 182,\n",
       " 'pleasantly': 183,\n",
       " 'dependency': 184,\n",
       " 'forcing': 185,\n",
       " 'saint': 186,\n",
       " 'bothering': 187,\n",
       " 'gras': 188,\n",
       " 'politically': 189,\n",
       " 'canadian': 190,\n",
       " 'louis': 191,\n",
       " 'subjects': 192,\n",
       " 'agent': 193,\n",
       " 'suspension': 194,\n",
       " 'holyrood': 195,\n",
       " 'intermittently': 196,\n",
       " 'indulge': 197,\n",
       " 'water': 198,\n",
       " 'look': 199,\n",
       " 'surprisingly': 200,\n",
       " 'sorts': 201,\n",
       " 'salesladies': 202,\n",
       " 'patents': 203,\n",
       " 'whoever': 204,\n",
       " 'scolds': 205,\n",
       " 'granada': 206,\n",
       " 'departure': 207,\n",
       " 'crooks': 208,\n",
       " 'evidence': 209,\n",
       " 'allocated': 210,\n",
       " 'knowing': 211,\n",
       " 'criminals': 212,\n",
       " 'gautama': 213,\n",
       " 'menorca': 214,\n",
       " 'mari': 215,\n",
       " 'drowning': 216,\n",
       " 'adaptation': 217,\n",
       " 'handy': 218,\n",
       " 'burst': 219,\n",
       " 'dating': 220,\n",
       " 'hear': 221,\n",
       " 'caucasian': 222,\n",
       " 'fee': 223,\n",
       " 'sovereign': 224,\n",
       " 'ramses': 225,\n",
       " 'february': 226,\n",
       " 'boosting': 227,\n",
       " 'household': 228,\n",
       " 'assumptions': 229,\n",
       " 'test': 230,\n",
       " 'courthouse': 231,\n",
       " 'chennai': 232,\n",
       " 'vehicle': 233,\n",
       " 'rivoli': 234,\n",
       " 'worries': 235,\n",
       " 'pistol': 236,\n",
       " 'reject': 237,\n",
       " 'nodded': 238,\n",
       " 'rallies': 239,\n",
       " 'condition': 240,\n",
       " 'pour': 241,\n",
       " 'purchaser': 242,\n",
       " 'supreme': 243,\n",
       " 'typical': 244,\n",
       " 'filled': 245,\n",
       " 'county': 246,\n",
       " 'claimed': 247,\n",
       " 'determination': 248,\n",
       " 'band': 249,\n",
       " 'tournament': 250,\n",
       " 'belonged': 251,\n",
       " 'envy': 252,\n",
       " 'camped': 253,\n",
       " 'compellingly': 254,\n",
       " 'massacre': 255,\n",
       " 'movies': 256,\n",
       " 'surrounded': 257,\n",
       " 'coloured': 258,\n",
       " 'modern': 259,\n",
       " 'stimulated': 260,\n",
       " 'crose': 261,\n",
       " 'mobility': 262,\n",
       " 'large': 263,\n",
       " 'propelled': 264,\n",
       " 'lit': 265,\n",
       " 'baltimore': 266,\n",
       " 'subside': 267,\n",
       " 'coalition': 268,\n",
       " 'microhockey': 269,\n",
       " 'comparison': 270,\n",
       " 'amnesty': 271,\n",
       " 'heyday': 272,\n",
       " 'selected': 273,\n",
       " 'generic': 274,\n",
       " 'outputs': 275,\n",
       " 'volley': 276,\n",
       " 'bathrooms': 277,\n",
       " 'bits': 278,\n",
       " 'speed': 279,\n",
       " 'mcdonald': 280,\n",
       " 'matching': 281,\n",
       " 'stephanopoulos': 282,\n",
       " 'craft': 283,\n",
       " 'cheerfully': 284,\n",
       " 'explored': 285,\n",
       " 'charming': 286,\n",
       " 'stranded': 287,\n",
       " 'toxicity': 288,\n",
       " 'volunteer': 289,\n",
       " 'unlikely': 290,\n",
       " 'buddhism': 291,\n",
       " 'repudiated': 292,\n",
       " 'holland': 293,\n",
       " 'perfect': 294,\n",
       " 'ricky': 295,\n",
       " 'angeles': 296,\n",
       " 'bay': 297,\n",
       " 'manufacturers': 298,\n",
       " 'occasional': 299,\n",
       " 'porch': 300,\n",
       " 'scores': 301,\n",
       " 'san': 302,\n",
       " 'available': 303,\n",
       " 'tales': 304,\n",
       " 'graceful': 305,\n",
       " 'doubts': 306,\n",
       " 'bus': 307,\n",
       " 'produced': 308,\n",
       " 'santa': 309,\n",
       " 'marching': 310,\n",
       " 'bien': 311,\n",
       " 'variety': 312,\n",
       " 'sat': 313,\n",
       " 'issue': 314,\n",
       " 'punta': 315,\n",
       " 'symphony': 316,\n",
       " 'agree': 317,\n",
       " 'equity': 318,\n",
       " 'enlightened': 319,\n",
       " 'severe': 320,\n",
       " 'valid': 321,\n",
       " 'converting': 322,\n",
       " 'domain': 323,\n",
       " 'shuddered': 324,\n",
       " 'j': 325,\n",
       " 'swine': 326,\n",
       " 'dodged': 327,\n",
       " 'affords': 328,\n",
       " 'tailored': 329,\n",
       " 'dichotomy': 330,\n",
       " 'defending': 331,\n",
       " 'relegated': 332,\n",
       " 'cardiac': 333,\n",
       " 'acreage': 334,\n",
       " 'undertaken': 335,\n",
       " 'equation': 336,\n",
       " 'parkland': 337,\n",
       " 'rockefeller': 338,\n",
       " 'raucous': 339,\n",
       " 'address': 340,\n",
       " 'smelledof': 341,\n",
       " 'felipe': 342,\n",
       " 'tireless': 343,\n",
       " 'maharashtra': 344,\n",
       " 'inspiration': 345,\n",
       " 'flat': 346,\n",
       " 'taiping': 347,\n",
       " 'flavor': 348,\n",
       " 'realized': 349,\n",
       " 'pelee': 350,\n",
       " 'capital': 351,\n",
       " 'vietnam': 352,\n",
       " 'parachute': 353,\n",
       " 'expertise': 354,\n",
       " 'enduring': 355,\n",
       " 'wrote': 356,\n",
       " 'distributors': 357,\n",
       " 'apse': 358,\n",
       " 'christ': 359,\n",
       " 'auto': 360,\n",
       " 'seventeen': 361,\n",
       " 'rocs': 362,\n",
       " 'jann': 363,\n",
       " 'stroll': 364,\n",
       " 'imports': 365,\n",
       " 'umbrella': 366,\n",
       " 'stunning': 367,\n",
       " 'thick': 368,\n",
       " 'restaurants': 369,\n",
       " 'poisoned': 370,\n",
       " 'pigs': 371,\n",
       " 'bounty': 372,\n",
       " 'shave': 373,\n",
       " 'thankful': 374,\n",
       " 'italians': 375,\n",
       " 'luxor': 376,\n",
       " 'carmo': 377,\n",
       " 'spite': 378,\n",
       " 'personification': 379,\n",
       " 'liqueur': 380,\n",
       " 'adjusting': 381,\n",
       " 'additions': 382,\n",
       " 'trace': 383,\n",
       " 'escort': 384,\n",
       " 'organization': 385,\n",
       " 'bournemouth': 386,\n",
       " 'passes': 387,\n",
       " 'shown': 388,\n",
       " 'lotion': 389,\n",
       " 'zombie': 390,\n",
       " 'privacy': 391,\n",
       " 'scutari': 392,\n",
       " 'clarence': 393,\n",
       " 'outnumber': 394,\n",
       " 'explaining': 395,\n",
       " 'mattered': 396,\n",
       " 'william': 397,\n",
       " 'argue': 398,\n",
       " 'galax': 399,\n",
       " 'replacement': 400,\n",
       " 'photographed': 401,\n",
       " 'lewinsky': 402,\n",
       " 'bases': 403,\n",
       " 'strides': 404,\n",
       " 'celebrity': 405,\n",
       " 'e': 406,\n",
       " 'kalinga': 407,\n",
       " 'admitted': 408,\n",
       " 'uninteresting': 409,\n",
       " 'regimens': 410,\n",
       " 'tinted': 411,\n",
       " 'briefly': 412,\n",
       " 'abstains': 413,\n",
       " 'husbands': 414,\n",
       " 'seeking': 415,\n",
       " 'nasire': 416,\n",
       " 'refers': 417,\n",
       " 'managed': 418,\n",
       " 'declined': 419,\n",
       " 'usual': 420,\n",
       " 'bahadur': 421,\n",
       " 'laborde': 422,\n",
       " 'poked': 423,\n",
       " 'fresh': 424,\n",
       " 'palm': 425,\n",
       " 'studio': 426,\n",
       " 'enrolls': 427,\n",
       " 'facets': 428,\n",
       " 'elections': 429,\n",
       " 'month': 430,\n",
       " 'art': 431,\n",
       " 'opportunities': 432,\n",
       " 'chairmen': 433,\n",
       " 'six': 434,\n",
       " 'mask': 435,\n",
       " 'searching': 436,\n",
       " 'hang': 437,\n",
       " 'saltwater': 438,\n",
       " 'informational': 439,\n",
       " 'legged': 440,\n",
       " 'aid': 441,\n",
       " 'shultz': 442,\n",
       " 'midnight': 443,\n",
       " 'outweigh': 444,\n",
       " 'mark': 445,\n",
       " 'offenders': 446,\n",
       " 'newcomers': 447,\n",
       " 'wayang': 448,\n",
       " 'ambient': 449,\n",
       " 'fannie': 450,\n",
       " 'designer': 451,\n",
       " 'impressed': 452,\n",
       " 'importer': 453,\n",
       " 'cheapest': 454,\n",
       " 'behavior': 455,\n",
       " 'prescription': 456,\n",
       " 'canada': 457,\n",
       " 'trading': 458,\n",
       " 'reporter': 459,\n",
       " 'james': 460,\n",
       " 'kkk': 461,\n",
       " 'alternative': 462,\n",
       " 'each': 463,\n",
       " 'civic': 464,\n",
       " 'utilizing': 465,\n",
       " 'sweetly': 466,\n",
       " 'fec': 467,\n",
       " 'philadelphia': 468,\n",
       " 'cool': 469,\n",
       " 'commercial': 470,\n",
       " 'hazard': 471,\n",
       " 'terminus': 472,\n",
       " 'lodi': 473,\n",
       " 'technical': 474,\n",
       " 'windows': 475,\n",
       " 'monastery': 476,\n",
       " 'god': 477,\n",
       " 'pointed': 478,\n",
       " 'therein': 479,\n",
       " 'barely': 480,\n",
       " 'shuttered': 481,\n",
       " 'baptists': 482,\n",
       " 'liberals': 483,\n",
       " 'room': 484,\n",
       " 'outbreak': 485,\n",
       " 'conglomerates': 486,\n",
       " 'monks': 487,\n",
       " 'mill': 488,\n",
       " 'photo': 489,\n",
       " 'experiencing': 490,\n",
       " 'famed': 491,\n",
       " 'remission': 492,\n",
       " 'che': 493,\n",
       " 'proving': 494,\n",
       " 'forbidding': 495,\n",
       " 'changed': 496,\n",
       " 'soaker': 497,\n",
       " 'trips': 498,\n",
       " 'tack': 499,\n",
       " 'pokemon': 500,\n",
       " 'rowlett': 501,\n",
       " 'allenby': 502,\n",
       " 'solved': 503,\n",
       " 'voluntarily': 504,\n",
       " 'dressing': 505,\n",
       " 'cheesecake': 506,\n",
       " 'depicts': 507,\n",
       " 'ingoing': 508,\n",
       " 'turks': 509,\n",
       " 'shock': 510,\n",
       " 'channel': 511,\n",
       " 'hand': 512,\n",
       " 'cios': 513,\n",
       " 'mover': 514,\n",
       " 'charity': 515,\n",
       " 'investment': 516,\n",
       " 'welcome': 517,\n",
       " 'formlessness': 518,\n",
       " 'periodically': 519,\n",
       " 'clerk': 520,\n",
       " 'height': 521,\n",
       " 'proceed': 522,\n",
       " 'compatible': 523,\n",
       " 'perilously': 524,\n",
       " 'eupalinos': 525,\n",
       " 'czarek': 526,\n",
       " 'implies': 527,\n",
       " 'sitting': 528,\n",
       " 'prosecutor': 529,\n",
       " 'consumer': 530,\n",
       " 'cares': 531,\n",
       " 'version': 532,\n",
       " 'talented': 533,\n",
       " 'compressable': 534,\n",
       " 'deity': 535,\n",
       " 'humans': 536,\n",
       " 'itself': 537,\n",
       " 'average': 538,\n",
       " 'chloroform': 539,\n",
       " 'nothing': 540,\n",
       " 'diplomacy': 541,\n",
       " 'retroactive': 542,\n",
       " 'ultimate': 543,\n",
       " 'farouk': 544,\n",
       " 'compensate': 545,\n",
       " 'racing': 546,\n",
       " 'shutterbugs': 547,\n",
       " 'narrow': 548,\n",
       " 'volunteers': 549,\n",
       " 'coastal': 550,\n",
       " 'differently': 551,\n",
       " 'projection': 552,\n",
       " 'observers': 553,\n",
       " 'tenfold': 554,\n",
       " 'mediocre': 555,\n",
       " 'repaired': 556,\n",
       " 'bid': 557,\n",
       " 'gpra': 558,\n",
       " 'variegatus': 559,\n",
       " 'huguenot': 560,\n",
       " 'extravagant': 561,\n",
       " 'area': 562,\n",
       " 'watermelon': 563,\n",
       " 'welt': 564,\n",
       " 'pontoon': 565,\n",
       " 'dana': 566,\n",
       " 'default': 567,\n",
       " 'changes': 568,\n",
       " 'subsidies': 569,\n",
       " 'envious': 570,\n",
       " 'reversal': 571,\n",
       " 'submit': 572,\n",
       " 'dangerous': 573,\n",
       " 'keen': 574,\n",
       " 'advertising': 575,\n",
       " 'meantime': 576,\n",
       " 'revolver': 577,\n",
       " 'shuttering': 578,\n",
       " 'bears': 579,\n",
       " 'overtly': 580,\n",
       " 'emeralds': 581,\n",
       " 'bedesten': 582,\n",
       " 'tigers': 583,\n",
       " 'persian': 584,\n",
       " 'and': 585,\n",
       " 'card': 586,\n",
       " 'cucci': 587,\n",
       " 'fool': 588,\n",
       " 'telling': 589,\n",
       " 'dublin': 590,\n",
       " 'journal': 591,\n",
       " 'spices': 592,\n",
       " 'chase': 593,\n",
       " 'ferocious': 594,\n",
       " 'propose': 595,\n",
       " 'wright': 596,\n",
       " 'picked': 597,\n",
       " 'enlisted': 598,\n",
       " 'mae': 599,\n",
       " 'hannibal': 600,\n",
       " 'bhansi': 601,\n",
       " 'unsafe': 602,\n",
       " 'spanish': 603,\n",
       " 'hippodrome': 604,\n",
       " 'association': 605,\n",
       " 'manoa': 606,\n",
       " 'convene': 607,\n",
       " 'submitted': 608,\n",
       " 'autopilot': 609,\n",
       " 'pans': 610,\n",
       " 'sooner': 611,\n",
       " 'charmers': 612,\n",
       " 'vibrant': 613,\n",
       " 'nist': 614,\n",
       " 'welsh': 615,\n",
       " 'suggest': 616,\n",
       " 'tool': 617,\n",
       " 'laughed': 618,\n",
       " 'azaleas': 619,\n",
       " 'dozen': 620,\n",
       " 'flesh': 621,\n",
       " 'winners': 622,\n",
       " 'recline': 623,\n",
       " 'assumption': 624,\n",
       " 'demonstrations': 625,\n",
       " 'rubbed': 626,\n",
       " 'ideas': 627,\n",
       " 'procured': 628,\n",
       " 'governor': 629,\n",
       " 'mines': 630,\n",
       " 'pollster': 631,\n",
       " 'armbands': 632,\n",
       " 'streamlined': 633,\n",
       " 'worrying': 634,\n",
       " 'nurse': 635,\n",
       " 'injured': 636,\n",
       " 'sadistic': 637,\n",
       " 'theory': 638,\n",
       " 'phrase': 639,\n",
       " 'encouraged': 640,\n",
       " 'appropriated': 641,\n",
       " 'twenties': 642,\n",
       " 'armada': 643,\n",
       " 'napoleon': 644,\n",
       " 'needs': 645,\n",
       " 'luisa': 646,\n",
       " 'thira': 647,\n",
       " 'childless': 648,\n",
       " 'once': 649,\n",
       " 'tegh': 650,\n",
       " 'misdemeanor': 651,\n",
       " 'force': 652,\n",
       " 'considering': 653,\n",
       " 'opposition': 654,\n",
       " 'lunch': 655,\n",
       " 'carroll': 656,\n",
       " 'rip': 657,\n",
       " 'horror': 658,\n",
       " 'husband': 659,\n",
       " 'la': 660,\n",
       " 'sta': 661,\n",
       " 'sustained': 662,\n",
       " 'developed': 663,\n",
       " 'west': 664,\n",
       " 'responsable': 665,\n",
       " 'crevices': 666,\n",
       " 'reductions': 667,\n",
       " 'experiments': 668,\n",
       " 'complaint': 669,\n",
       " 'perpetual': 670,\n",
       " 'wanting': 671,\n",
       " 'islands': 672,\n",
       " 'usps': 673,\n",
       " 'galilean': 674,\n",
       " 'having': 675,\n",
       " 'during': 676,\n",
       " 'boots': 677,\n",
       " 'troupe': 678,\n",
       " 'candle': 679,\n",
       " 'managers': 680,\n",
       " 'combat': 681,\n",
       " 'else': 682,\n",
       " 'modem': 683,\n",
       " 'availability': 684,\n",
       " 'jets': 685,\n",
       " 'eligible': 686,\n",
       " 'bertrand': 687,\n",
       " 'interpenetrating': 688,\n",
       " 'stroke': 689,\n",
       " 'rationalized': 690,\n",
       " 'clubs': 691,\n",
       " 'automatically': 692,\n",
       " 'income': 693,\n",
       " 'parts': 694,\n",
       " 'selimiye': 695,\n",
       " 'sides': 696,\n",
       " 'front': 697,\n",
       " 'repent': 698,\n",
       " 'secrets': 699,\n",
       " 'other': 700,\n",
       " 'reading': 701,\n",
       " 'taken': 702,\n",
       " 'merry': 703,\n",
       " 'streams': 704,\n",
       " 'legs': 705,\n",
       " 'collectibles': 706,\n",
       " 'announcing': 707,\n",
       " 'received': 708,\n",
       " 'bringing': 709,\n",
       " 'delicacy': 710,\n",
       " 'mumbai': 711,\n",
       " 'reserves': 712,\n",
       " 'blame': 713,\n",
       " 'tadminster': 714,\n",
       " 'palestrina': 715,\n",
       " 'methodologies': 716,\n",
       " 'yellow': 717,\n",
       " 'sabina': 718,\n",
       " 'hastings': 719,\n",
       " 'taj': 720,\n",
       " 'canals': 721,\n",
       " 'wyoming': 722,\n",
       " 'jagged': 723,\n",
       " 'basically': 724,\n",
       " 'constitute': 725,\n",
       " 'pertaining': 726,\n",
       " 'whilst': 727,\n",
       " 'shaved': 728,\n",
       " 'texan': 729,\n",
       " 'dominant': 730,\n",
       " 'rapidly': 731,\n",
       " 'units': 732,\n",
       " 'decadent': 733,\n",
       " 'los': 734,\n",
       " 'kid': 735,\n",
       " 'undefended': 736,\n",
       " 'newhoff': 737,\n",
       " 'contradict': 738,\n",
       " 'gobind': 739,\n",
       " 'legal': 740,\n",
       " 'collect': 741,\n",
       " 'funding': 742,\n",
       " 'alert': 743,\n",
       " 'goddess': 744,\n",
       " 'drop': 745,\n",
       " 'intel': 746,\n",
       " 'tragedy': 747,\n",
       " 'hurriya': 748,\n",
       " 'supported': 749,\n",
       " 'fond': 750,\n",
       " 'econometric': 751,\n",
       " 'proportion': 752,\n",
       " 'dirty': 753,\n",
       " 'responsibilities': 754,\n",
       " 'textile': 755,\n",
       " 'gang': 756,\n",
       " 'tomatoes': 757,\n",
       " 'consist': 758,\n",
       " 'epicentres': 759,\n",
       " 'details': 760,\n",
       " 'advocating': 761,\n",
       " 'referendums': 762,\n",
       " 'good': 763,\n",
       " 'economically': 764,\n",
       " 'orchestra': 765,\n",
       " 'chatterbox': 766,\n",
       " 'liggett': 767,\n",
       " 'dolomites': 768,\n",
       " 'joy': 769,\n",
       " 'wealth': 770,\n",
       " 'showroom': 771,\n",
       " 'misconduct': 772,\n",
       " 'verge': 773,\n",
       " 'perfectly': 774,\n",
       " 'acclamation': 775,\n",
       " 'attendance': 776,\n",
       " 'premiums': 777,\n",
       " 'abundance': 778,\n",
       " 'page': 779,\n",
       " 'succeed': 780,\n",
       " 'situated': 781,\n",
       " 'staffing': 782,\n",
       " 'lasted': 783,\n",
       " 'mare': 784,\n",
       " 'wgn': 785,\n",
       " 'was': 786,\n",
       " 'lectures': 787,\n",
       " 'role': 788,\n",
       " 'selangor': 789,\n",
       " 'indignantly': 790,\n",
       " 'grams': 791,\n",
       " 'competitors': 792,\n",
       " 'scavengers': 793,\n",
       " 'harshly': 794,\n",
       " 'ready': 795,\n",
       " 'falls': 796,\n",
       " 'venerated': 797,\n",
       " 'flapping': 798,\n",
       " 'home': 799,\n",
       " 'bankers': 800,\n",
       " 'cleaning': 801,\n",
       " 'capita': 802,\n",
       " 'scripture': 803,\n",
       " 'all': 804,\n",
       " 'doing': 805,\n",
       " 'interpretation': 806,\n",
       " 'dear': 807,\n",
       " 'agreement': 808,\n",
       " 'two': 809,\n",
       " 'candidates': 810,\n",
       " 'tinos': 811,\n",
       " 'hoi': 812,\n",
       " 'emperors': 813,\n",
       " 'handing': 814,\n",
       " 'outlawing': 815,\n",
       " 'dealt': 816,\n",
       " 'chain': 817,\n",
       " 'consequences': 818,\n",
       " 'oak': 819,\n",
       " 'sped': 820,\n",
       " 'preparation': 821,\n",
       " 'rafting': 822,\n",
       " 'presenting': 823,\n",
       " 'vary': 824,\n",
       " 'farmer': 825,\n",
       " 'entirely': 826,\n",
       " 'tighter': 827,\n",
       " 'strain': 828,\n",
       " 'procedures': 829,\n",
       " 'conform': 830,\n",
       " 'bundle': 831,\n",
       " 'clinicians': 832,\n",
       " 'realization': 833,\n",
       " 'formed': 834,\n",
       " 'theaters': 835,\n",
       " 'indicted': 836,\n",
       " 'inadvertently': 837,\n",
       " 'relates': 838,\n",
       " 'questioning': 839,\n",
       " 'these': 840,\n",
       " 'shivered': 841,\n",
       " 'strips': 842,\n",
       " 'arch': 843,\n",
       " 'muckraking': 844,\n",
       " 'rainy': 845,\n",
       " 'delicious': 846,\n",
       " 'criticism': 847,\n",
       " 'manchester': 848,\n",
       " 'filters': 849,\n",
       " 'voters': 850,\n",
       " 'prison': 851,\n",
       " 'affirm': 852,\n",
       " 'whites': 853,\n",
       " 'route': 854,\n",
       " 'principle': 855,\n",
       " 'bounds': 856,\n",
       " 'crawling': 857,\n",
       " 'moniz': 858,\n",
       " 'crashed': 859,\n",
       " 'translated': 860,\n",
       " 'flatter': 861,\n",
       " 'contrast': 862,\n",
       " 'loyalty': 863,\n",
       " 'miniseries': 864,\n",
       " 'demolish': 865,\n",
       " 'gallup': 866,\n",
       " 'performers': 867,\n",
       " 'wheat': 868,\n",
       " 'corporate': 869,\n",
       " 'perestrelo': 870,\n",
       " 'veneto': 871,\n",
       " 'fitted': 872,\n",
       " 'conflicts': 873,\n",
       " 'nose': 874,\n",
       " 'results': 875,\n",
       " 'laced': 876,\n",
       " 'referencing': 877,\n",
       " 'whiskey': 878,\n",
       " 'hawaiian': 879,\n",
       " 'sprout': 880,\n",
       " 'context': 881,\n",
       " 'publique': 882,\n",
       " 'oval': 883,\n",
       " 'atop': 884,\n",
       " 'conservative': 885,\n",
       " 'starvation': 886,\n",
       " 'unanimous': 887,\n",
       " 'layman': 888,\n",
       " 'senders': 889,\n",
       " 'furnished': 890,\n",
       " 'opens': 891,\n",
       " 'rock': 892,\n",
       " 'everyone': 893,\n",
       " 'magical': 894,\n",
       " 'morgan': 895,\n",
       " 'villages': 896,\n",
       " 'versace': 897,\n",
       " 'economic': 898,\n",
       " 'mower': 899,\n",
       " 'evaluated': 900,\n",
       " 'chrysolite': 901,\n",
       " 'requesters': 902,\n",
       " 'companies': 903,\n",
       " 'swimming': 904,\n",
       " 'himalayas': 905,\n",
       " 'absalom': 906,\n",
       " 'kale': 907,\n",
       " 'heart': 908,\n",
       " 'creature': 909,\n",
       " 'retired': 910,\n",
       " 'piercing': 911,\n",
       " 'flipper': 912,\n",
       " 'vosges': 913,\n",
       " 'highway': 914,\n",
       " 'calculable': 915,\n",
       " 'exercise': 916,\n",
       " 'del': 917,\n",
       " 'kemal': 918,\n",
       " 'appreciated': 919,\n",
       " 'neglected': 920,\n",
       " 'karl': 921,\n",
       " 'restaurant': 922,\n",
       " 'luxurious': 923,\n",
       " 'mechanical': 924,\n",
       " 'vacationed': 925,\n",
       " 'children': 926,\n",
       " 'coroner': 927,\n",
       " 'doesnt': 928,\n",
       " 'whistling': 929,\n",
       " 'statute': 930,\n",
       " 'heroin': 931,\n",
       " 'loft': 932,\n",
       " 'zoning': 933,\n",
       " 'won': 934,\n",
       " 'testify': 935,\n",
       " 'crusaders': 936,\n",
       " 'grove': 937,\n",
       " 'merchants': 938,\n",
       " 'redeeming': 939,\n",
       " 'website': 940,\n",
       " 'columbia': 941,\n",
       " 'mar': 942,\n",
       " 'unaffected': 943,\n",
       " 'tiberias': 944,\n",
       " 'sim': 945,\n",
       " 'instruction': 946,\n",
       " 'bait': 947,\n",
       " 'hurtled': 948,\n",
       " 'punishment': 949,\n",
       " 'adamant': 950,\n",
       " 'nine': 951,\n",
       " 'bars': 952,\n",
       " 'officials': 953,\n",
       " 'thompson': 954,\n",
       " 'algebra': 955,\n",
       " 'callers': 956,\n",
       " 'brought': 957,\n",
       " 'bat': 958,\n",
       " 'fairly': 959,\n",
       " 'planning': 960,\n",
       " 'risks': 961,\n",
       " 'deranged': 962,\n",
       " 'bucks': 963,\n",
       " 'hotter': 964,\n",
       " 'morality': 965,\n",
       " 'fair': 966,\n",
       " 'francis': 967,\n",
       " 'wished': 968,\n",
       " 'shopping': 969,\n",
       " 'madrid': 970,\n",
       " 'tran': 971,\n",
       " 'libert': 972,\n",
       " 'patronized': 973,\n",
       " 'tested': 974,\n",
       " 'fill': 975,\n",
       " 'asking': 976,\n",
       " 'omb': 977,\n",
       " 'expanding': 978,\n",
       " 'alluded': 979,\n",
       " 'political': 980,\n",
       " 'retailers': 981,\n",
       " 'dona': 982,\n",
       " 'cassis': 983,\n",
       " 'kendal': 984,\n",
       " 'shockingly': 985,\n",
       " 'yours': 986,\n",
       " 'erotica': 987,\n",
       " 'drives': 988,\n",
       " 'busily': 989,\n",
       " 'shoot': 990,\n",
       " 'naples': 991,\n",
       " 'cared': 992,\n",
       " 'nefarious': 993,\n",
       " 'rhetoric': 994,\n",
       " 'expenditures': 995,\n",
       " 'insects': 996,\n",
       " 'eviction': 997,\n",
       " 'mangrove': 998,\n",
       " 'tracy': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "52fd7d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.100d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b5039a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 10507 words (257 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "words_not_found = []\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        words_not_found.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "020651eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'alsacien',\n",
       " 'salesladies',\n",
       " 'microhockey',\n",
       " 'smelledof',\n",
       " 'nasire',\n",
       " 'eupalinos',\n",
       " 'czarek',\n",
       " 'compressable',\n",
       " 'bedesten',\n",
       " 'bhansi',\n",
       " 'tadminster',\n",
       " 'newhoff',\n",
       " 'perestrelo',\n",
       " 'chrysolite',\n",
       " 'barenakedino',\n",
       " 'meydane',\n",
       " 'nkow',\n",
       " 'bhuleshwar',\n",
       " 'unpompous',\n",
       " 'ofrequired',\n",
       " 'photomurals',\n",
       " 'iversons',\n",
       " 'furniure',\n",
       " 'whitebelly',\n",
       " 'workshare',\n",
       " 'interlaboratory',\n",
       " 'heand',\n",
       " 'egus',\n",
       " 'vedr',\n",
       " 'atechnical',\n",
       " 'casuality',\n",
       " 'dubbawya',\n",
       " 'uluda',\n",
       " 'recultivate',\n",
       " 'marlenheim',\n",
       " 'tragea',\n",
       " 'smegal',\n",
       " 'sabelhaus',\n",
       " 'ataterk',\n",
       " 'beryllina',\n",
       " 'wealthies',\n",
       " 'carbet',\n",
       " 'louisian',\n",
       " 'ofiice',\n",
       " 'idpa',\n",
       " 'showbizzy',\n",
       " 'riviyre',\n",
       " 'espetada',\n",
       " 'counterevidence',\n",
       " 'mastihohoria',\n",
       " 'troues',\n",
       " 'siddartha',\n",
       " 'mailstreams',\n",
       " 'redhanded',\n",
       " 'atat',\n",
       " 'afterthefact',\n",
       " 'knowledgebased',\n",
       " 'cityart',\n",
       " 'gauve',\n",
       " 'pattys',\n",
       " 'pollentia',\n",
       " 'montmarte',\n",
       " 'panzar',\n",
       " 'citypalace',\n",
       " 'preservationalists',\n",
       " 'disintermediating',\n",
       " 'mutahir',\n",
       " 'nontransportation',\n",
       " 'monumentalprotection',\n",
       " 'tetanic',\n",
       " 'huaisheng',\n",
       " 'mytilini',\n",
       " 'restoorant',\n",
       " 'dictatorially',\n",
       " 'ceteau',\n",
       " 'castanheiro',\n",
       " 'ofcurrent',\n",
       " 'directiions',\n",
       " 'vandemeyer',\n",
       " 'gofundme',\n",
       " 'gambolling',\n",
       " 'kelase',\n",
       " 'motionlessly',\n",
       " 'zefat',\n",
       " 'nonexchange',\n",
       " 'mailstream',\n",
       " 'loyala',\n",
       " 'strees',\n",
       " 'bicurei',\n",
       " 'bgross',\n",
       " 'wonking',\n",
       " 'morethan',\n",
       " 'pippens',\n",
       " 'kizartmas',\n",
       " 'nileometer',\n",
       " 'vaikuntaperumal',\n",
       " 'paroseas',\n",
       " 'mysidopsis',\n",
       " 'fiveyear',\n",
       " 'tengh',\n",
       " 'stramongate',\n",
       " 'javis',\n",
       " 'bsing',\n",
       " 'wordsmithing',\n",
       " 'valueable',\n",
       " 'chiropractics',\n",
       " 'friedrick',\n",
       " 'crotoy',\n",
       " 'pergamene',\n",
       " 'barnam',\n",
       " 'keleter',\n",
       " 'incase',\n",
       " 'punditus',\n",
       " 'kulesi',\n",
       " 'boork',\n",
       " 'proserous',\n",
       " 'lingett',\n",
       " 'katachi',\n",
       " 'unprepssessing',\n",
       " 'calue',\n",
       " 'mandrakes',\n",
       " 'felicities',\n",
       " 'bauerstein',\n",
       " 'rulemakings',\n",
       " 'battistoni',\n",
       " 'fengari',\n",
       " 'availalbe',\n",
       " 'mortifyingly',\n",
       " 'patlecan',\n",
       " 'clintonas',\n",
       " 'ineptitudes',\n",
       " 'czesiek',\n",
       " 'bannisters',\n",
       " 'cabourge',\n",
       " 'palmaria',\n",
       " 'madeirans',\n",
       " 'postaward',\n",
       " 'podunkowice',\n",
       " 'zelon',\n",
       " 'worldaid',\n",
       " 'massabielle',\n",
       " 'vezir',\n",
       " 'clienteligible',\n",
       " 'apalrc',\n",
       " 'curros',\n",
       " 'melodio',\n",
       " 'reppublica',\n",
       " 'mccalpinmaria',\n",
       " 'adversisers',\n",
       " 'nonautomated',\n",
       " 'archeabacteria',\n",
       " 'overstayer',\n",
       " 'sefat',\n",
       " 'empaling',\n",
       " 'samothrakia',\n",
       " 'hayey',\n",
       " 'nepdg',\n",
       " 'levadas',\n",
       " 'andratx',\n",
       " 'lusadas',\n",
       " 'naturisme',\n",
       " 'enterprisewide',\n",
       " 'complicatedly',\n",
       " 'territoriy',\n",
       " 'nlada',\n",
       " 'caleornia',\n",
       " 'krewski',\n",
       " 'kutchins',\n",
       " 'camees',\n",
       " 'melroseabbey',\n",
       " 'fwi',\n",
       " 'onardo',\n",
       " 'wagonheim',\n",
       " 'alonissos',\n",
       " 'nonproselytizing',\n",
       " 'madrile',\n",
       " 'menidia',\n",
       " 'thirasia',\n",
       " 'deitiesinegyptianmythologyandthis',\n",
       " 'hamzy',\n",
       " 'crosethe',\n",
       " 'pmsd',\n",
       " 'burnsian',\n",
       " 'gagas',\n",
       " 'postpayment',\n",
       " 'disaffecting',\n",
       " 'tehy',\n",
       " 'disjointedly',\n",
       " 'inmotion',\n",
       " 'suggesetions',\n",
       " 'cityalk',\n",
       " 'gaoas',\n",
       " 'thedegree',\n",
       " 'hillend',\n",
       " 'conspiracism',\n",
       " 'differant',\n",
       " 'alacah',\n",
       " 'achange',\n",
       " 'fasulye',\n",
       " 'scafelf',\n",
       " 'groupof',\n",
       " 'ptolomies',\n",
       " 'cathedrale',\n",
       " 'capgains',\n",
       " 'cityhall',\n",
       " 'tarare',\n",
       " 'rajabai',\n",
       " 'erlenborn',\n",
       " 'brodkeys',\n",
       " 'neccesary',\n",
       " 'spproaches',\n",
       " 'unibasket',\n",
       " 'pices',\n",
       " 'financerelated',\n",
       " 'kingsferry',\n",
       " 'croseover',\n",
       " 'discothyques',\n",
       " 'barogue',\n",
       " 'inglethorp',\n",
       " 'reigninh',\n",
       " 'lasnny',\n",
       " 'busineses',\n",
       " 'heftman',\n",
       " 'famour',\n",
       " 'probononet',\n",
       " 'tauted',\n",
       " 'riph',\n",
       " 'dwara',\n",
       " 'syvres',\n",
       " 'scafeld',\n",
       " 'itbased',\n",
       " 'sarayy',\n",
       " 'labord',\n",
       " 'diso',\n",
       " 'hosue',\n",
       " 'lalley',\n",
       " 'herdwick',\n",
       " 'rique',\n",
       " 'missenhardt',\n",
       " 'worksharing',\n",
       " 'overcomplicates',\n",
       " 'kadifekale',\n",
       " 'adrin',\n",
       " 'vreanna',\n",
       " 'ceter',\n",
       " 'hersheimmer',\n",
       " 'acondition',\n",
       " 'espalmador',\n",
       " 'douchebags',\n",
       " 'lolani',\n",
       " 'caletta',\n",
       " 'souveineers',\n",
       " 'workshared',\n",
       " 'barfed',\n",
       " 'overmechanical']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c11fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    #trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66b79f",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "61a94039",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sequences_input = keras.Input(shape=(100,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 3, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model1 = Model(inputs=int_sequences_input, outputs=x)\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7469ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 4s 28ms/step - loss: 1.1108 - accuracy: 0.3509 - val_loss: 1.1025 - val_accuracy: 0.3451\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 1.0854 - accuracy: 0.3941 - val_loss: 1.1009 - val_accuracy: 0.3524\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 1.0367 - accuracy: 0.4778 - val_loss: 1.1091 - val_accuracy: 0.3617\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.9206 - accuracy: 0.5643 - val_loss: 1.1317 - val_accuracy: 0.3597\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 3s 27ms/step - loss: 0.6714 - accuracy: 0.7252 - val_loss: 1.3466 - val_accuracy: 0.3576\n"
     ]
    }
   ],
   "source": [
    "cnn = model1.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "30841440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_pred = np.round(model1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e781969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.24939349830179525\n",
      "F1-score [0.34972678 0.30877193 0.18201998]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.36      0.35       720\n",
      "           1       0.35      0.28      0.31       637\n",
      "           2       0.42      0.12      0.18       704\n",
      "\n",
      "   micro avg       0.36      0.25      0.29      2061\n",
      "   macro avg       0.37      0.25      0.28      2061\n",
      "weighted avg       0.37      0.25      0.28      2061\n",
      " samples avg       0.25      0.25      0.25      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, cnn_pred))\n",
    "print('F1-score %s' % f1_score(y_test, cnn_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7661e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(100,), dtype=\"int64\") \n",
    "x   =  embedding_layer(input)\n",
    "#x   =  Dropout(0.2)(x)\n",
    "x   =  Conv1D(100, 3, padding='valid',activation='relu', strides=1)(x)\n",
    "x   =  GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=input, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5905dc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 4s 26ms/step - loss: 1.1140 - accuracy: 0.3405 - val_loss: 1.1051 - val_accuracy: 0.3233\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 1.0908 - accuracy: 0.3826 - val_loss: 1.1096 - val_accuracy: 0.3347\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 1.0524 - accuracy: 0.4554 - val_loss: 1.1207 - val_accuracy: 0.3368\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.9610 - accuracy: 0.5487 - val_loss: 1.2645 - val_accuracy: 0.3170\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 3s 24ms/step - loss: 0.8206 - accuracy: 0.6428 - val_loss: 1.3183 - val_accuracy: 0.3170\n"
     ]
    }
   ],
   "source": [
    "cnn = model.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4ef2be96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_pred = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8c529a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.21542940320232898\n",
      "F1-score [0.10383747 0.34543011 0.26679281]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.06      0.10       720\n",
      "           1       0.30      0.40      0.35       637\n",
      "           2       0.40      0.20      0.27       704\n",
      "\n",
      "   micro avg       0.32      0.22      0.26      2061\n",
      "   macro avg       0.33      0.22      0.24      2061\n",
      "weighted avg       0.33      0.22      0.23      2061\n",
      " samples avg       0.22      0.22      0.22      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, cnn_pred))\n",
    "print('F1-score %s' % f1_score(y_test, cnn_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf30d7",
   "metadata": {},
   "source": [
    "### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e707bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121/121 [==============================] - 41s 326ms/step - loss: 1.1010 - accuracy: 0.3486 - val_loss: 1.0987 - val_accuracy: 0.3503\n",
      "Epoch 2/3\n",
      "121/121 [==============================] - 39s 325ms/step - loss: 1.0596 - accuracy: 0.4318 - val_loss: 1.0969 - val_accuracy: 0.3701\n",
      "Epoch 3/3\n",
      "121/121 [==============================] - 39s 326ms/step - loss: 0.9394 - accuracy: 0.5516 - val_loss: 1.2334 - val_accuracy: 0.3690\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(100,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x   =  LSTM(100, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x   =  GlobalMaxPool1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "lstm_model = Model(inputs=int_sequences_input, outputs=x)\n",
    "lstm_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "lstm = lstm_model.fit(X_train, y_train, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "61528a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 4s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = np.round(lstm_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "44e2647f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.22125181950509462\n",
      "F1-score [0.08302808 0.24072217 0.40536913]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.05      0.08       720\n",
      "           1       0.33      0.19      0.24       637\n",
      "           2       0.38      0.43      0.41       704\n",
      "\n",
      "   micro avg       0.37      0.22      0.28      2061\n",
      "   macro avg       0.35      0.22      0.24      2061\n",
      "weighted avg       0.35      0.22      0.24      2061\n",
      " samples avg       0.22      0.22      0.22      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, lstm_pred))\n",
    "print('F1-score %s' % f1_score(y_test, lstm_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b49021bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(sequence_length,))\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = embedding_layer(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "# Add a classifier\n",
    "x = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model2 = keras.Model(inputs, outputs=x)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "83acf08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 81s 636ms/step - loss: 1.0233 - accuracy: 0.4549 - val_loss: 1.3113 - val_accuracy: 0.3119\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 70s 578ms/step - loss: 0.8714 - accuracy: 0.6207 - val_loss: 1.5195 - val_accuracy: 0.3077\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 71s 587ms/step - loss: 0.7462 - accuracy: 0.6946 - val_loss: 1.4782 - val_accuracy: 0.2848\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 75s 620ms/step - loss: 0.6484 - accuracy: 0.7377 - val_loss: 1.7203 - val_accuracy: 0.3191\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 79s 653ms/step - loss: 0.5237 - accuracy: 0.7944 - val_loss: 1.9165 - val_accuracy: 0.3202\n"
     ]
    }
   ],
   "source": [
    "lstm = model2.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d2e9a9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 12s 161ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = np.round(model2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5dfb9188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.2828723920426977\n",
      "F1-score [0.18967136 0.31390135 0.36657682]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.14      0.19       720\n",
      "           1       0.30      0.33      0.31       637\n",
      "           2       0.35      0.39      0.37       704\n",
      "\n",
      "   micro avg       0.32      0.28      0.30      2061\n",
      "   macro avg       0.31      0.29      0.29      2061\n",
      "weighted avg       0.31      0.28      0.29      2061\n",
      " samples avg       0.28      0.28      0.28      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, pred))\n",
    "print('F1-score %s' % f1_score(y_test, pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fdd1fdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a4f535d9a0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lstm.history['loss'], label='loss', marker = 'o')\n",
    "plt.plot(lstm.history['val_loss'], label = 'val_loss', marker = 'o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1d77c",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e47bde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now sequence must be 300 to fit with fastText\n",
    "max_features = len(text1)+2\n",
    "embedding_dim = 128\n",
    "sequence_length = 300\n",
    "\n",
    "\n",
    "def custom_slpit(input_data):\n",
    "    return tf.strings.split(input_data)\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    vocabulary = text1,\n",
    "    output_mode=\"int\",\n",
    "    ngrams = None,\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "#commented because we passed a vocabulary\n",
    "#vectorize_layer.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "238897e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorize_layer(x_train)\n",
    "X_test = vectorize_layer(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "167c8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q crawl-300d-2M.vec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2c4ada1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1999996 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('crawl-300d-2M.vec', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4d4cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorize_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2368842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 10421 words (343 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "words_not_found = []\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        words_not_found.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8d27a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'proserous',\n",
       " 'crosethe',\n",
       " 'tarpley',\n",
       " 'tzfat',\n",
       " 'hoysala',\n",
       " 'allenby',\n",
       " 'filipa',\n",
       " 'photomurals',\n",
       " 'yanomamo',\n",
       " 'cityalk',\n",
       " 'hurriya',\n",
       " 'uluda',\n",
       " 'beaubourg',\n",
       " 'capgains',\n",
       " 'labord',\n",
       " 'lvov',\n",
       " 'blencathra',\n",
       " 'patlecan',\n",
       " 'mayar',\n",
       " 'francesc',\n",
       " 'pedder',\n",
       " 'unibasket',\n",
       " 'kizartmas',\n",
       " 'kinsky',\n",
       " 'osmin',\n",
       " 'scafeld',\n",
       " 'mutahir',\n",
       " 'eupalinos',\n",
       " 'podunkowice',\n",
       " 'ofrequired',\n",
       " 'berbera',\n",
       " 'iolani',\n",
       " 'savonarola',\n",
       " 'tadminster',\n",
       " 'vreanna',\n",
       " 'cabourg',\n",
       " 'microhockey',\n",
       " 'kentridge',\n",
       " 'vezir',\n",
       " 'nahariya',\n",
       " 'dinard',\n",
       " 'borsig',\n",
       " 'palmaria',\n",
       " 'erlenborn',\n",
       " 'gauve',\n",
       " 'kutchins',\n",
       " 'galim',\n",
       " 'royko',\n",
       " 'mrinal',\n",
       " 'marathas',\n",
       " 'riph',\n",
       " 'greuze',\n",
       " 'panzar',\n",
       " 'tramuntana',\n",
       " 'langmuir',\n",
       " 'workshared',\n",
       " 'hersheimmer',\n",
       " 'gododdin',\n",
       " 'lolani',\n",
       " 'ataterk',\n",
       " 'clienteligible',\n",
       " 'mauryas',\n",
       " 'fwi',\n",
       " 'ptolemies',\n",
       " 'louisian',\n",
       " 'voth',\n",
       " 'tuileries',\n",
       " 'barogue',\n",
       " 'srivijaya',\n",
       " 'stephanopoulos',\n",
       " 'nabatean',\n",
       " 'disaffecting',\n",
       " 'kadifekale',\n",
       " 'czarek',\n",
       " 'javis',\n",
       " 'melroseabbey',\n",
       " 'adversisers',\n",
       " 'stramongate',\n",
       " 'xiaoping',\n",
       " 'empaling',\n",
       " 'exley',\n",
       " 'cucci',\n",
       " 'perestrelo',\n",
       " 'meydane',\n",
       " 'geffen',\n",
       " 'kelase',\n",
       " 'nonautomated',\n",
       " 'fhwa',\n",
       " 'hcfa',\n",
       " 'kogen',\n",
       " 'crose',\n",
       " 'gpra',\n",
       " 'adbul',\n",
       " 'espalmador',\n",
       " 'mccalpinmaria',\n",
       " 'caletta',\n",
       " 'ramseys',\n",
       " 'kinneret',\n",
       " 'ombo',\n",
       " 'adrin',\n",
       " 'zefat',\n",
       " 'miramax',\n",
       " 'haussmann',\n",
       " 'formentor',\n",
       " 'territoriy',\n",
       " 'yagoda',\n",
       " 'pmsd',\n",
       " 'recultivate',\n",
       " 'naturisme',\n",
       " 'wenner',\n",
       " 'egus',\n",
       " 'lydians',\n",
       " 'afterthefact',\n",
       " 'vandemeyer',\n",
       " 'ovitz',\n",
       " 'tonelson',\n",
       " 'fengari',\n",
       " 'suharto',\n",
       " 'dejima',\n",
       " 'probononet',\n",
       " 'swarga',\n",
       " 'nontransportation',\n",
       " 'manacor',\n",
       " 'selimiye',\n",
       " 'smegal',\n",
       " 'montluc',\n",
       " 'apalrc',\n",
       " 'sefat',\n",
       " 'ptolomies',\n",
       " 'michiko',\n",
       " 'pachino',\n",
       " 'huguenots',\n",
       " 'queensferry',\n",
       " 'carbet',\n",
       " 'theodosius',\n",
       " 'financerelated',\n",
       " 'landsburg',\n",
       " 'siddartha',\n",
       " 'akko',\n",
       " 'kakutani',\n",
       " 'archeabacteria',\n",
       " 'marlenheim',\n",
       " 'chowpatty',\n",
       " 'czesiek',\n",
       " 'jamus',\n",
       " 'curnin',\n",
       " 'ptolemaic',\n",
       " 'sarayy',\n",
       " 'bicurei',\n",
       " 'palestrina',\n",
       " 'kulesi',\n",
       " 'tengh',\n",
       " 'nonexchange',\n",
       " 'hsia',\n",
       " 'crotoy',\n",
       " 'camees',\n",
       " 'reigninh',\n",
       " 'usepa',\n",
       " 'worldaid',\n",
       " 'aila',\n",
       " 'madeirans',\n",
       " 'hayey',\n",
       " 'blois',\n",
       " 'preservationalists',\n",
       " 'iversons',\n",
       " 'curros',\n",
       " 'pyrgos',\n",
       " 'lesvos',\n",
       " 'samothrakia',\n",
       " 'gaoas',\n",
       " 'manzanares',\n",
       " 'masr',\n",
       " 'whitebelly',\n",
       " 'massabielle',\n",
       " 'msba',\n",
       " 'citypalace',\n",
       " 'weicker',\n",
       " 'overmechanical',\n",
       " 'tragea',\n",
       " 'wagonheim',\n",
       " 'restoorant',\n",
       " 'minoans',\n",
       " 'tarare',\n",
       " 'esquivel',\n",
       " 'bhuleshwar',\n",
       " 'spproaches',\n",
       " 'nlada',\n",
       " 'friedrick',\n",
       " 'hamzy',\n",
       " 'herrnstein',\n",
       " 'tsim',\n",
       " 'balearics',\n",
       " 'frankenheimer',\n",
       " 'troues',\n",
       " 'suggesetions',\n",
       " 'girgis',\n",
       " 'lumbini',\n",
       " 'zelon',\n",
       " 'brodkeys',\n",
       " 'mailstreams',\n",
       " 'montmarte',\n",
       " 'richelieu',\n",
       " 'vrenna',\n",
       " 'monumentalprotection',\n",
       " 'newhoff',\n",
       " 'cabourge',\n",
       " 'rajabai',\n",
       " 'pallava',\n",
       " 'huaisheng',\n",
       " 'melodio',\n",
       " 'blankley',\n",
       " 'wachter',\n",
       " 'aurangzeb',\n",
       " 'pfitzner',\n",
       " 'raskolnikov',\n",
       " 'postaward',\n",
       " 'cocomo',\n",
       " 'lusadas',\n",
       " 'bhansi',\n",
       " 'krewski',\n",
       " 'ujong',\n",
       " 'reppublica',\n",
       " 'yemenite',\n",
       " 'barenakedino',\n",
       " 'rijksmuseum',\n",
       " 'souveineers',\n",
       " 'kalinga',\n",
       " 'menidia',\n",
       " 'furniure',\n",
       " 'nezu',\n",
       " 'akrotiri',\n",
       " 'lalley',\n",
       " 'alonissos',\n",
       " 'loyala',\n",
       " 'scafelf',\n",
       " 'larut',\n",
       " 'caleornia',\n",
       " 'nabateans',\n",
       " 'cpas',\n",
       " 'liggett',\n",
       " 'punditus',\n",
       " 'samothrace',\n",
       " 'mysidopsis',\n",
       " 'trianon',\n",
       " 'directiions',\n",
       " 'dubliners',\n",
       " 'baryshnikov',\n",
       " 'norquist',\n",
       " 'mastihohoria',\n",
       " 'tsfat',\n",
       " 'laborde',\n",
       " 'tancred',\n",
       " 'dunnes',\n",
       " 'dubbawya',\n",
       " 'heftman',\n",
       " 'sabelhaus',\n",
       " 'bgross',\n",
       " 'vedr',\n",
       " 'keleter',\n",
       " 'castanheiro',\n",
       " 'inglethorp',\n",
       " 'boork',\n",
       " 'pergamene',\n",
       " 'charnock',\n",
       " 'discothyques',\n",
       " 'madrile',\n",
       " 'croteau',\n",
       " 'bonapartists',\n",
       " 'maintenon',\n",
       " 'rehnquist',\n",
       " 'mytilini',\n",
       " 'barnam',\n",
       " 'eisner',\n",
       " 'onardo',\n",
       " 'tegh',\n",
       " 'bendahara',\n",
       " 'cityart',\n",
       " 'croseover',\n",
       " 'knowledgebased',\n",
       " 'geveden',\n",
       " 'smelledof',\n",
       " 'mulhouse',\n",
       " 'beryllina',\n",
       " 'pollentia',\n",
       " 'andratx',\n",
       " 'bedesten',\n",
       " 'kotter',\n",
       " 'tiberias',\n",
       " 'calue',\n",
       " 'riviyre',\n",
       " 'flodden',\n",
       " 'pippens',\n",
       " 'unpompous',\n",
       " 'philipsburg',\n",
       " 'bauerstein',\n",
       " 'carmo',\n",
       " 'nonproselytizing',\n",
       " 'clintonas',\n",
       " 'cowgate',\n",
       " 'lasnny',\n",
       " 'wanniski',\n",
       " 'burnsian',\n",
       " 'paroseas',\n",
       " 'nileometer',\n",
       " 'kingsferry',\n",
       " 'thewlis',\n",
       " 'lambros',\n",
       " 'ceteau',\n",
       " 'hillend',\n",
       " 'aicpa',\n",
       " 'huguenot',\n",
       " 'missenhardt',\n",
       " 'thirasia',\n",
       " 'argentineans',\n",
       " 'parameswara',\n",
       " 'zmuda',\n",
       " 'nepdg',\n",
       " 'dionysos',\n",
       " 'shuger',\n",
       " 'pelee',\n",
       " 'unprepssessing',\n",
       " 'itbased',\n",
       " 'ringwald',\n",
       " 'meriwether',\n",
       " 'alacah',\n",
       " 'lingett',\n",
       " 'pitre',\n",
       " 'trenchtown',\n",
       " 'wealthies',\n",
       " 'boskin',\n",
       " 'deitiesinegyptianmythologyandthis',\n",
       " 'bettelheim',\n",
       " 'vaikuntaperumal',\n",
       " 'battistoni',\n",
       " 'nasire',\n",
       " 'cyprinodon',\n",
       " 'qumran',\n",
       " 'syvres',\n",
       " 'borker',\n",
       " 'rosenblatt',\n",
       " 'fasulye']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0db4802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebbbc3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 5s 37ms/step - loss: 1.1382 - accuracy: 0.3151 - val_loss: 1.1421 - val_accuracy: 0.2952\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 4s 36ms/step - loss: 0.9574 - accuracy: 0.5812 - val_loss: 1.1640 - val_accuracy: 0.3004\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 4s 37ms/step - loss: 0.8440 - accuracy: 0.6860 - val_loss: 1.2003 - val_accuracy: 0.2963\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 4s 37ms/step - loss: 0.7296 - accuracy: 0.7551 - val_loss: 1.2616 - val_accuracy: 0.3015\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 4s 36ms/step - loss: 0.6238 - accuracy: 0.8089 - val_loss: 1.3377 - val_accuracy: 0.2827\n"
     ]
    }
   ],
   "source": [
    "input = keras.Input(shape=(300,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(input)\n",
    "x = Conv1D(128, 3, activation=\"relu\")(embedded_sequences)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "#x = Conv1D(128, 3, activation=\"relu\")(x)\n",
    "#x = GlobalMaxPooling1D()(x)\n",
    "#x = Conv1D(128, 3, activation=\"relu\")(x)\n",
    "#x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "m = Model(inputs=input, outputs=x)\n",
    "m.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "c = m.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a863c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "pr = np.round(m.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26536ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.17515769044153323\n",
      "F1-score [0.28991597 0.11777778 0.20507614]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29       720\n",
      "           1       0.20      0.08      0.12       637\n",
      "           2       0.36      0.14      0.21       704\n",
      "\n",
      "   micro avg       0.29      0.18      0.22      2061\n",
      "   macro avg       0.28      0.17      0.20      2061\n",
      "weighted avg       0.29      0.18      0.21      2061\n",
      " samples avg       0.57      0.18      0.18      2061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, pr))\n",
    "print('F1-score %s' % f1_score(y_test, pr, average=None, zero_division = 1))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,pr,zero_division = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6406f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 4s 33ms/step - loss: 1.1068 - accuracy: 0.3377 - val_loss: 1.1004 - val_accuracy: 0.3347\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 4s 33ms/step - loss: 1.0947 - accuracy: 0.3634 - val_loss: 1.1016 - val_accuracy: 0.3202\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 4s 32ms/step - loss: 1.0873 - accuracy: 0.3813 - val_loss: 1.1100 - val_accuracy: 0.3191\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 4s 33ms/step - loss: 1.0515 - accuracy: 0.4474 - val_loss: 1.1284 - val_accuracy: 0.3222\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 4s 33ms/step - loss: 0.9673 - accuracy: 0.5300 - val_loss: 1.2174 - val_accuracy: 0.3337\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(embedding_dim,), dtype=\"int64\") \n",
    "x   =  embedding_layer(input)\n",
    "#x   =  Dropout(0.2)(x)\n",
    "x   =  Conv1D(100, 3, padding='valid',activation='relu', strides=1)(x)\n",
    "x   =  GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "m1 = Model(inputs=input, outputs=x)\n",
    "m1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "c1 = m1.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "db6fd393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 2s 24ms/step\n"
     ]
    }
   ],
   "source": [
    "pr1 = np.round(m1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "36fb8ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.17467248908296942\n",
      "F1-score [0.10280374 0.25716768 0.28620102]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.06      0.10       720\n",
      "           1       0.29      0.23      0.26       637\n",
      "           2       0.36      0.24      0.29       704\n",
      "\n",
      "   micro avg       0.32      0.17      0.23      2061\n",
      "   macro avg       0.32      0.18      0.22      2061\n",
      "weighted avg       0.32      0.17      0.21      2061\n",
      " samples avg       0.63      0.17      0.17      2061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, pr1))\n",
    "print('F1-score %s' % f1_score(y_test, pr1, average=None, zero_division = 1))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,pr1,zero_division = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162be9f",
   "metadata": {},
   "source": [
    "### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2531c715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121/121 [==============================] - 56s 449ms/step - loss: 1.1025 - accuracy: 0.3374 - val_loss: 1.1009 - val_accuracy: 0.3472\n",
      "Epoch 2/3\n",
      "121/121 [==============================] - 56s 462ms/step - loss: 1.0856 - accuracy: 0.3793 - val_loss: 1.1120 - val_accuracy: 0.3524\n",
      "Epoch 3/3\n",
      "121/121 [==============================] - 56s 467ms/step - loss: 1.0568 - accuracy: 0.4461 - val_loss: 1.0840 - val_accuracy: 0.3773\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(embedding_dim,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x   =  LSTM(100, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x   =  GlobalMaxPool1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "lstm_model = Model(inputs=int_sequences_input, outputs=x)\n",
    "lstm_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "lstm = lstm_model.fit(X_train, y_train, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ec652453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 8s 116ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = np.round(lstm_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "05580519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.07035419699175158\n",
      "F1-score [0.01369863 0.         0.28865979]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.01      0.01       720\n",
      "           1       0.00      0.00      0.00       637\n",
      "           2       0.53      0.20      0.29       704\n",
      "\n",
      "   micro avg       0.52      0.07      0.12      2061\n",
      "   macro avg       0.34      0.07      0.10      2061\n",
      "weighted avg       0.35      0.07      0.10      2061\n",
      " samples avg       0.07      0.07      0.07      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, lstm_pred))\n",
    "print('F1-score %s' % f1_score(y_test, lstm_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11e05596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 111s 869ms/step - loss: 1.1001 - accuracy: 0.3455 - val_loss: 1.1019 - val_accuracy: 0.3482\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 117s 972ms/step - loss: 1.0976 - accuracy: 0.3546 - val_loss: 1.0997 - val_accuracy: 0.3337\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 272s 2s/step - loss: 1.0931 - accuracy: 0.3780 - val_loss: 1.1073 - val_accuracy: 0.3139\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 122s 1s/step - loss: 1.0845 - accuracy: 0.3871 - val_loss: 1.1091 - val_accuracy: 0.3264\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 188s 2s/step - loss: 1.0687 - accuracy: 0.4195 - val_loss: 1.1801 - val_accuracy: 0.3056\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 275s 2s/step - loss: 1.0495 - accuracy: 0.4406 - val_loss: 1.1765 - val_accuracy: 0.2963\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 120s 989ms/step - loss: 1.0174 - accuracy: 0.4710 - val_loss: 1.1905 - val_accuracy: 0.2921\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 110s 912ms/step - loss: 0.9737 - accuracy: 0.5139 - val_loss: 1.2463 - val_accuracy: 0.2921\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 118s 972ms/step - loss: 0.9117 - accuracy: 0.5511 - val_loss: 1.3990 - val_accuracy: 0.2890\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 111s 921ms/step - loss: 0.8663 - accuracy: 0.5768 - val_loss: 1.4819 - val_accuracy: 0.3129\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(embedding_dim,))\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = embedding_layer(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "# Add a classifier\n",
    "x = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model2 = keras.Model(inputs, outputs=x)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "lstm2 = model2.fit(X_train, y_train, epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b9c2dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 16s 214ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = np.round(model2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de13ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.17515769044153323\n",
      "F1-score [0.18423552 0.23518519 0.25160698]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.13      0.18       720\n",
      "           1       0.29      0.20      0.24       637\n",
      "           2       0.36      0.19      0.25       704\n",
      "\n",
      "   micro avg       0.31      0.18      0.22      2061\n",
      "   macro avg       0.31      0.18      0.22      2061\n",
      "weighted avg       0.31      0.18      0.22      2061\n",
      " samples avg       0.18      0.18      0.18      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, pred))\n",
    "print('F1-score %s' % f1_score(y_test, pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ff856f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x25263282c70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAvtUlEQVR4nO3deXxU1fn48c+TyWRPCBBIgAABQRYBQSNKUQyLUhURtD93tKilShVtK7XYr3vrRqvW4lq/FFFLpIq4UfkqGJECCmFXliprwpKwZSH7zPn9cSdkm0ASMrmTmef9es0rc9d5cgj3mXPOveeIMQallFLBK8TuAJRSStlLE4FSSgU5TQRKKRXkNBEopVSQ00SglFJBLtTuABorISHBpKSkNOnY48ePEx0d3bwBtWJaHjVpeVTRsqgpEMojMzPzkDGmg7dtPksEIjIbGAfkGGMGeNmeBnwI7PSsWmCMefxU501JSWHNmjVNiikjI4O0tLQmHRuItDxq0vKoomVRUyCUh4jsrm+bL2sEc4BZwNyT7PO1MWacD2NQSil1Cj7rIzDGLAOO+Or8Simlmof48sliEUkBPjlJ09D7QBawD7jfGPNdPeeZAkwBSExMPDc9Pb1J8RQWFhITE9OkYwORlkdNWh5VtCxqCoTyGDlyZKYxJtXbNjsTQRzgNsYUisjlwF+NMb1Pdc7U1FSjfQTNQ8ujJi2PKv5YFuXl5WRlZVFSUtLin11SUkJERESLf25TREREkJycjNPprLFeROpNBLbdNWSMya/2fpGIvCwiCcaYQ3bFpJTyX1lZWcTGxpKSkoKItOhnFxQUEBsb26Kf2RTGGA4fPkxWVhY9evRo8HG2JQIRSQIOGmOMiAzF6q84bFc8Sin/VlJSYksS8AtFR6BgP7jKwBEGsZ0gql2d3USE9u3bk5ub26jT+/L20XlAGpAgIlnAI4ATwBjzKvAz4C4RqQCKgeuNDoWqlDqJoE0CeXvBuK1lV5m1DPUmg8byWSIwxtxwiu2zsG4vVUopVZ+C/VVJoJJxW+u9JIKm0CEmlFKqgWy5c8hV1rj1TdDqhphQSqmGWLgum5mLt7HvWDGd4yOZPrYPE4Z0sTusxikvrn+bI6zZPkZrBEqpgLNwXTYzFmwi+1gxBsg+VsyMBZtYuC67Wc5vjGH69OkMGDCAgQMH8u677wKwf/9+RowYweDBgxkwYABff/01LpeLn//85yf2ff755xv2IUVHIHc7iAOo1e4vIVaHcTPRGoFSqtV57OPv+H5ffr3b1+05RpmrZrt6cbmL3723kXnf7vF6TP/OcTxy5VkN+vwFCxawfv16NmzYwKFDhzjvvPMYMWIE//znPxk7dix/+MMfcLlcFBUVsX79erKzs9m8eTMAx44dO/nJjRvy98HxXAiLhrY9oLSgQXcNNZUmAqVUwKmdBE61vrGWL1/ODTfcgMPhIDExkYsvvpjVq1dz3nnncdttt1FeXs6ECRMYPHgwPXv2ZMeOHdxzzz1cccUVXHrppfWf2FUOR3dC2XGI7gBxna1v/1HtmvXCX5smAqVUq3Oqb+7Dn15K9rG67etd4iN595fDTvvz67vTfcSIESxbtoxPP/2USZMmMX36dG655RY2bNjA4sWLeemll5g/fz6zZ8+ue3BpIRzdBW4XxHf36YW/Nu0jUEoFnOlj+xDpdNRYF+l0MH1sn2Y5/4gRI3j33XdxuVzk5uaybNkyhg4dyu7du+nYsSO/+MUvuP3221m7di2HDh3C7XZzzTXX8MQTT7B27dqaJzPGagY6/AOIQIczWzQJgNYIlFIBqPLuIF/dNTRx4kRWrlzJ2WefjYjw7LPPkpSUxJtvvsnMmTNxOp3ExMQwd+5csrOzmTx5Mm631Sz11FNPVZ3I7bYeDis+AuFx0LY7hLT8ZVkTgVIqIE0Y0qXZbxctLCwErKd3Z86cycyZM2tsv/XWW7n11lvrHFenFgBQUQpHdkJFMcQmQUySVSOwgSYCpZRqaSX5Vn8AQLueENHG1nA0ESilVEsxBgoPWreChkZCux4QGm53VJoIlFKqRbgr4OhuKM2HyLbQpiuEOE59XAvQRKCUUr5WXmz1B7jKIC4ZohNs6w/wRhOBUkr5UvFROLbHejCsfS8I978pLzURKKWUL1QfKsIZbfUHOJynPs4GmgiUUqq5ucqtu4LKCmsOFeGn/DcypZQ6HRvnw/MD4NF46+fG+S3zuWXHIXcbMd3PtoaKaJNcJwns2rWLAQMGtEw8DaA1AqVU4Nk4Hz6eVjWef95eaxlg0LW++UxjoOgQ5GVbTUCVg8W1ApoIlFKtz79/Dwc21b89azW4SmuuKy+GD++GzDe9H5M0EC57ut5TPvDAA3Tv3p2pU6cC8OijjyIiLFu2jKNHj1JeUsQfp/+Sq8aPt2oCDVRSUsJdd93FmjVrCA0N5bnnnmPkyJF89913TJ48mbKyMtxuN++//z6dO3fm2muvJSsrC5fLxUMPPcR1113X4M+qjyYCpVTgqZ0ETrW+Aa6//nruu+++E4lg/vz5fPbZZ/z6nqnEuQ5z6OA+Lhh/O+NvvRcJaXir+0svvQTApk2b2Lp1K5deeinbt2/n1Vdf5d577+Wmm26irKwMl8vFokWL6Ny5M59++ikAeXl5Tf59qtNEoJRqfU7yzR2w+gTy9tZd36YrTP60SR85ZMgQcnJy2LdvH7m5ubRt25ZObaP59bRfseybtYQ4w8nef4CDOTkkJSU1+LzLly/nnnvuAaBv3750796d7du3M2zYMP70pz+RlZXF1VdfTe/evRk4cCD3338/DzzwAOPGjeOiiy5q0u9Sm3YWK6UCz+iHwRlZc50z0lp/Gn72s5/x3nvv8W56OtdPuJx33phF7pE8MjMzWb9hE4mJiZSUlDTqnPXNbXDjjTfy0UcfERkZydixY1m6dClnnnkmmZmZDBw4kBkzZvD444+f1u9TSROBUirwDLoWrnzRqgEg1s8rXzztjuLrr7+e9PR5vDc/nZ+NOY+8Ejcdu56BMzKWL7/8kt27dzf6nCNGjOCdd94BYPv27ezZs4c+ffqwY8cOevbsybRp0xg/fjwbN25k3759REVFcfPNN3P//fd7H9W0CXzWNCQis4FxQI4xpt77pETkPGAVcJ0x5j1fxaOUCjKDrm32O4TOOrMnBUcP0yUxgU69B3NT8hCuHD+e1NRUBg8eTN++fRt9zqlTp3LnnXcycOBAQkNDmTNnDuHh4bz77ru8/fbbOJ1OkpKSePjhh1m9ejXTp08nJCQEp9PJK6+80iy/ly/7COYAs4C59e0gIg7gGWCxD+NQSqmmKToCBfuJcZXB8VBwu9j05fvWhPLhMSTEwMqVK70eWjl3gTcpKSknJrOPiIhgzpw5dfaZMWMGM2bMqLFu7NixjB07tum/Tz181jRkjFkGHDnFbvcA7wM5vopDKaWapOiI1eHsKkPAGj0UY00g44fjBZ0O2+4aEpEuwERgFHCeXXEopZRXBfut8YJqO54DMR0adIpNmzYxadKkGuvCw8P55ptvmiPCZiP19Vg3y8lFUoBPvPURiMi/gL8YY1aJyBzPfl77CERkCjAFIDEx8dz09PQmxVNYWEhMTGBl8tOh5VGTlkcVfyyLNm3acMYZZyAtNHxzTMEPePskAxTG9mqRGJrCGMOPP/5Y5xmDkSNHZhpjUr0dY2ci2AknyjkBKAKmGGMWnuycqampZs2aNU2KJyMjg7S0tCYdG4i0PGrS8qjij2Wxc+dOYmNjad++fcskgwObwV1ed70jDBLP8v3nN4ExhsOHD1NQUECPHj1qbBORehOBbU1DxpgTUVarESy0Kx6llH9LTk4mKyuL3Nxc33+YMVCQUzcRiEBkOziyxfcxNFFERATJycmNOsaXt4/OA9KABBHJAh4BnADGmFd99blKqcDkdDrrfMv1mWV/hqVPwHl3wPbFmLwspE2y9UDaoEtbJoYW5LNEYIy5oRH7/txXcSilVKPs3wAZT8FZV8MVf4Er/sJXfthU1pz0yWKllKpUXgILfglRCVYSCBI66JxSSlX68o+QuwVuer/VzCXQHLRGoJRSALuWw4pZkHob9B5jdzQtShOBUkqV5MPCu6wJ5i/9o93RtDhtGlJKqcUzIC8LblsMYdF2R9PitEaglApuWz+FdW/Dhb+GrkPtjsYWmgiUUsGrMBc+mmbNV3zx7+2OxjbaNKSUCk7GwCf3QWk+TPwYQsPsjsg2WiNQSgWnDfNg6yfW08KJ/e2OxlaaCJRSwefYHlj0O+g+HC6Yanc0ttNEoJQKLm43LJwKGJjwCoQ47I7IdtpHoJQKLt+8Aru+hvGzoG13u6PxC1ojUEoFj5yt8MVj0OdyGHKz3dH4DU0ESqngUFEGH0yB8Fi48q/W3AIK0KYhpVSwWDbTGmL6urchpqPd0fgVrREopQJf1hr4+i9w9o3Q70q7o/E7mgiUUoGtrAgWTIG4znDZ03ZH45e0aUgpFdg+fxiO/Ai3fgwRbeyOxi9pjUApFbh+WAKr/w4X/Ap6jLA7Gr+liUApFZiKj8KHv4KEPjD6Ibuj8WvaNKSUCkyf3g/Hc+GGdHBG2h2NX9MagVIq8Gx+Hza/Zw0t3Xmw3dH4PU0ESqnAkr8fPvkNdEm1JptRp+SzRCAis0UkR0Q217P9KhHZKCLrRWSNiFzoq1iUUkHCGPjobqgohYmvgUNbvxvClzWCOcBPT7J9CXC2MWYwcBvwhg9jUUoFgzWz4Ycv4NInIKGX3dG0Gj5LBMaYZcCRk2wvNMYYz2I0YOrbVymlTunwj/B//wM9R8J5d9gdTatiax+BiEwUka3Ap1i1AqWUajxXBXxwJzicMOFlHVCukaTqS7kPTi6SAnxijBlwiv1GAA8bY8bUs30KMAUgMTHx3PT09CbFU1hYSExMTJOODURaHjVpeVRpbWXRbfd79Nz5Ft/3+y05ic3/4FhrKw9vRo4cmWmMSfW2zS8SgWffncB5xphDJ9svNTXVrFmzpknxZGRkkJaW1qRjA5GWR01aHlVaVVns3wh/HwX9xsHP/uGT2kCrKo96iEi9icC2piER6SVi/YuJyDlAGHDYrniUUq1QeQl88EuIag9XPKdNQk3ks3urRGQekAYkiEgW8AjgBDDGvApcA9wiIuVAMXCd8WX1RCkVeL78I+R8Dze9B1Ht7I6m1fJZIjDG3HCK7c8Az/jq85VSAW7Xf2DFLEi9DXpfYnc0rZo+WayUan1K8mHhndA2BS55wu5oWj197E4p1fosngF5WTD5Mwhv3Xfz+AOtESilWpeti2Dd2zD8Puh2vt3RBARNBEqp1uP4Ifh4GiQOhLQZdkcTMLRpSCnVOhgDH98LJXlwy0cQGmZ3RAFDawRKqdZhwzzY+gmMeggS+9sdTUDRRKCU8n/H9sC/H4Duw2HYr+yOJuBoIlBK+Te3GxZOBeO2BpQLcdgdUcDRPgKllH/75lXY9TWMn2U9N6CanSYCpZT/2TgfljxuPSuAgaRBMORmu6MKWNo0pJTyLxvnW7eI5u3lxHxVh7bDpn/ZGlYg00SglPIvSx6H8uKa6ypKrPXKJzQRKKX8R2GOpybgRV5Wy8YSRLSPQCllv5I8WPE3WPly/fu0SW65eIKMJgKllH3Ki+Hbv8Py56D4KJw1ETqfCxl/qtk85IyE0Q/bF2eA00SglGp5rgpY/w5kPA0F++CM0daFvvNga3tsYtVdQ22SrW2DrrU15ECmiUAp1XKMge8/hKVPwOEfoEsqXP0a9Kg14fyga/XC34I0ESilfM8Y2PElfPEY7F8PHfrCde9A3yt0nmE/oIlAKeVbWZmw5FHYuQzadIUJr8Cg63SoCD+iiUAp5Rs5W60moK2fQFQC/PQZSJ0MoeF2R6Zq0USglGpex/ZYncAb5oEzGtIehGFTITzW7shUPTQRKKWax/FD8PVfYPUbgMAFU+HC30B0e7sjU6egiUApdXpK8mHlS7ByFpQXweAb4eLfQ3xXuyNTDaSJQCnVNOUlsGY2fP1nKDoM/cbDqP+BDn3sjkw1ks8SgYjMBsYBOcaYAV623wQ84FksBO4yxmzwVTxKqWbiqoCN6fDlU5CfBT0uhtGPQPK5dkemmsiXNYI5wCxgbj3bdwIXG2OOishlwOvA+T6MRyl1Ooyx7gBa8gQc2gadh8BVs+CMkXZHpk6TzxKBMWaZiKScZPuKaourAB1RSil/teMrWPIYZGdC+95w7VyrKUgfBgsIYow59U4i0UCxMcYtImcCfYF/G2PKT3FcCvCJt6ahWvvdD/Q1xtxRz/YpwBSAxMTEc9PT008ZszeFhYXExMQ06dhApOVRk5YHdDz4FT13vEV4aS6l4R3YlzSG+PwttDu6npLw9uxKuZGDiSMxQfYwWCD8bYwcOTLTGJPqbVtDE0EmcBHQFuvb+xqgyBhz0ymOS+EUiUBERgIvAxcaYw6fKpbU1FSzZs2aU8bsTUZGBmlpaU06NhBpedQU9OVROTNY7UlhnNEw8kE47w5wRtgTm80C4W9DROpNBA1tGhJjTJGI3A78zRjzrIisa4bABgFvAJc1JAkopZpRaQEc3Q1Hd1mvjKfqJgGAyHj4yd0tHJxqSQ1OBCIyDLgJuL2Rx9Z3wm7AAmCSMWb76ZxLqdPimSj94rwsWBdAQx67XZC/r+pCX/tVdKhh58nf56sIlZ9o6MX8PmAG8IEx5jsR6Ql8ebIDRGQekAYkiEgW8AjgBDDGvAo8DLQHXharw6mivmqLUj5TrTlEwJom8eNp1raWTgaehNSoMfhL8mpd4Kt9wz+2B9zVuvHEYT3k1TbFGvWzbUrN12sjvE8TqTODBbwGJQJjzFfAVwAiEgIcMsZMO8UxN5xi+x2A185hpVqMt4nSy4vh099CwQFrZqzQcAiNtNrHQz3LzkgIjfCyPaJpo2rWbp+vTEhuN3S/oP5v9cVHa54nsq11Ue80CPqPr3mhj0sGx0n+y49+uG4fgc4MFhQalAhE5J/AnYALyATaiMhzxpiZvgxOKZ+rb0L00nz4/KGmnTPEWS1ReJKD16RRLamsf8d7Qlr4y1rnDoX4btaFvfOQmhf6+O5We35TVdY+ljyOyctCdGawoNHQpqH+xph8z9PAi7CeCM4ENBGo1qn4GHw2A6jnrrk2yTB1lTWMQoXnVV5c7X0JVBRDRWnV+nLPckWx9+2Vx5Xk1TpvidVxW5/xszwX++4Q18W34/h7Zgb7KgDuklEN19BE4BQRJzABmGWMKReRU993qpQ/+uEL+PAeKDwIfS63Zs6q0xzyiDVscksNnfz8gHra57vCOZNaJgYVtEIauN9rwC4gGlgmIt2BfF8FpZRPlBbAR9Pg7WusC/wdn8MN8+DKF6FNVwxiXXivfLHlm0NGP2wloOq0fV61kIZ2Fr8IvFht1W7Pg2BKtQ47voIP77a+df9kGoz8Q9XDUf7QHFKtfb5Rdw0p1Qwa2lncBuv2zxGeVV8BjwN5PopLqeZRWghfPAqr/w7tzoDbFkM3Px3b0JOQlGppDe0jmA1sBir/SicB/wCu9kVQSjWL3Stg4V3WvfUXTIVRD0FYlN1RKeV3GpoIzjDGXFNt+TERWe+DeJQ6feXFVhPLqlesO21+/imkDLc7KqX8VkMTQbGIXGiMWQ4gIsMBL4OSKGWzvath4Z1w+AdrkLQxj0F46x41Uilfa2giuBOY6+krADgK3OqbkJRqgvISyHgSVvzNutd+0kKdMEWpBmroXUMbgLNFJM6znC8i9wEbfRibUg2TvdbqC8jdCufcApf+CSLi7I5KqVajoc8RAFYCMMZUPj/wGx/Eo1TDVZTB0j/CG2OgJB9ueh/G/02TgFKNdDpDSescdco++zdatYCDm+HsG+GnT53eODtKBbHTSQQ6xIRqea5yWP48fPUMRLWH6+dB38vtjkqpVu2kiUBECvB+wRcg0st6pXzn4PdWLWD/ehjwM7h8JkS1szsqpVq9kyYCY0wLjbil1Em4KmDFi9ZUiuGxcO1c6H+V3VEpFTBOa7pJpXwud7tVC8heA/3GwxXPQUwHu6NSKqBoIlD+ye2CVS/DkiesYSGu+V8YcA2I3qOgVHPTRKD8z+EfYeFU2LvKmi9g3AsQm2h3VEoFLE0Eyn+43dYooZ8/Ao4wmPgaDLpOawFK+ZgmAmWfjfOrxt+PTYLwODi0DXpdAuNfhLjOdkeoVFDQRBCMPBfgi/OyYJ1NE6BsnA8fT6uaIrJgv/U65xZrhjCtBSjVYoIjEfjDhc8fGAPr3oJF06GixHo0PG+vNXPX/k3Q/QJwV1gPbbld4C6vZ7nC+tmkZZd1vn1rwVVWN8Yfv9QkoFQL81kiEJHZwDggxxgzwMv2vliT25wD/MEY82efBLJxPhUf3kOoq+rCV/HhPdYvbse34OaairC8GIqOQPFRKPb8rLN8tOZy8VHvF19XKax80Xo1hjjA4YSQ0KqX12UHhDirlkPDvMcBVtkopVqUL2sEc4BZwNx6th8BpgETfBgDRf9+mChXSY11oa4Syj7+LWEleZ4LldPqnHSE1nzvCPMsV39f+fKyLcRR/7fZagkJqEpI7go4Y1Q9F/Lqy8dqLleUeP8cAEe49cRtZDuIbAsJva2fke3gPy/Uc5DAlIwGXtg970/nm/vzA6zaSG1tkpt+TqVUk/gsERhjlolIykm25wA5InKFr2IAiCg+4HV9WHk+LLq/WT/LILhDQjHixDicmJBQTEgYhIQSenwfocZVY/9QV4n1sFR9QpyeC7rnIt42BboMqVqObFtze+Wy8ySjf2x+v/4LcOfBTfq9m2T0wzX7CMCKe/TDLReDUgpoJX0EIjIFmAKQmJhIRkZGg4/t5W5PcsihOuv3udvxUPwz4K5A3BWIsdqvrfcuxJQT4nYhxkWIsfZxGGubgwqcuHBSQSgVhOEilAqcUn29q+q9uJgYstfreK3GwOPuyRwPiaUoJIYiRywljhhKHbEYRwThoUK4EcJLIcwlhBdDuEMId1T/WU644yDhjhzCHFjHOCAsBKTWt/ZjkRO59NirRElV00yRCeP/IicS34hyPX0d6djrLnrueIvw0kOUhiewo+ckco50hBaNo0phYWGj/rYCmZZFTYFeHq0iERhjXgdeB0hNTTVpaWkNPvbR5Tfzu/KX61z4Xg+7hf/9TdPa540xlLsM5S435S43ZS43ZRXuE+us99Zy5fvsfw4jWeompGyTAEN/QUiZ68RLyitwl7koLnNxqNRFUZmL4rIKisorMI0Y81UEIp0OosIcRIY5iHKGsuPQMJaaCn4XOp/Ocph9pj3PVlzLsoMX8exFfWkfE0a76HDaRYcRFxFaJ5E0rzTgEQAigP6el10yMjJozN9WINOyqCnQy6NVJILTMfiKKTz8QQX3mfQTF74XuJ4Lr5jS5HOKCGGhQlhow+f1eTTMe0J6I+xmHr3yrAadwxhDaYWbojIXRWUVFJe5PO9dFJdXVL0vq5Y8ylwUlVeuq2DbwQI+4kI+Kruw5smLy5nyVmaNVU6H0DYqjHbRVa/20Z5EEVP5vupnfFQYjpCGJ46F67KZuXgb+44V0zk+kulj+zBhSJcGH6+Uah4BnwisC8tUrls8muxjxXSx6YLTHAlJRIhwOohwOmgXHdakOIY/vZTsY8V11ifGhfPGLedx+HgpR46XceR4GYePl3Gk0PPzeCmbs/M4cryM/JKKeuKDtlFhtI1y0t5Tq6ieMKykYa1fveswT/17KyXlbgCyjxUzY8EmAE0GSrUwX94+Og+r7p8gIllYbQBOAGPMqyKSBKwB4gC3Zw7k/tWmwmw2E4Z0YcKQLrZW76onJDu/AU8f24cZCzZRXF7VcR3pdDDjsn4MTG7ToHOUu9wcrUwUJxJGadV7z88fcgs5squMo0VlDWrSKi538ejH39GtfRQ9E6KJj2paslNKNY4v7xq64RTbDwBBda9gZUKyOwaAmYu3NbmG5HSE0DEugo5xEQ3a3+U25BWXc+R4KYcLrURx1ztrve57rKicq19eAUDbKCc9O8TQIyGanh2i6ZkQTc8OMXRrF0WE09HgeJVSJxfwTUOqrpauITlC5ETTUK+O1rou8ZFem6g6xobz5MSB7Dx0nB2HCtmRe5xl23N5L7PqQTMR6/ieHWI8ySGaHgnWq3ObSEIa0U+hlNJEoGxSXxPVg5f3Y0z/ukNOF5SUs+tQ0YnkUJkoMncd4XhZ1TnCQ0NO1CCs5BBzojZRX1NTZad19rFiuqxaqp3WKuhoIlC2qN5E1ZA+k9gIJwOT29TpxzDGkFtQyo+VySG3kJ2HjrN1fwGLvzuIy13VOdEuOuxEzaEyOew8dJy/LvmvdlqroKaJQNmmOfpMROREf8WwM9rX2FbucrP3SFG1GoSVKGo3NdVWXO7iyUVbuPLszo26HVap1koTgQpYTkeI1Y/QIabOtsqmpitnLfd6bE5BKQMeWcyZSbH0S4qlX6c4+nWKo09SLG0inb4OXakWpYlABaXKpqb6Oq3jo5xcPSSZLfvz+ey7A6SvrhqfqUt8JP06VSWHvkmxdG8frbUH1WppIlBBrb5O60evPOtEs5UxhoP5pWzZn8+WA/ls2V/Alv35LN2aQ2UXRKTTQZ+k2BoJok9SLHERWntQ/k8TgQpqDXmuQkRIahNBUpsIRvbteGJ9SbmL/x4s9CQH67Vo0wHmfVtVe0huG2klBk/zUt9OcXRvF+X1FlcdckPZRROBCnpNfa4iwumocyeTMYYD+SWexFBwIkEs2XLwRO0hKsyqPfRNiqO/pwbxQ04Bj3285UTNRO9eUi1JE4FSzUhE6NQmkk5tIhnVt+p5iJJyF9sPFtRIEJ9u3Me8b72P2wTW3UszF2/TRKB8ThOBUi0gwulgUHI8g5LjT6wzxrA/z6o93P7mGq/HZR8rZsv+fPomxfp4SHAVzDQRKGUTEaFzfCSd4yPrvXsJ4LK/fk2X+Egu6Z/ImH6JDO3RrlFDoCt1KpoIlPID9Y4Ke3kfwkMdfP59Dumr9zBnxS5iw0O5uE8HLumfSNqZHWkTpXcmqdOjiUApP3CqITeuO68bxWUu/vPDIb7YcpAvtuTwycb9OEKEoSntGNM/kUv6JdKtfZSdv4ZqpTQRKOUnTjXkRmSYgzH9ExnTPxG327Ah65iVFL7P4YlPvueJT77nzMQYxvRL5JL+iZydHK8jsaoG0USgVCsUEiIM6daWId3aMn1sX/YcLvLUFA7y2rIdvJzxIwkx4Yzp15Ex/RIZ3iuByDCdw0F5p4lAqQDQrX0Ut13Yg9su7EFeUTkZ23P4YksOn27cT/rqvUQ4Q7iwVwcu6d+RUX0T6RAbbnfIyo9oIlAqwLSJcnLV4C5cNbgLZRVuVu86wuffH+Tz760ag8gmBneNP9GE1LtjzIlbU3VuhuCkiUCpABYWGsLwXgkM75XAI1f2Z+uBAr7wJISZi7cxc/E2urWLYky/RCLCQpi9fKfOzRCENBEoFSRE5MSAePeM7s3B/BKWbMnhiy0Hefub3ZRVuOsco083BwdNBEoFqcS4CG48vxs3nt+NorIK+j+82Ot+++p50E0FDn08USlFVFgoXeIjvW4zwB1vrmHZ9lzc1ab+VIFDE4FSCrCebo501rzFNDw0hEv6dWTdnqPcMvtbRv0lgze+3sGxojKbolS+4LOmIRGZDYwDcowxA7xsF+CvwOVAEfBzY8xaX8WjlDq5k83NUFrh4rPNB3h71W7++OkWZi7exlWDOzPpgpQaw3Cr1smXfQRzgFnA3Hq2Xwb09rzOB17x/FRK2aS+uRnCQx0nbkn9fl8+b3+zm4Xrspm/Jouzu8Yz6YLujBvUiQinPrTWGvmsacgYsww4cpJdrgLmGssqIF5EOvkqHqVU8+jfOY4nJw5k1YOjeWz8WRwvreD+f23ggqeW8NSiLew5XGR3iKqRxBjfdf6ISArwST1NQ58ATxtjlnuWlwAPGGPqDMwuIlOAKQCJiYnnpqenNymewsJCYmJimnRsINLyqEnLo0pjysIYw9YjbpbsKWdtjgtjYGCCg1HdQhnUwUFIAMyjEAh/GyNHjsw0xqR622bn7aPe/jq8ZiVjzOvA6wCpqammMdMJVtfYqQgDnZZHTVoeVRpbFiOBu4ADeSWkr97DP7/ZwwtrS0luG8lN53fj2tRk2se03mEtAv1vw867hrKArtWWk4F9NsWilGoGSW0iuG/Mmfzn96N4+aZz6No2imc+28qwp5by63fXk7n7KL5shVBNY2eN4CPgbhFJx+okzjPG7LcxHqVUM3E6Qrh8YCcuH9iJ/x4s4J1v9vB+ZhYfrMumf6c4Jg3rzlWDOxMVps+0+gOf1QhEZB6wEugjIlkicruI3Ckid3p2WQTsAH4A/g5M9VUsSin79E6M5dHxZ7HqwdH8aeIA3MYwY8Emzn9yCY99/B0/5hbaHWLQ81k6NsbccIrtBviVrz5fKeVfosNDuen87tw4tBuZu4/y1qrdvL1qN//4zy6G92rPpAu6M6ZfIqGOkBOjoHqbrU01P62XKaValIiQmtKO1JR2/M8V/Zm/Zi/vrNrNnW+vJSkugiHd4vlyaw4lFToKakvRISaUUrbpEBvOr0b24usHRvH3W1I5MymWf28+cCIJVKocBVX5hiYCpZTtHCHCJf0TmXvbUK/3lYOOgupLmgiUUn6lcz2joMZGhFJS7mrhaIKDJgKllF/xNgpqiEB+SQWXPr+ML74/qM8iNDNNBEopvzJhSBeeunogXeIjEaBLfCTPXTuYt24fitMh3DF3DZPnrGaH3nbabPSuIaWU36kcBbW2z+4bwZsrdvHCF/9l7AvLuO3CHtwzqjcx4XopOx1aI1BKtRpORwh3XNSTpfdfzFWDu/DaVzsY9ecMFq7L1uai06CJQCnV6nSMjeDP/+9sFkz9iTW+0bvr+X+vrmRzdp7dobVKmgiUUq3WOd3asnDqcJ65ZiA7Dx3nylnL+cMHmzh6XKfSbAxNBEqpVi0kRLjuvG4svT+NW4elkL56L2l/zuCtlbtwubW5qCE0ESilAkKbSCePjj+LRdMuol+nWB768DvG/W053+482USJCjQRKKUCTJ+kWOb94gJeuvEc8orKuPa1lUybt44DeSV2h+a3NBEopQKOiHDFoE588duLmTaqF599d4BRf8ng5YwfKK3Qp5Nr00SglApYUWGh/ObSPnzx64sZ3iuBZz/bxtjnl7F060G7Q/MrmgiUUgGvW/so/n5LKm/eNpSQEOG2OWu4bc5qdh06bndofkETgVIqaFx8Zgc+u3cED17el292HObS55fx7GdbOV5aYXdottJEoJQKKmGhIUwZcQZf3p/GuEGdeDnjR0b/5Ss+XB+8TydrIlBKBaWOcRE8d91g3r9rGAmxYdybvp7rXlvF9/vy7Q6txWkiUEoFtXO7t+PDX13IkxMH8t+cAsb97WseWriZY0VlLFyXzfCnl/Lzz44z/OmlLFyXbXe4PqFD9imlgp4jRLjx/G5cMbATz32+jbdW7ea9zL1UuA3lLqu5KJDnTtYagVJKebSJcvLYVQP4dNpFuNycSAKVAnXuZE0ESilVS79OcZS73F63BeLcyT5NBCLyUxHZJiI/iMjvvWxvKyIfiMhGEflWRAb4Mh6llGqo+uZORuDpf28lO4ASgs8SgYg4gJeAy4D+wA0i0r/Wbg8C640xg4BbgL/6Kh6llGoMb3Mnh4WGMLBLHK8v+5ERz37J1Hcy+XbnkVZ/26kvO4uHAj8YY3YAiEg6cBXwfbV9+gNPARhjtopIiogkGmP0+W+llK0qO4RnLt5G9rFiusRHMn1sHyYM6ULW0SLeWrWb9G/3smjTAc7qHMfPf5LClWd3JqJW8mgNxFeZTER+BvzUGHOHZ3kScL4x5u5q+zwJRBhjfiMiQ4EVnn0ya51rCjAFIDEx8dz09PQmxVRYWEhMTEyTjg1EWh41aXlU0bKoqb7yKHUZVu6r4PPd5WQXGmLDIK2rk1FdQ2kb4V9dsCNHjsw0xqR62+bLGoF4WVc76zwN/FVE1gObgHVAnWe9jTGvA68DpKammrS0tCYFlJGRQVOPDURaHjVpeVTRsqjpZOUxFnjEGFb8eJh//GcXn2w9yL93VnDZwE5MHp7COd3atmisTeHLRJAFdK22nAzsq76DMSYfmAwgIgLs9LyUUqrVEBGG90pgeK8Edh8+ztyVu5m/ei8fb9jH2V3jmfyTFC4f2ImwUP+qJVTyZVSrgd4i0kNEwoDrgY+q7yAi8Z5tAHcAyzzJQSmlWqXu7aN5aFx/Vj04msevOouC4nLue3c9w59ZygtfbCe3oNTuEOvwWY3AGFMhIncDiwEHMNsY852I3OnZ/irQD5grIi6sTuTbfRWPUkq1pOjwUG4ZlsLN53dn2X9zmbNiFy988V9e/vJHxg3qxOThPRiY3MbuMAEfDzFhjFkELKq17tVq71cCvX0Zg1JK2SkkREjr05G0Ph3ZkVvImyt28V5mFgvWZXNu97ZMHp7C2LOScDrsazbSsYaUUqqF9OwQw2NXDeC3Y/vwrzVZvLliF3f/cx1JcRFMGtadG4Z2o1102KlP1Mz8s+dCKaUCWFyEk9sv7MGX96fxxi2p9OoYw8zF27jgqSX87r0NLT4UttYIlFLKJo4QYUz/RMb0T2T7wQLmrNjFgrVZzF+Txfk92jF5eA8u6Z/Ixxv2MXPxNvYdK6ZztQfbmosmAqWU8gNnJsby5MSB/G5sH95dvZe5K3dz59uZxEc6KSytoMLtu+GwtWlIKaX8SHxUGL+8+Ay+mp7GqzefQ1GZ60QSqNTcw2FrIlBKKT8U6gjhpwM6tchw2JoIlFLKj9U3HHa9w2Q3gSYCpZTyY96Gw450Opg+tk+zfYZ2FiullB+rPhy23jWklFJBasKQLs164a9Nm4aUUirIaSJQSqkgp4lAKaWCnCYCpZQKcpoIlFIqyPls8npfEZFcYHcTD08ADjVjOK2dlkdNWh5VtCxqCoTy6G6M6eBtQ6tLBKdDRNYYY1LtjsNfaHnUpOVRRcuipkAvD20aUkqpIKeJQCmlglywJYLX7Q7Az2h51KTlUUXLoqaALo+g6iNQSilVV7DVCJRSStWiiUAppYJc0CQCEfmpiGwTkR9E5Pd2x2MnEekqIl+KyBYR+U5E7rU7JruJiENE1onIJ3bHYjcRiReR90Rkq+dvZJjdMdlFRH7t+T+yWUTmiUiE3TH5QlAkAhFxAC8BlwH9gRtEpL+9UdmqAvitMaYfcAHwqyAvD4B7gS12B+En/gp8ZozpC5xNkJaLiHQBpgGpxpgBgAO43t6ofCMoEgEwFPjBGLPDGFMGpANX2RyTbYwx+40xaz3vC7D+o/tusHM/JyLJwBXAG3bHYjcRiQNGAP8LYIwpM8YcszUoe4UCkSISCkQB+2yOxyeCJRF0AfZWW84iiC981YlICjAE+MbmUOz0AvA7wPss4cGlJ5AL/MPTVPaGiETbHZQdjDHZwJ+BPcB+IM8Y83/2RuUbwZIIxMu6oL9vVkRigPeB+4wx+XbHYwcRGQfkGGMy7Y7FT4QC5wCvGGOGAMeBoOxTE5G2WC0HPYDOQLSI3GxvVL4RLIkgC+habTmZAK3iNZSIOLGSwDvGmAV2x2Oj4cB4EdmF1WQ4SkTetjckW2UBWcaYyhrie1iJIRiNAXYaY3KNMeXAAuAnNsfkE8GSCFYDvUWkh4iEYXX4fGRzTLYREcFqA95ijHnO7njsZIyZYYxJNsakYP1dLDXGBOS3voYwxhwA9opIH8+q0cD3NoZkpz3ABSIS5fk/M5oA7TgPisnrjTEVInI3sBir53+2MeY7m8Oy03BgErBJRNZ71j1ojFlkX0jKj9wDvOP50rQDmGxzPLYwxnwjIu8Ba7HutFtHgA41oUNMKKVUkAuWpiGllFL10ESglFJBThOBUkoFOU0ESikV5DQRKKVUkNNEoFQtIuISkfXVXs32ZK2IpIjI5uY6n1LNISieI1CqkYqNMYPtDkKplqI1AqUaSER2icgzIvKt59XLs767iCwRkY2en9086xNF5AMR2eB5VQ5P4BCRv3vGuf8/EYm07ZdSCk0ESnkTWatp6Lpq2/KNMUOBWVijluJ5P9cYMwh4B3jRs/5F4CtjzNlY4/VUPs3eG3jJGHMWcAy4xqe/jVKnoE8WK1WLiBQaY2K8rN8FjDLG7PAM2nfAGNNeRA4BnYwx5Z71+40xCSKSCyQbY0qrnSMF+NwY09uz/ADgNMb8sQV+NaW80hqBUo1j6nlf3z7elFZ770L76pTNNBEo1TjXVfu50vN+BVVTGN4ELPe8XwLcBSfmRI5rqSCVagz9JqJUXZHVRmUFa/7eyltIw0XkG6wvUTd41k0DZovIdKzZvSpH67wXeF1Ebsf65n8X1kxXSvkV7SNQqoE8fQSpxphDdseiVHPSpiGllApyWiNQSqkgpzUCpZQKcpoIlFIqyGkiUEqpIKeJQCmlgpwmAqWUCnL/H6DqqAKT7Bb9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lstm2.history['loss'], label='loss', marker = 'o')\n",
    "plt.plot(lstm2.history['val_loss'], label = 'val_loss', marker = 'o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36e200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
