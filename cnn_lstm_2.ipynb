{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8293d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "import spacy\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f851c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df168f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Input\n",
    "from keras.layers import Embedding \n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalMaxPool1D\n",
    "from keras.layers import LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3583b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f7bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6574e0",
   "metadata": {},
   "source": [
    "## Bags of words embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa99c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('train.csv',encoding ='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f952fa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>lang_abv</th>\n",
       "      <th>language</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5130fd2cb5</td>\n",
       "      <td>and these comments were considered in formulat...</td>\n",
       "      <td>The rules developed in the interim were put to...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5b72532a0b</td>\n",
       "      <td>These are issues that we wrestle with in pract...</td>\n",
       "      <td>Practice groups are not permitted to work on t...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5622f0c60b</td>\n",
       "      <td>you know they can't really defend themselves l...</td>\n",
       "      <td>They can't defend themselves because of their ...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fdcd1bd867</td>\n",
       "      <td>From Cockpit Country to St. Ann's Bay</td>\n",
       "      <td>From St. Ann's Bay to Cockpit Country.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7cfb3d272c</td>\n",
       "      <td>Look, it's your skin, but you're going to be i...</td>\n",
       "      <td>The boss will fire you if he sees you slacking...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12115</th>\n",
       "      <td>2b78e2a914</td>\n",
       "      <td>The results of even the most well designed epi...</td>\n",
       "      <td>All studies have the same amount of uncertaint...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12116</th>\n",
       "      <td>7e9943d152</td>\n",
       "      <td>But there are two kinds of  the pleasure of do...</td>\n",
       "      <td>But there are two kinds of the pleasure of doi...</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12117</th>\n",
       "      <td>5085923e6c</td>\n",
       "      <td>The important thing is to realize that it's wa...</td>\n",
       "      <td>It cannot be moved, now or ever.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12118</th>\n",
       "      <td>fc8e2fd1fe</td>\n",
       "      <td>At the west end is a detailed model of the who...</td>\n",
       "      <td>The model temple complex is at the east end.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12119</th>\n",
       "      <td>44301dfb14</td>\n",
       "      <td>For himself he chose Atat??rk, or Father of th...</td>\n",
       "      <td>Ataturk was the father of the Turkish nation.</td>\n",
       "      <td>en</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6870 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                            premise  \\\n",
       "0      5130fd2cb5  and these comments were considered in formulat...   \n",
       "1      5b72532a0b  These are issues that we wrestle with in pract...   \n",
       "3      5622f0c60b  you know they can't really defend themselves l...   \n",
       "7      fdcd1bd867              From Cockpit Country to St. Ann's Bay   \n",
       "8      7cfb3d272c  Look, it's your skin, but you're going to be i...   \n",
       "...           ...                                                ...   \n",
       "12115  2b78e2a914  The results of even the most well designed epi...   \n",
       "12116  7e9943d152  But there are two kinds of  the pleasure of do...   \n",
       "12117  5085923e6c  The important thing is to realize that it's wa...   \n",
       "12118  fc8e2fd1fe  At the west end is a detailed model of the who...   \n",
       "12119  44301dfb14  For himself he chose Atat??rk, or Father of th...   \n",
       "\n",
       "                                              hypothesis lang_abv language  \\\n",
       "0      The rules developed in the interim were put to...       en  English   \n",
       "1      Practice groups are not permitted to work on t...       en  English   \n",
       "3      They can't defend themselves because of their ...       en  English   \n",
       "7                 From St. Ann's Bay to Cockpit Country.       en  English   \n",
       "8      The boss will fire you if he sees you slacking...       en  English   \n",
       "...                                                  ...      ...      ...   \n",
       "12115  All studies have the same amount of uncertaint...       en  English   \n",
       "12116  But there are two kinds of the pleasure of doi...       en  English   \n",
       "12117                   It cannot be moved, now or ever.       en  English   \n",
       "12118       The model temple complex is at the east end.       en  English   \n",
       "12119      Ataturk was the father of the Turkish nation.       en  English   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          2  \n",
       "3          0  \n",
       "7          2  \n",
       "8          1  \n",
       "...      ...  \n",
       "12115      2  \n",
       "12116      0  \n",
       "12117      2  \n",
       "12118      2  \n",
       "12119      0  \n",
       "\n",
       "[6870 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# english data set\n",
    "df_en = dt.loc[dt['lang_abv'] == 'en']\n",
    "df_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617d3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#english x\n",
    "x_p = df_en.premise.values\n",
    "x_h =  df_en.hypothesis.values\n",
    "#english y \n",
    "y = df_en.label.values\n",
    "# split train and test\n",
    "x_train_p, x_test_p,x_train_h,x_test_h, y_train, y_test = train_test_split(x_p,x_h, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40a8e550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Crosethe Rue de Rivoli to the Palais-Royal, built for Car?\\xaddi?\\xadnal Richelieu as his Paris residence in 1639, and originally named Palais-Cardinal. Cardinal Richelieu was a wealthy man who worked diligently for the Catholic church.',\n",
       "       \"If I had chosen to be an actor, I should have been the greatest actor living!  I chose to become an actor, but I wasn't very good at it. \",\n",
       "       'Poor Dave, she said. She was happy for Dave.', ...,\n",
       "       'Troyes is also a center for shopping, with two outlet centers selling both French and international designer-name fashions and home accessories. There are three outlet centers in Troyes, all of which sell only French fashions.',\n",
       "       'Children will enjoy the little steam train that loops around the bay to Le Crotoy in the summer. There is a steam train looping around the bay to Le Crotoy.',\n",
       "       'They said that (1) agencies need to be able to design their procedures to fit their particular circumstances (e.g. The authors of the recently introduced bill stated each agency would be required to match their operational methods to their particular situations.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train_p +' '+x_train_h\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f93e654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, ..., 2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5bd1a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok = [word_tokenize(sentence) for sentence in x_train]\n",
    "X_train_tok = [[word.lower() for word in s]for s in X_train_tok]\n",
    "X_train_tok = [[word for word in s if word.isalpha()]for s in X_train_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd0209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "for l in X_train_tok:\n",
    "    for i in l:\n",
    "        text.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37cebe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = set(text)\n",
    "text1 =list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b67c3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model constants.\n",
    "max_features = len(text1)+2\n",
    "embedding_dim = 128\n",
    "sequence_length = 100\n",
    "\n",
    "\n",
    "def custom_slpit(input_data):\n",
    "    return tf.strings.split(input_data)\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    vocabulary = text1,\n",
    "    output_mode=\"int\",\n",
    "    ngrams = None,\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "#vectorize_layer.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "889f7a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'puglia',\n",
       " 'fancifully',\n",
       " 'disruptions',\n",
       " 'disturbed',\n",
       " 'lesson',\n",
       " 'leathery',\n",
       " 'elusive',\n",
       " 'install',\n",
       " 'candles',\n",
       " 'niche',\n",
       " 'giving',\n",
       " 'years',\n",
       " 'trouble',\n",
       " 'effects',\n",
       " 'se',\n",
       " 'unconstrained',\n",
       " 'pray',\n",
       " 'announcing',\n",
       " 'surely',\n",
       " 'gradually',\n",
       " 'twist',\n",
       " 'blades',\n",
       " 'insemination',\n",
       " 'characters',\n",
       " 'experts',\n",
       " 'deposition',\n",
       " 'acknowledge',\n",
       " 'fasulye',\n",
       " 'chloroform',\n",
       " 'beg',\n",
       " 'biological',\n",
       " 'kidder',\n",
       " 'already',\n",
       " 'asians',\n",
       " 'pertaining',\n",
       " 'neighboring',\n",
       " 'gifts',\n",
       " 'grand',\n",
       " 'deal',\n",
       " 'actual',\n",
       " 'italians',\n",
       " 'pennsylvania',\n",
       " 'industry',\n",
       " 'calcutta',\n",
       " 'recommitted',\n",
       " 'seattle',\n",
       " 'perspiration',\n",
       " 'distributors',\n",
       " 'outcomes',\n",
       " 'breath',\n",
       " 'crashed',\n",
       " 'imbued',\n",
       " 'seriously',\n",
       " 'believe',\n",
       " 'professional',\n",
       " 'increasing',\n",
       " 'cute',\n",
       " 'rowlett',\n",
       " 'obscurity',\n",
       " 'unsure',\n",
       " 'reached',\n",
       " 'locations',\n",
       " 'cloud',\n",
       " 'dracula',\n",
       " 'educators',\n",
       " 'lost',\n",
       " 'typical',\n",
       " 'version',\n",
       " 'second',\n",
       " 'requester',\n",
       " 'hud',\n",
       " 'enlisted',\n",
       " 'tee',\n",
       " 'goats',\n",
       " 'exhort',\n",
       " 'dinners',\n",
       " 'reiterating',\n",
       " 'landing',\n",
       " 'fingerprints',\n",
       " 'grease',\n",
       " 'traffic',\n",
       " 'microphone',\n",
       " 'imagine',\n",
       " 'capable',\n",
       " 'exceed',\n",
       " 'equate',\n",
       " 'enclave',\n",
       " 'metzger',\n",
       " 'herb',\n",
       " 'discount',\n",
       " 'boca',\n",
       " 'dance',\n",
       " 'scuba',\n",
       " 'meaning',\n",
       " 'rotting',\n",
       " 'demonstrates',\n",
       " 'devotees',\n",
       " 'unattractive',\n",
       " 'troupe',\n",
       " 'dynamic',\n",
       " 'frequent',\n",
       " 'logical',\n",
       " 'liberated',\n",
       " 'domination',\n",
       " 'allegations',\n",
       " 'contemporary',\n",
       " 'halt',\n",
       " 'lets',\n",
       " 'scene',\n",
       " 'working',\n",
       " 'definition',\n",
       " 'keep',\n",
       " 'unanimous',\n",
       " 'globalization',\n",
       " 'villas',\n",
       " 'gambolling',\n",
       " 'motionlessly',\n",
       " 'attracted',\n",
       " 'equipped',\n",
       " 'carnot',\n",
       " 'wives',\n",
       " 'malfunction',\n",
       " 'who',\n",
       " 'poured',\n",
       " 'winding',\n",
       " 'eight',\n",
       " 'sample',\n",
       " 'evacuate',\n",
       " 'transported',\n",
       " 'slightly',\n",
       " 'manoa',\n",
       " 'tank',\n",
       " 'cybernetics',\n",
       " 'grow',\n",
       " 'escaped',\n",
       " 'rocky',\n",
       " 'case',\n",
       " 'fireworks',\n",
       " 'texas',\n",
       " 'filipa',\n",
       " 'bulls',\n",
       " 'efficiency',\n",
       " 'texans',\n",
       " 'internationally',\n",
       " 'look',\n",
       " 'civic',\n",
       " 'save',\n",
       " 'perched',\n",
       " 'means',\n",
       " 'jolly',\n",
       " 'undesirable',\n",
       " 'detected',\n",
       " 'skillet',\n",
       " 'airplanes',\n",
       " 'reppublica',\n",
       " 'molecule',\n",
       " 'evening',\n",
       " 'bodhi',\n",
       " 'terminally',\n",
       " 'undefended',\n",
       " 'informational',\n",
       " 'tegh',\n",
       " 'railroad',\n",
       " 'loads',\n",
       " 'correlation',\n",
       " 'pausing',\n",
       " 'tougher',\n",
       " 'accidents',\n",
       " 'holden',\n",
       " 'regime',\n",
       " 'spaceships',\n",
       " 'principles',\n",
       " 'breathe',\n",
       " 'died',\n",
       " 'forefront',\n",
       " 'demonstrations',\n",
       " 'evil',\n",
       " 'library',\n",
       " 'grasse',\n",
       " 'governing',\n",
       " 'depicted',\n",
       " 'powerful',\n",
       " 'bannisters',\n",
       " 'therein',\n",
       " 'allocations',\n",
       " 'steepled',\n",
       " 'de',\n",
       " 'risks',\n",
       " 'colleges',\n",
       " 'inpatient',\n",
       " 'anxious',\n",
       " 'deborah',\n",
       " 'landsburg',\n",
       " 'ghosting',\n",
       " 'studded',\n",
       " 'palace',\n",
       " 'pause',\n",
       " 'corbett',\n",
       " 'produces',\n",
       " 'ken',\n",
       " 'visitors',\n",
       " 'georgia',\n",
       " 'agenda',\n",
       " 'pantheon',\n",
       " 'prototyping',\n",
       " 'author',\n",
       " 'raves',\n",
       " 'interestingly',\n",
       " 'stick',\n",
       " 'opponents',\n",
       " 'women',\n",
       " 'reputedly',\n",
       " 'putting',\n",
       " 'remained',\n",
       " 'culpable',\n",
       " 'premises',\n",
       " 'lucky',\n",
       " 'denominations',\n",
       " 'acts',\n",
       " 'imposing',\n",
       " 'enlighten',\n",
       " 'era',\n",
       " 'appraised',\n",
       " 'collections',\n",
       " 'carlyle',\n",
       " 'identical',\n",
       " 'tsui',\n",
       " 'cowboy',\n",
       " 'omen',\n",
       " 'throughout',\n",
       " 'signs',\n",
       " 'henry',\n",
       " 'increase',\n",
       " 'tactics',\n",
       " 'camped',\n",
       " 'salt',\n",
       " 'most',\n",
       " 'surveys',\n",
       " 'pilots',\n",
       " 'sight',\n",
       " 'cafes',\n",
       " 'cliches',\n",
       " 'bell',\n",
       " 'prevent',\n",
       " 'curros',\n",
       " 'departure',\n",
       " 'supplements',\n",
       " 'establishing',\n",
       " 'akrotiri',\n",
       " 'heal',\n",
       " 'medieval',\n",
       " 'forth',\n",
       " 'electricity',\n",
       " 'theorists',\n",
       " 'several',\n",
       " 'transformation',\n",
       " 'announced',\n",
       " 'southern',\n",
       " 'epidemiological',\n",
       " 'dismounted',\n",
       " 'diving',\n",
       " 'chennai',\n",
       " 'purge',\n",
       " 'assigning',\n",
       " 'montluc',\n",
       " 'symbols',\n",
       " 'iberian',\n",
       " 'journalism',\n",
       " 'coveted',\n",
       " 'meats',\n",
       " 'sparse',\n",
       " 'herculean',\n",
       " 'appreciate',\n",
       " 'musical',\n",
       " 'contract',\n",
       " 'citizens',\n",
       " 'trio',\n",
       " 'appropriated',\n",
       " 'bridge',\n",
       " 'safari',\n",
       " 'allow',\n",
       " 'signed',\n",
       " 'hamilton',\n",
       " 'examines',\n",
       " 'terrific',\n",
       " 'governmentwide',\n",
       " 'shinto',\n",
       " 'disastrous',\n",
       " 'doug',\n",
       " 'kate',\n",
       " 'representatives',\n",
       " 'recommend',\n",
       " 'crimean',\n",
       " 'monument',\n",
       " 'staffing',\n",
       " 'counsel',\n",
       " 'cyclical',\n",
       " 'loops',\n",
       " 'establishment',\n",
       " 'neighbourhoods',\n",
       " 'jumping',\n",
       " 'photographed',\n",
       " 'planning',\n",
       " 'choir',\n",
       " 'deitiesinegyptianmythologyandthis',\n",
       " 'diagram',\n",
       " 'sheltered',\n",
       " 'targeted',\n",
       " 'vanguard',\n",
       " 'cons',\n",
       " 'versa',\n",
       " 'bargaining',\n",
       " 'regulation',\n",
       " 'garnered',\n",
       " 'body',\n",
       " 'ramseys',\n",
       " 'destined',\n",
       " 'jensen',\n",
       " 'george',\n",
       " 'carved',\n",
       " 'narthex',\n",
       " 'ruling',\n",
       " 'pitch',\n",
       " 'transfers',\n",
       " 'carnegie',\n",
       " 'time',\n",
       " 'hottest',\n",
       " 'inventions',\n",
       " 'apartment',\n",
       " 'weak',\n",
       " 'compromise',\n",
       " 'urine',\n",
       " 'outlawing',\n",
       " 'lead',\n",
       " 'fat',\n",
       " 'mentality',\n",
       " 'kingsferry',\n",
       " 'warlocks',\n",
       " 'suzie',\n",
       " 'concepts',\n",
       " 'fwi',\n",
       " 'outlaw',\n",
       " 'incompetent',\n",
       " 'nixon',\n",
       " 'wisconsin',\n",
       " 'extremely',\n",
       " 'bush',\n",
       " 'interchange',\n",
       " 'write',\n",
       " 'age',\n",
       " 'intends',\n",
       " 'axe',\n",
       " 'runs',\n",
       " 'telephones',\n",
       " 'eric',\n",
       " 'bounced',\n",
       " 'ipm',\n",
       " 'directed',\n",
       " 'resultant',\n",
       " 'stayed',\n",
       " 'severely',\n",
       " 'humiliated',\n",
       " 'marching',\n",
       " 'ethnic',\n",
       " 'divan',\n",
       " 'pokemon',\n",
       " 'galilee',\n",
       " 'arizona',\n",
       " 'copies',\n",
       " 'accommodating',\n",
       " 'airy',\n",
       " 'asia',\n",
       " 'negev',\n",
       " 'embody',\n",
       " 'shoguns',\n",
       " 'aims',\n",
       " 'grows',\n",
       " 'lusitania',\n",
       " 'conservative',\n",
       " 'staying',\n",
       " 'date',\n",
       " 'nickel',\n",
       " 'morally',\n",
       " 'end',\n",
       " 'worries',\n",
       " 'hi',\n",
       " 'ribbon',\n",
       " 'tomatoes',\n",
       " 'rides',\n",
       " 'honor',\n",
       " 'azt',\n",
       " 'cbs',\n",
       " 'partners',\n",
       " 'derry',\n",
       " 'role',\n",
       " 'rigid',\n",
       " 'oldest',\n",
       " 'shave',\n",
       " 'tiering',\n",
       " 'antonio',\n",
       " 'pants',\n",
       " 'flourish',\n",
       " 'telling',\n",
       " 'auto',\n",
       " 'services',\n",
       " 'suitcase',\n",
       " 'opinions',\n",
       " 'territoriy',\n",
       " 'newly',\n",
       " 'cesar',\n",
       " 'failing',\n",
       " 'pad',\n",
       " 'heroin',\n",
       " 'settling',\n",
       " 'hustle',\n",
       " 'nkow',\n",
       " 'voth',\n",
       " 'omb',\n",
       " 'manacor',\n",
       " 'chimneys',\n",
       " 'comply',\n",
       " 'zen',\n",
       " 'worse',\n",
       " 'country',\n",
       " 'notre',\n",
       " 'ile',\n",
       " 'divisions',\n",
       " 'tom',\n",
       " 'defensive',\n",
       " 'horsemen',\n",
       " 'epidemic',\n",
       " 'sabah',\n",
       " 'gosh',\n",
       " 'car',\n",
       " 'lift',\n",
       " 'cadences',\n",
       " 'indeed',\n",
       " 'negotiations',\n",
       " 'mademoiselle',\n",
       " 'showrooms',\n",
       " 'pursuit',\n",
       " 'ecology',\n",
       " 'paradise',\n",
       " 'unlocked',\n",
       " 'colonize',\n",
       " 'debatable',\n",
       " 'picked',\n",
       " 'huffington',\n",
       " 'german',\n",
       " 'curbing',\n",
       " 'thann',\n",
       " 'overhead',\n",
       " 'terminal',\n",
       " 'ingredient',\n",
       " 'randolph',\n",
       " 'dispatched',\n",
       " 'rsa',\n",
       " 'woven',\n",
       " 'collectors',\n",
       " 'beatty',\n",
       " 'fraud',\n",
       " 'qualities',\n",
       " 'enthused',\n",
       " 'size',\n",
       " 'rectangular',\n",
       " 'later',\n",
       " 'pollutants',\n",
       " 'misconduct',\n",
       " 'possum',\n",
       " 'youre',\n",
       " 'investigated',\n",
       " 'exemption',\n",
       " 'cosmopolitan',\n",
       " 'crumbled',\n",
       " 'monumentalprotection',\n",
       " 'note',\n",
       " 'wasted',\n",
       " 'identified',\n",
       " 'determination',\n",
       " 'prepare',\n",
       " 'vigorous',\n",
       " 'nezu',\n",
       " 'invokes',\n",
       " 'singing',\n",
       " 'commitment',\n",
       " 'harder',\n",
       " 'governments',\n",
       " 'morals',\n",
       " 'deviations',\n",
       " 'seekers',\n",
       " 'oliver',\n",
       " 'swore',\n",
       " 'suicide',\n",
       " 'solutions',\n",
       " 'resounding',\n",
       " 'successfully',\n",
       " 'clubs',\n",
       " 'walloped',\n",
       " 'sprinkled',\n",
       " 'smarter',\n",
       " 'california',\n",
       " 'tapa',\n",
       " 'arnold',\n",
       " 'emit',\n",
       " 'annual',\n",
       " 'garrison',\n",
       " 'less',\n",
       " 'abolished',\n",
       " 'associate',\n",
       " 'minors',\n",
       " 'lewisville',\n",
       " 'majestic',\n",
       " 'backpacking',\n",
       " 'department',\n",
       " 'execute',\n",
       " 'family',\n",
       " 'recipients',\n",
       " 'prisoner',\n",
       " 'coda',\n",
       " 'rubles',\n",
       " 'incorrect',\n",
       " 'stared',\n",
       " 'possibilities',\n",
       " 'mann',\n",
       " 'allowing',\n",
       " 'betrayal',\n",
       " 'yankee',\n",
       " 'steady',\n",
       " 'sofas',\n",
       " 'cef',\n",
       " 'stacks',\n",
       " 'torrent',\n",
       " 'stabilize',\n",
       " 'confident',\n",
       " 'nationalizing',\n",
       " 'addictive',\n",
       " 'capabilities',\n",
       " 'commercial',\n",
       " 'consistent',\n",
       " 'struck',\n",
       " 'sculptures',\n",
       " 'hinges',\n",
       " 'decorated',\n",
       " 'hawaii',\n",
       " 'neck',\n",
       " 'hamon',\n",
       " 'apple',\n",
       " 'newton',\n",
       " 'underneath',\n",
       " 'courtroom',\n",
       " 'perestrelo',\n",
       " 'carrer',\n",
       " 'adventurous',\n",
       " 'developing',\n",
       " 'trails',\n",
       " 'ago',\n",
       " 'endemic',\n",
       " 'wto',\n",
       " 'wray',\n",
       " 'enormous',\n",
       " 'good',\n",
       " 'auditing',\n",
       " 'pleasantly',\n",
       " 'poppies',\n",
       " 'coalition',\n",
       " 'die',\n",
       " 'contingent',\n",
       " 'doe',\n",
       " 'overstaying',\n",
       " 'enormously',\n",
       " 'hut',\n",
       " 'sampled',\n",
       " 'orang',\n",
       " 'subsidy',\n",
       " 'dollar',\n",
       " 'grotto',\n",
       " 'glowing',\n",
       " 'midland',\n",
       " 'mandarin',\n",
       " 'hop',\n",
       " 'filters',\n",
       " 'kph',\n",
       " 'devoid',\n",
       " 'pub',\n",
       " 'whitewashed',\n",
       " 'dunfermline',\n",
       " 'mccalpinmaria',\n",
       " 'gory',\n",
       " 'suggested',\n",
       " 'solution',\n",
       " 'may',\n",
       " 'idled',\n",
       " 'milwaukee',\n",
       " 'thank',\n",
       " 'implied',\n",
       " 'beaubourg',\n",
       " 'shipyards',\n",
       " 'ft',\n",
       " 'plush',\n",
       " 'stronger',\n",
       " 'simply',\n",
       " 'valuable',\n",
       " 'involved',\n",
       " 'tv',\n",
       " 'signal',\n",
       " 'relaxing',\n",
       " 'drums',\n",
       " 'primitive',\n",
       " 'liveliest',\n",
       " 'jack',\n",
       " 'legacy',\n",
       " 'spots',\n",
       " 'smile',\n",
       " 'summers',\n",
       " 'muslims',\n",
       " 'enlarging',\n",
       " 'admissions',\n",
       " 'automatic',\n",
       " 'symmetrical',\n",
       " 'tales',\n",
       " 'plain',\n",
       " 'conceivable',\n",
       " 'lived',\n",
       " 'gaiety',\n",
       " 'beijing',\n",
       " 'occupied',\n",
       " 'longest',\n",
       " 'teams',\n",
       " 'me',\n",
       " 'flesh',\n",
       " 'poverty',\n",
       " 'getting',\n",
       " 'cultural',\n",
       " 'silent',\n",
       " 'savour',\n",
       " 'encouraged',\n",
       " 'would',\n",
       " 'palaces',\n",
       " 'horribly',\n",
       " 'galleries',\n",
       " 'stoops',\n",
       " 'pistols',\n",
       " 'inventors',\n",
       " 'guardian',\n",
       " 'alsatian',\n",
       " 'trucking',\n",
       " 'launched',\n",
       " 'convenient',\n",
       " 'doing',\n",
       " 'pp',\n",
       " 'personification',\n",
       " 'outlay',\n",
       " 'itemize',\n",
       " 'jumped',\n",
       " 'temples',\n",
       " 'huntington',\n",
       " 'closing',\n",
       " 'forest',\n",
       " 'steeple',\n",
       " 'sinatra',\n",
       " 'khas',\n",
       " 'receipt',\n",
       " 'constitutes',\n",
       " 'speaking',\n",
       " 'arts',\n",
       " 'solvency',\n",
       " 'functionary',\n",
       " 'giuliana',\n",
       " 'vt',\n",
       " 'shabby',\n",
       " 'complete',\n",
       " 'efficient',\n",
       " 'affirms',\n",
       " 'formentor',\n",
       " 'strain',\n",
       " 'its',\n",
       " 'vaunted',\n",
       " 'souveineers',\n",
       " 'rant',\n",
       " 'zas',\n",
       " 'dungeons',\n",
       " 'van',\n",
       " 'length',\n",
       " 'incident',\n",
       " 'tracks',\n",
       " 'trail',\n",
       " 'minor',\n",
       " 'showcases',\n",
       " 'weightlessness',\n",
       " 'buckley',\n",
       " 'budget',\n",
       " 'get',\n",
       " 'unremarkable',\n",
       " 'al',\n",
       " 'usage',\n",
       " 'puppet',\n",
       " 'capabilites',\n",
       " 'flip',\n",
       " 'visigoths',\n",
       " 'launch',\n",
       " 'assaults',\n",
       " 'simultaneously',\n",
       " 'repeated',\n",
       " 'solar',\n",
       " 'tempore',\n",
       " 'south',\n",
       " 'exchanged',\n",
       " 'weirdly',\n",
       " 'household',\n",
       " 'capture',\n",
       " 'charming',\n",
       " 'expanded',\n",
       " 'committed',\n",
       " 'madrid',\n",
       " 'analysts',\n",
       " 'mold',\n",
       " 'roth',\n",
       " 'constitute',\n",
       " 'acknowledgement',\n",
       " 'huge',\n",
       " 'kennedy',\n",
       " 'missouri',\n",
       " 'bullets',\n",
       " 'scottish',\n",
       " 'accounts',\n",
       " 'estuaries',\n",
       " 'implementing',\n",
       " 'unearthed',\n",
       " 'stealing',\n",
       " 'contrast',\n",
       " 'pattern',\n",
       " 'hindus',\n",
       " 'distributed',\n",
       " 'trojan',\n",
       " 'ones',\n",
       " 'allies',\n",
       " 'coal',\n",
       " 'equipment',\n",
       " 'asssess',\n",
       " 'group',\n",
       " 'clothes',\n",
       " 'evidence',\n",
       " 'stream',\n",
       " 'knew',\n",
       " 'prioritized',\n",
       " 'creature',\n",
       " 'ever',\n",
       " 'participated',\n",
       " 'daytime',\n",
       " 'limited',\n",
       " 'guard',\n",
       " 'yanomamo',\n",
       " 'devised',\n",
       " 'came',\n",
       " 'exploring',\n",
       " 'peripheral',\n",
       " 'killers',\n",
       " 'tauted',\n",
       " 'rainbow',\n",
       " 'explains',\n",
       " 'strategic',\n",
       " 'scr',\n",
       " 'thousands',\n",
       " 'similarly',\n",
       " 'escalating',\n",
       " 'consist',\n",
       " 'absorbed',\n",
       " 'acceptances',\n",
       " 'anticipated',\n",
       " 'impression',\n",
       " 'escaping',\n",
       " 'dive',\n",
       " 'manhattan',\n",
       " 'granada',\n",
       " 'bowling',\n",
       " 'entrants',\n",
       " 'pieces',\n",
       " 'community',\n",
       " 'wacky',\n",
       " 'pushed',\n",
       " 'jail',\n",
       " 'unemployed',\n",
       " 'hilarious',\n",
       " 'breadth',\n",
       " 'varanasi',\n",
       " 'bandwagon',\n",
       " 'because',\n",
       " 'climbing',\n",
       " 'bhakti',\n",
       " 'grander',\n",
       " 'shepherd',\n",
       " 'studying',\n",
       " 'belongs',\n",
       " 'relinquish',\n",
       " 'banned',\n",
       " 'bread',\n",
       " 'able',\n",
       " 'resemble',\n",
       " 'institution',\n",
       " 'secret',\n",
       " 'lush',\n",
       " 'singh',\n",
       " 'glyph',\n",
       " 'spotted',\n",
       " 'buddhism',\n",
       " 'hair',\n",
       " 'sits',\n",
       " 'asserting',\n",
       " 'soleil',\n",
       " 'broaden',\n",
       " 'loopholes',\n",
       " 'castle',\n",
       " 'current',\n",
       " 'depicting',\n",
       " 'sentimental',\n",
       " 'bomb',\n",
       " 'statues',\n",
       " 'add',\n",
       " 'geometry',\n",
       " 'divorce',\n",
       " 'harbour',\n",
       " 'implant',\n",
       " 'strictly',\n",
       " 'amphitheatre',\n",
       " 'stimulant',\n",
       " 'doubling',\n",
       " 'constituted',\n",
       " 'privacy',\n",
       " 'flemish',\n",
       " 'employer',\n",
       " 'valueable',\n",
       " 'prize',\n",
       " 'again',\n",
       " 'bill',\n",
       " 'overlying',\n",
       " 'lilac',\n",
       " 'thirds',\n",
       " 'innocents',\n",
       " 'recovery',\n",
       " 'nodded',\n",
       " 'hobby',\n",
       " 'presenting',\n",
       " 'turban',\n",
       " 'carefully',\n",
       " 'pets',\n",
       " 'unprepssessing',\n",
       " 'harvelle',\n",
       " 'frees',\n",
       " 'trace',\n",
       " 'hard',\n",
       " 'fries',\n",
       " 'story',\n",
       " 'relates',\n",
       " 'benchmarked',\n",
       " 'unintended',\n",
       " 'paints',\n",
       " 'conversation',\n",
       " 'diminished',\n",
       " 'does',\n",
       " 'picnic',\n",
       " 'vampires',\n",
       " 'mahal',\n",
       " 'someday',\n",
       " 'bangladesh',\n",
       " 'wake',\n",
       " 'espresso',\n",
       " 'striving',\n",
       " 'elaborate',\n",
       " 'destiny',\n",
       " 'skin',\n",
       " 'they',\n",
       " 'always',\n",
       " 'lecherous',\n",
       " 'sparkling',\n",
       " 'geezers',\n",
       " 'process',\n",
       " 'senior',\n",
       " 'counseling',\n",
       " 'attest',\n",
       " 'context',\n",
       " 'animation',\n",
       " 'martyrdom',\n",
       " 'secures',\n",
       " 'supervise',\n",
       " 'ra',\n",
       " 'risk',\n",
       " 'says',\n",
       " 'japan',\n",
       " 'dune',\n",
       " 'exercise',\n",
       " 'game',\n",
       " 'ritual',\n",
       " 'roadblock',\n",
       " 'vicious',\n",
       " 'vase',\n",
       " 'goes',\n",
       " 'poll',\n",
       " 'hikes',\n",
       " 'spill',\n",
       " 'born',\n",
       " 'jann',\n",
       " 'normality',\n",
       " 'archaebacteria',\n",
       " 'rolling',\n",
       " 'nave',\n",
       " 'moni',\n",
       " 'production',\n",
       " 'russell',\n",
       " 'fixing',\n",
       " 'dagger',\n",
       " 'spices',\n",
       " 'application',\n",
       " 'mary',\n",
       " 'leaves',\n",
       " 'chanted',\n",
       " 'flow',\n",
       " 'reference',\n",
       " 'steal',\n",
       " 'weeks',\n",
       " 'quotes',\n",
       " 'finger',\n",
       " 'prospered',\n",
       " 'sister',\n",
       " 'supplement',\n",
       " 'meydane',\n",
       " 'rushed',\n",
       " 'knife',\n",
       " 'left',\n",
       " 'squeeze',\n",
       " 'curious',\n",
       " 'wolfe',\n",
       " 'wounds',\n",
       " 'policy',\n",
       " 'academic',\n",
       " 'npd',\n",
       " 'fewer',\n",
       " 'blame',\n",
       " 'dignitaries',\n",
       " 'beresford',\n",
       " 'prosecutors',\n",
       " 'eilat',\n",
       " 'brocade',\n",
       " 'corners',\n",
       " 'communication',\n",
       " 'budge',\n",
       " 'assembly',\n",
       " 'shuttering',\n",
       " 'bustle',\n",
       " 'lawyering',\n",
       " 'gary',\n",
       " 'want',\n",
       " 'wolves',\n",
       " 'p',\n",
       " 'apology',\n",
       " 'blessing',\n",
       " 'abstinence',\n",
       " 'continues',\n",
       " 'vienna',\n",
       " 'shapes',\n",
       " 'parameswara',\n",
       " 'francis',\n",
       " 'chews',\n",
       " 'calling',\n",
       " 'veal',\n",
       " 'envy',\n",
       " 'jetty',\n",
       " 'can',\n",
       " 'innocence',\n",
       " 'sequences',\n",
       " 'communicated',\n",
       " 'normandy',\n",
       " 'harmless',\n",
       " 'bar',\n",
       " 'tutor',\n",
       " 'fund',\n",
       " 'grey',\n",
       " 'sarayy',\n",
       " 'surfeit',\n",
       " 'panels',\n",
       " 'angels',\n",
       " 'somebody',\n",
       " 'privileges',\n",
       " 'rationality',\n",
       " 'sheepshead',\n",
       " 'milo',\n",
       " 'unaddressed',\n",
       " 'incriminating',\n",
       " 'transformed',\n",
       " 'alter',\n",
       " 'circumference',\n",
       " 'sacrilegious',\n",
       " 'capitalized',\n",
       " 'leader',\n",
       " 'interventions',\n",
       " 'comparatively',\n",
       " 'raising',\n",
       " 'undiminished',\n",
       " 'siphon',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67a9a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p = vectorize_layer(x_train_p)\n",
    "X_test_p = vectorize_layer(x_test_p)\n",
    "X_train_h = vectorize_layer(x_train_h)\n",
    "X_test_h = vectorize_layer(x_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de038c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((X_train_p,X_train_h))\n",
    "X_test = np.hstack((X_test_p,X_test_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36d17927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4809, 200)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb44f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to OHE \n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test  = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3700ad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A integer input for vocab indices.\n",
    "inputs = Input(shape=(200,), dtype=\"int64\")\n",
    "\n",
    "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
    "# 'embedding_dim'.\n",
    "x = Embedding(max_features, embedding_dim)(inputs)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# Conv1D + global max pooling\n",
    "x = Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "x = layers.Dense(3, activation=\"softmax\", name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs=x)\n",
    "\n",
    "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "366aba13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121/121 [==============================] - 6s 45ms/step - loss: 1.1001 - accuracy: 0.3296 - val_loss: 1.0965 - val_accuracy: 0.3680\n",
      "Epoch 2/3\n",
      "121/121 [==============================] - 5s 44ms/step - loss: 1.0760 - accuracy: 0.4123 - val_loss: 1.0922 - val_accuracy: 0.3545\n",
      "Epoch 3/3\n",
      "121/121 [==============================] - 5s 44ms/step - loss: 0.7404 - accuracy: 0.6914 - val_loss: 1.3904 - val_accuracy: 0.3368\n"
     ]
    }
   ],
   "source": [
    "cnn = model.fit(X_train, y_train, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ac6689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_pred = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4189188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.2678311499272198\n",
      "F1-score [0.19562955 0.32145685 0.36273115]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.13      0.20       703\n",
      "           1       0.34      0.30      0.32       667\n",
      "           2       0.36      0.37      0.36       691\n",
      "\n",
      "   micro avg       0.35      0.27      0.30      2061\n",
      "   macro avg       0.35      0.27      0.29      2061\n",
      "weighted avg       0.35      0.27      0.29      2061\n",
      " samples avg       0.27      0.27      0.27      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, cnn_pred))\n",
    "print('F1-score %s' % f1_score(y_test, cnn_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5867c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(200,), dtype=\"int64\") \n",
    "x   =  Embedding(max_features, embedding_dim)(input)\n",
    "#x   =  Dropout(0.2)(x)\n",
    "x   =  Conv1D(100, 3, padding='valid',activation='relu', strides=1)(x)\n",
    "x   =  GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model1 = Model(inputs=input, outputs=x)\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e031d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121/121 [==============================] - 5s 35ms/step - loss: 1.0989 - accuracy: 0.3434 - val_loss: 1.0987 - val_accuracy: 0.3056\n",
      "Epoch 2/3\n",
      "121/121 [==============================] - 4s 35ms/step - loss: 1.0757 - accuracy: 0.4073 - val_loss: 1.1018 - val_accuracy: 0.3306\n",
      "Epoch 3/3\n",
      "121/121 [==============================] - 4s 35ms/step - loss: 0.9276 - accuracy: 0.5760 - val_loss: 1.2172 - val_accuracy: 0.3015\n"
     ]
    }
   ],
   "source": [
    "cnn1 = model1.fit(X_train, y_train, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1bc14964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_pred1 = np.round(model1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab86ec01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.16302765647743814\n",
      "F1-score [0.12351029 0.19657349 0.30881017]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.08      0.12       703\n",
      "           1       0.25      0.16      0.20       667\n",
      "           2       0.41      0.25      0.31       691\n",
      "\n",
      "   micro avg       0.31      0.16      0.21      2061\n",
      "   macro avg       0.31      0.16      0.21      2061\n",
      "weighted avg       0.31      0.16      0.21      2061\n",
      " samples avg       0.16      0.16      0.16      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, cnn_pred1))\n",
    "print('F1-score %s' % f1_score(y_test, cnn_pred1,average=None,zero_division = 0))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, cnn_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6268a8d",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eea569d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(200, )) \n",
    "x   =  Embedding(max_features, embedding_dim)(input)\n",
    "x   =  LSTM(200, return_sequences=True,name='lstm_layer')(x)\n",
    "x   =  GlobalMaxPool1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eecaee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_l = Model(inputs=input, outputs=x)\n",
    "model_l.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f45fd2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121/121 [==============================] - 33s 252ms/step - loss: 1.0988 - accuracy: 0.3553 - val_loss: 1.0972 - val_accuracy: 0.3680\n",
      "Epoch 2/3\n",
      "121/121 [==============================] - 29s 242ms/step - loss: 1.0819 - accuracy: 0.4011 - val_loss: 1.0699 - val_accuracy: 0.4137\n",
      "Epoch 3/3\n",
      "121/121 [==============================] - 32s 261ms/step - loss: 0.9766 - accuracy: 0.5220 - val_loss: 1.1468 - val_accuracy: 0.3971\n"
     ]
    }
   ],
   "source": [
    "lstm = model_l.fit(X_train, y_train, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f6ac8ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 6s 72ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = np.round(model_l.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "576a8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.23532265890344492\n",
      "F1-score [0.21041667 0.32517483 0.37253057]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.14      0.21       703\n",
      "           1       0.39      0.28      0.33       667\n",
      "           2       0.53      0.29      0.37       691\n",
      "\n",
      "   micro avg       0.44      0.24      0.31      2061\n",
      "   macro avg       0.44      0.24      0.30      2061\n",
      "weighted avg       0.44      0.24      0.30      2061\n",
      " samples avg       0.24      0.24      0.24      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, lstm_pred))\n",
    "print('F1-score %s' % f1_score(y_test, lstm_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0079ccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(200,))\n",
    "x = Embedding(max_features, embedding_dim)(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = Bidirectional(LSTM(200, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "# Add a classifier\n",
    "x = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ed12da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 113s 897ms/step - loss: 1.0988 - accuracy: 0.3499 - val_loss: 1.0960 - val_accuracy: 0.3680\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 123s 1s/step - loss: 1.0974 - accuracy: 0.3509 - val_loss: 1.1099 - val_accuracy: 0.3285\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 133s 1s/step - loss: 1.0484 - accuracy: 0.4458 - val_loss: 1.2402 - val_accuracy: 0.2609\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 130s 1s/step - loss: 0.9193 - accuracy: 0.5287 - val_loss: 1.3673 - val_accuracy: 0.2089\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 128s 1s/step - loss: 0.8158 - accuracy: 0.5781 - val_loss: 1.8167 - val_accuracy: 0.1923\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 127s 1s/step - loss: 0.7116 - accuracy: 0.6116 - val_loss: 2.2814 - val_accuracy: 0.1965\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 126s 1s/step - loss: 0.6179 - accuracy: 0.6421 - val_loss: 2.9776 - val_accuracy: 0.1892\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 128s 1s/step - loss: 0.5792 - accuracy: 0.6371 - val_loss: 3.4273 - val_accuracy: 0.1767\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 126s 1s/step - loss: 0.5471 - accuracy: 0.6608 - val_loss: 3.7042 - val_accuracy: 0.1819\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 123s 1s/step - loss: 0.5444 - accuracy: 0.6616 - val_loss: 3.9518 - val_accuracy: 0.1694\n"
     ]
    }
   ],
   "source": [
    "lstm = model.fit(X_train, y_train, epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c5dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 14s 200ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "156ae378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.13537117903930132\n",
      "F1-score [0.16995448 0.14529148 0.12656365]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.16      0.17       703\n",
      "           1       0.18      0.12      0.15       667\n",
      "           2       0.13      0.12      0.13       691\n",
      "\n",
      "   micro avg       0.16      0.14      0.15      2061\n",
      "   macro avg       0.16      0.14      0.15      2061\n",
      "weighted avg       0.16      0.14      0.15      2061\n",
      " samples avg       0.14      0.14      0.14      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, lstm_pred))\n",
    "print('F1-score %s' % f1_score(y_test, lstm_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d53027c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x18889ff8b80>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lstm.history['loss'], label='loss', marker = 'o')\n",
    "plt.plot(lstm.history['val_loss'], label = 'val_loss', marker = 'o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c71ba69",
   "metadata": {},
   "source": [
    "## Pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0519e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5ff769fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorize_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "599d115a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '[UNK]': 1,\n",
       " 'cheaper': 2,\n",
       " 'biology': 3,\n",
       " 'recruits': 4,\n",
       " 'warheads': 5,\n",
       " 'cooperation': 6,\n",
       " 'teacher': 7,\n",
       " 'defeating': 8,\n",
       " 'name': 9,\n",
       " 'skim': 10,\n",
       " 'caterwauling': 11,\n",
       " 'scary': 12,\n",
       " 'children': 13,\n",
       " 'forehead': 14,\n",
       " 'tasha': 15,\n",
       " 'showed': 16,\n",
       " 'weekly': 17,\n",
       " 'research': 18,\n",
       " 'gentleman': 19,\n",
       " 'ply': 20,\n",
       " 'idled': 21,\n",
       " 'custom': 22,\n",
       " 'rural': 23,\n",
       " 'hiring': 24,\n",
       " 'brighter': 25,\n",
       " 'unarmed': 26,\n",
       " 'essential': 27,\n",
       " 'share': 28,\n",
       " 'dragon': 29,\n",
       " 'karan': 30,\n",
       " 'reason': 31,\n",
       " 'incident': 32,\n",
       " 'fishing': 33,\n",
       " 'assumption': 34,\n",
       " 'campaigning': 35,\n",
       " 'thinned': 36,\n",
       " 'capital': 37,\n",
       " 'teti': 38,\n",
       " 'dunlap': 39,\n",
       " 'demonstrated': 40,\n",
       " 'brands': 41,\n",
       " 'music': 42,\n",
       " 'severely': 43,\n",
       " 'dealt': 44,\n",
       " 'raiser': 45,\n",
       " 'creativity': 46,\n",
       " 'large': 47,\n",
       " 'cincinnati': 48,\n",
       " 'models': 49,\n",
       " 'competitors': 50,\n",
       " 'use': 51,\n",
       " 'oldest': 52,\n",
       " 'impedance': 53,\n",
       " 'trust': 54,\n",
       " 'clearance': 55,\n",
       " 'stoned': 56,\n",
       " 'donates': 57,\n",
       " 'wealthiest': 58,\n",
       " 'owner': 59,\n",
       " 'bidden': 60,\n",
       " 'centered': 61,\n",
       " 'khas': 62,\n",
       " 'vast': 63,\n",
       " 'perceived': 64,\n",
       " 'shared': 65,\n",
       " 'hefty': 66,\n",
       " 'adaptations': 67,\n",
       " 'norther': 68,\n",
       " 'finish': 69,\n",
       " 'gas': 70,\n",
       " 'license': 71,\n",
       " 'appropriation': 72,\n",
       " 'lax': 73,\n",
       " 'farmer': 74,\n",
       " 'chimneys': 75,\n",
       " 'departed': 76,\n",
       " 'comprises': 77,\n",
       " 'kph': 78,\n",
       " 'invasions': 79,\n",
       " 'preceding': 80,\n",
       " 'upcoming': 81,\n",
       " 'bankers': 82,\n",
       " 'trimester': 83,\n",
       " 'chances': 84,\n",
       " 'liveliest': 85,\n",
       " 'haunted': 86,\n",
       " 'charities': 87,\n",
       " 'hated': 88,\n",
       " 'loaf': 89,\n",
       " 'portuguese': 90,\n",
       " 'drafted': 91,\n",
       " 'produces': 92,\n",
       " 'poppy': 93,\n",
       " 'cham': 94,\n",
       " 'couples': 95,\n",
       " 'reconnoitring': 96,\n",
       " 'nist': 97,\n",
       " 'outlets': 98,\n",
       " 'cop': 99,\n",
       " 'heavily': 100,\n",
       " 'troues': 101,\n",
       " 'cooling': 102,\n",
       " 'pujols': 103,\n",
       " 'accomplice': 104,\n",
       " 'harsher': 105,\n",
       " 'tancred': 106,\n",
       " 'wrapped': 107,\n",
       " 'direct': 108,\n",
       " 'disney': 109,\n",
       " 'ingredient': 110,\n",
       " 'created': 111,\n",
       " 'congressional': 112,\n",
       " 'scarce': 113,\n",
       " 'temple': 114,\n",
       " 'justifiably': 115,\n",
       " 'undergraduate': 116,\n",
       " 'imposed': 117,\n",
       " 'know': 118,\n",
       " 'specialist': 119,\n",
       " 'processed': 120,\n",
       " 'avenger': 121,\n",
       " 'conserve': 122,\n",
       " 'fix': 123,\n",
       " 'adds': 124,\n",
       " 'philosophy': 125,\n",
       " 'nhl': 126,\n",
       " 'journalism': 127,\n",
       " 'compensate': 128,\n",
       " 'creole': 129,\n",
       " 'incompressible': 130,\n",
       " 'loving': 131,\n",
       " 'surowiecki': 132,\n",
       " 'boating': 133,\n",
       " 'acquiring': 134,\n",
       " 'funny': 135,\n",
       " 'dirty': 136,\n",
       " 'designed': 137,\n",
       " 'lady': 138,\n",
       " 'q': 139,\n",
       " 'rare': 140,\n",
       " 'abilities': 141,\n",
       " 'unfair': 142,\n",
       " 'pragmatist': 143,\n",
       " 'flute': 144,\n",
       " 'bottles': 145,\n",
       " 'endorphins': 146,\n",
       " 'worked': 147,\n",
       " 'losses': 148,\n",
       " 'tommasini': 149,\n",
       " 'economies': 150,\n",
       " 'apply': 151,\n",
       " 'buy': 152,\n",
       " 'authorize': 153,\n",
       " 'need': 154,\n",
       " 'recommend': 155,\n",
       " 'chuch': 156,\n",
       " 'affords': 157,\n",
       " 'marry': 158,\n",
       " 'theorizing': 159,\n",
       " 'aggregate': 160,\n",
       " 'thankful': 161,\n",
       " 'films': 162,\n",
       " 'wildly': 163,\n",
       " 'julia': 164,\n",
       " 'adolescents': 165,\n",
       " 'gears': 166,\n",
       " 'diminished': 167,\n",
       " 'uniforms': 168,\n",
       " 'collection': 169,\n",
       " 'nicotine': 170,\n",
       " 'vaccine': 171,\n",
       " 'ceased': 172,\n",
       " 'invested': 173,\n",
       " 'hamilton': 174,\n",
       " 'chavez': 175,\n",
       " 'news': 176,\n",
       " 'atmospheres': 177,\n",
       " 'facets': 178,\n",
       " 'laundry': 179,\n",
       " 'nervous': 180,\n",
       " 'landscapes': 181,\n",
       " 'machine': 182,\n",
       " 'sold': 183,\n",
       " 'journeying': 184,\n",
       " 'parkland': 185,\n",
       " 'installations': 186,\n",
       " 'filling': 187,\n",
       " 'buddy': 188,\n",
       " 'wit': 189,\n",
       " 'corporation': 190,\n",
       " 'unsafe': 191,\n",
       " 'coops': 192,\n",
       " 'glamour': 193,\n",
       " 'joy': 194,\n",
       " 'unfairly': 195,\n",
       " 'killers': 196,\n",
       " 'portland': 197,\n",
       " 'throw': 198,\n",
       " 'plot': 199,\n",
       " 'characterized': 200,\n",
       " 'devoid': 201,\n",
       " 'lillian': 202,\n",
       " 'committed': 203,\n",
       " 'prices': 204,\n",
       " 'appropriate': 205,\n",
       " 'canadian': 206,\n",
       " 'grateful': 207,\n",
       " 'triumph': 208,\n",
       " 'scafeld': 209,\n",
       " 'generalizability': 210,\n",
       " 'pubs': 211,\n",
       " 'carnegie': 212,\n",
       " 'general': 213,\n",
       " 'reveled': 214,\n",
       " 'conscious': 215,\n",
       " 'rigid': 216,\n",
       " 'oilskin': 217,\n",
       " 'casuality': 218,\n",
       " 'cpi': 219,\n",
       " 'master': 220,\n",
       " 'purposes': 221,\n",
       " 'anonymous': 222,\n",
       " 'disastrous': 223,\n",
       " 'mortality': 224,\n",
       " 'cede': 225,\n",
       " 'rulemaking': 226,\n",
       " 'monte': 227,\n",
       " 'roman': 228,\n",
       " 'hat': 229,\n",
       " 'itbased': 230,\n",
       " 'central': 231,\n",
       " 'assad': 232,\n",
       " 'selecting': 233,\n",
       " 'e': 234,\n",
       " 'tower': 235,\n",
       " 'n': 236,\n",
       " 'decent': 237,\n",
       " 'reality': 238,\n",
       " 'gatehouse': 239,\n",
       " 'defendants': 240,\n",
       " 'fully': 241,\n",
       " 'intently': 242,\n",
       " 'content': 243,\n",
       " 'world': 244,\n",
       " 'excitement': 245,\n",
       " 'theater': 246,\n",
       " 'layman': 247,\n",
       " 'pursuing': 248,\n",
       " 'presented': 249,\n",
       " 'warned': 250,\n",
       " 'refuse': 251,\n",
       " 'vacationed': 252,\n",
       " 'river': 253,\n",
       " 'chase': 254,\n",
       " 'keep': 255,\n",
       " 'chairmanship': 256,\n",
       " 'analyst': 257,\n",
       " 'write': 258,\n",
       " 'billiards': 259,\n",
       " 'ironclad': 260,\n",
       " 'tables': 261,\n",
       " 'vehicle': 262,\n",
       " 'panacea': 263,\n",
       " 'primitive': 264,\n",
       " 'hosts': 265,\n",
       " 'stakeholders': 266,\n",
       " 'paperwork': 267,\n",
       " 'precise': 268,\n",
       " 'nope': 269,\n",
       " 'mobility': 270,\n",
       " 'pursuit': 271,\n",
       " 'd': 272,\n",
       " 'garlic': 273,\n",
       " 'swath': 274,\n",
       " 'irrelevant': 275,\n",
       " 'craze': 276,\n",
       " 'mysore': 277,\n",
       " 'hospice': 278,\n",
       " 'describes': 279,\n",
       " 'millions': 280,\n",
       " 'disapprove': 281,\n",
       " 'profits': 282,\n",
       " 'input': 283,\n",
       " 'rich': 284,\n",
       " 'jamus': 285,\n",
       " 'lakeland': 286,\n",
       " 'admired': 287,\n",
       " 'practice': 288,\n",
       " 'belief': 289,\n",
       " 'bank': 290,\n",
       " 'sweetly': 291,\n",
       " 'zoning': 292,\n",
       " 'mutahi': 293,\n",
       " 'arches': 294,\n",
       " 'invaded': 295,\n",
       " 'afternoon': 296,\n",
       " 'scenario': 297,\n",
       " 'reduction': 298,\n",
       " 'pointing': 299,\n",
       " 'ice': 300,\n",
       " 'qualities': 301,\n",
       " 'spoils': 302,\n",
       " 'production': 303,\n",
       " 'imaginative': 304,\n",
       " 'expendable': 305,\n",
       " 'supervise': 306,\n",
       " 'tim': 307,\n",
       " 'shake': 308,\n",
       " 'drive': 309,\n",
       " 'transaction': 310,\n",
       " 'exposed': 311,\n",
       " 'around': 312,\n",
       " 'hearing': 313,\n",
       " 'prospect': 314,\n",
       " 'consisting': 315,\n",
       " 'taxpayers': 316,\n",
       " 'rice': 317,\n",
       " 'race': 318,\n",
       " 'format': 319,\n",
       " 'investments': 320,\n",
       " 'emit': 321,\n",
       " 'tamils': 322,\n",
       " 'administrator': 323,\n",
       " 'sandstorm': 324,\n",
       " 'contend': 325,\n",
       " 'stage': 326,\n",
       " 'lil': 327,\n",
       " 'front': 328,\n",
       " 'banister': 329,\n",
       " 'sick': 330,\n",
       " 'undiminished': 331,\n",
       " 'though': 332,\n",
       " 'voluntary': 333,\n",
       " 'capitolina': 334,\n",
       " 'ineptitudes': 335,\n",
       " 'georgia': 336,\n",
       " 'boulevard': 337,\n",
       " 'handed': 338,\n",
       " 'tail': 339,\n",
       " 'exported': 340,\n",
       " 'available': 341,\n",
       " 'cattle': 342,\n",
       " 'loudly': 343,\n",
       " 'streams': 344,\n",
       " 'itemized': 345,\n",
       " 'directions': 346,\n",
       " 'aspects': 347,\n",
       " 'employs': 348,\n",
       " 'pots': 349,\n",
       " 'humid': 350,\n",
       " 'dog': 351,\n",
       " 'sufficiently': 352,\n",
       " 'blues': 353,\n",
       " 'bailey': 354,\n",
       " 'supposes': 355,\n",
       " 'excited': 356,\n",
       " 'palatable': 357,\n",
       " 'evenly': 358,\n",
       " 'territoriy': 359,\n",
       " 'emergence': 360,\n",
       " 'industry': 361,\n",
       " 'year': 362,\n",
       " 'refs': 363,\n",
       " 'meeting': 364,\n",
       " 'shocking': 365,\n",
       " 'privacy': 366,\n",
       " 'iraqis': 367,\n",
       " 'diana': 368,\n",
       " 'senate': 369,\n",
       " 'teleconferences': 370,\n",
       " 'employ': 371,\n",
       " 'into': 372,\n",
       " 'makes': 373,\n",
       " 'awhile': 374,\n",
       " 'prove': 375,\n",
       " 'report': 376,\n",
       " 'intoxication': 377,\n",
       " 'farms': 378,\n",
       " 'robin': 379,\n",
       " 'brookings': 380,\n",
       " 'wright': 381,\n",
       " 'resent': 382,\n",
       " 'geezers': 383,\n",
       " 'scrubbing': 384,\n",
       " 'snowstorm': 385,\n",
       " 'calculable': 386,\n",
       " 'center': 387,\n",
       " 'delights': 388,\n",
       " 'toxic': 389,\n",
       " 'bud': 390,\n",
       " 'winslet': 391,\n",
       " 'accomplishments': 392,\n",
       " 'dastardly': 393,\n",
       " 'reigninh': 394,\n",
       " 'circumstances': 395,\n",
       " 'sees': 396,\n",
       " 'assurance': 397,\n",
       " 'simply': 398,\n",
       " 'groupie': 399,\n",
       " 'quality': 400,\n",
       " 'emepor': 401,\n",
       " 'reexamined': 402,\n",
       " 'thrive': 403,\n",
       " 'mykonos': 404,\n",
       " 'appraiser': 405,\n",
       " 'sir': 406,\n",
       " 'livia': 407,\n",
       " 'pledged': 408,\n",
       " 'exhibitions': 409,\n",
       " 'nasser': 410,\n",
       " 'reviews': 411,\n",
       " 'sunlight': 412,\n",
       " 'taping': 413,\n",
       " 'nationally': 414,\n",
       " 'offices': 415,\n",
       " 'nick': 416,\n",
       " 'fatal': 417,\n",
       " 'rude': 418,\n",
       " 'lunch': 419,\n",
       " 'utilizing': 420,\n",
       " 'porn': 421,\n",
       " 'kind': 422,\n",
       " 'sack': 423,\n",
       " 'drab': 424,\n",
       " 'problem': 425,\n",
       " 'mom': 426,\n",
       " 'nipa': 427,\n",
       " 'artisan': 428,\n",
       " 'rally': 429,\n",
       " 'watch': 430,\n",
       " 'hay': 431,\n",
       " 'quicker': 432,\n",
       " 'promptly': 433,\n",
       " 'troubled': 434,\n",
       " 'cio': 435,\n",
       " 'clubs': 436,\n",
       " 'modestly': 437,\n",
       " 'kuala': 438,\n",
       " 'giuliani': 439,\n",
       " 'online': 440,\n",
       " 'nodded': 441,\n",
       " 'machines': 442,\n",
       " 'prevented': 443,\n",
       " 'millennium': 444,\n",
       " 'nemesis': 445,\n",
       " 'flying': 446,\n",
       " 'sunset': 447,\n",
       " 'locked': 448,\n",
       " 'pelee': 449,\n",
       " 'sources': 450,\n",
       " 'occupation': 451,\n",
       " 'ft': 452,\n",
       " 'tuesday': 453,\n",
       " 'morals': 454,\n",
       " 'guessed': 455,\n",
       " 'appraised': 456,\n",
       " 'poisoned': 457,\n",
       " 'inn': 458,\n",
       " 'doubles': 459,\n",
       " 'ferdinand': 460,\n",
       " 'instruction': 461,\n",
       " 'supposition': 462,\n",
       " 'clerking': 463,\n",
       " 'slavers': 464,\n",
       " 'currently': 465,\n",
       " 'predominantly': 466,\n",
       " 'kingsferry': 467,\n",
       " 'obtain': 468,\n",
       " 'monument': 469,\n",
       " 'consumers': 470,\n",
       " 'knocked': 471,\n",
       " 'beziers': 472,\n",
       " 'cruise': 473,\n",
       " 'moyenne': 474,\n",
       " 'baccarat': 475,\n",
       " 'microphone': 476,\n",
       " 'cameron': 477,\n",
       " 'referral': 478,\n",
       " 'gentlemen': 479,\n",
       " 'discernible': 480,\n",
       " 'yields': 481,\n",
       " 'photographed': 482,\n",
       " 'restored': 483,\n",
       " 'absurd': 484,\n",
       " 'minors': 485,\n",
       " 'resentment': 486,\n",
       " 'baryshnikov': 487,\n",
       " 'planners': 488,\n",
       " 'apologizing': 489,\n",
       " 'stole': 490,\n",
       " 'myrna': 491,\n",
       " 'nickel': 492,\n",
       " 'boomer': 493,\n",
       " 'laureate': 494,\n",
       " 'domed': 495,\n",
       " 'slept': 496,\n",
       " 'investigate': 497,\n",
       " 'dick': 498,\n",
       " 'wanting': 499,\n",
       " 'driving': 500,\n",
       " 'smoothly': 501,\n",
       " 'average': 502,\n",
       " 'diarrhoea': 503,\n",
       " 'kansas': 504,\n",
       " 'musty': 505,\n",
       " 'kinds': 506,\n",
       " 'extend': 507,\n",
       " 'pursued': 508,\n",
       " 'hikes': 509,\n",
       " 'messrs': 510,\n",
       " 'soft': 511,\n",
       " 'scanned': 512,\n",
       " 'swamps': 513,\n",
       " 'spend': 514,\n",
       " 'targeting': 515,\n",
       " 'vaults': 516,\n",
       " 'smiled': 517,\n",
       " 'democrat': 518,\n",
       " 'ahkenaten': 519,\n",
       " 'poor': 520,\n",
       " 'preaching': 521,\n",
       " 'hollow': 522,\n",
       " 'controversy': 523,\n",
       " 'buried': 524,\n",
       " 'easter': 525,\n",
       " 'bent': 526,\n",
       " 'treatment': 527,\n",
       " 'rat': 528,\n",
       " 'supreme': 529,\n",
       " 'webpage': 530,\n",
       " 'owned': 531,\n",
       " 'unrestricted': 532,\n",
       " 'encroachment': 533,\n",
       " 'pausing': 534,\n",
       " 'rosewater': 535,\n",
       " 'dislikes': 536,\n",
       " 'dancers': 537,\n",
       " 'dead': 538,\n",
       " 'cautioned': 539,\n",
       " 'relating': 540,\n",
       " 'mutual': 541,\n",
       " 'triple': 542,\n",
       " 'deplored': 543,\n",
       " 'ease': 544,\n",
       " 'ataterk': 545,\n",
       " 'viewed': 546,\n",
       " 'churches': 547,\n",
       " 'thanks': 548,\n",
       " 'bugs': 549,\n",
       " 'order': 550,\n",
       " 'inc': 551,\n",
       " 'strictest': 552,\n",
       " 'insurers': 553,\n",
       " 'unnecessary': 554,\n",
       " 'showcases': 555,\n",
       " 'liqueur': 556,\n",
       " 'simulation': 557,\n",
       " 'contributor': 558,\n",
       " 'npd': 559,\n",
       " 'funded': 560,\n",
       " 'english': 561,\n",
       " 'at': 562,\n",
       " 'benitez': 563,\n",
       " 'bluff': 564,\n",
       " 'functions': 565,\n",
       " 'doubled': 566,\n",
       " 'vs': 567,\n",
       " 'happens': 568,\n",
       " 'fcic': 569,\n",
       " 'gingerbread': 570,\n",
       " 'criminals': 571,\n",
       " 'cleavage': 572,\n",
       " 'unusually': 573,\n",
       " 'buffs': 574,\n",
       " 'settling': 575,\n",
       " 'acreage': 576,\n",
       " 'racing': 577,\n",
       " 'statistical': 578,\n",
       " 'mohamed': 579,\n",
       " 'stalked': 580,\n",
       " 'pro': 581,\n",
       " 'meant': 582,\n",
       " 'grotto': 583,\n",
       " 'england': 584,\n",
       " 'core': 585,\n",
       " 'purchased': 586,\n",
       " 'indoor': 587,\n",
       " 'restaurant': 588,\n",
       " 'books': 589,\n",
       " 'compromising': 590,\n",
       " 'paid': 591,\n",
       " 'dying': 592,\n",
       " 'dated': 593,\n",
       " 'quivering': 594,\n",
       " 'classical': 595,\n",
       " 'goodies': 596,\n",
       " 'tsim': 597,\n",
       " 'proximity': 598,\n",
       " 'hears': 599,\n",
       " 'outline': 600,\n",
       " 'presenter': 601,\n",
       " 'control': 602,\n",
       " 'resources': 603,\n",
       " 'chios': 604,\n",
       " 'srivijaya': 605,\n",
       " 'floodgates': 606,\n",
       " 'burning': 607,\n",
       " 'ideals': 608,\n",
       " 'approaches': 609,\n",
       " 'marble': 610,\n",
       " 'difficult': 611,\n",
       " 'terminus': 612,\n",
       " 'demonstrates': 613,\n",
       " 'cared': 614,\n",
       " 'unimpressive': 615,\n",
       " 'even': 616,\n",
       " 'furniture': 617,\n",
       " 'pronoun': 618,\n",
       " 'law': 619,\n",
       " 'peter': 620,\n",
       " 'blushed': 621,\n",
       " 'anthem': 622,\n",
       " 'update': 623,\n",
       " 'manage': 624,\n",
       " 'claustrophobic': 625,\n",
       " 'cliffs': 626,\n",
       " 'pedicabs': 627,\n",
       " 'practically': 628,\n",
       " 'prestige': 629,\n",
       " 'lincoln': 630,\n",
       " 'emulate': 631,\n",
       " 'injured': 632,\n",
       " 'agricultural': 633,\n",
       " 'caught': 634,\n",
       " 'winning': 635,\n",
       " 'warren': 636,\n",
       " 'arrive': 637,\n",
       " 'plus': 638,\n",
       " 'consents': 639,\n",
       " 'businessman': 640,\n",
       " 'suburb': 641,\n",
       " 'married': 642,\n",
       " 'compatible': 643,\n",
       " 'unfit': 644,\n",
       " 'hodgepodge': 645,\n",
       " 'radical': 646,\n",
       " 'hud': 647,\n",
       " 'cute': 648,\n",
       " 'gather': 649,\n",
       " 'injected': 650,\n",
       " 'fortified': 651,\n",
       " 'dave': 652,\n",
       " 'appraisers': 653,\n",
       " 'poll': 654,\n",
       " 'port': 655,\n",
       " 'jacques': 656,\n",
       " 'sectors': 657,\n",
       " 'apiece': 658,\n",
       " 'facilities': 659,\n",
       " 'voting': 660,\n",
       " 'knew': 661,\n",
       " 'hiking': 662,\n",
       " 'dine': 663,\n",
       " 'africa': 664,\n",
       " 'sailor': 665,\n",
       " 'plainclothes': 666,\n",
       " 'maintained': 667,\n",
       " 'cafe': 668,\n",
       " 'letting': 669,\n",
       " 'cultivate': 670,\n",
       " 'insecure': 671,\n",
       " 'poppies': 672,\n",
       " 'intimidated': 673,\n",
       " 'visible': 674,\n",
       " 'theodosius': 675,\n",
       " 'calls': 676,\n",
       " 'yachtsmen': 677,\n",
       " 'intelligence': 678,\n",
       " 'suicide': 679,\n",
       " 'sand': 680,\n",
       " 'xiaoping': 681,\n",
       " 'signals': 682,\n",
       " 'toxicants': 683,\n",
       " 'overlapping': 684,\n",
       " 'considerably': 685,\n",
       " 'ourselves': 686,\n",
       " 'drivers': 687,\n",
       " 'boskin': 688,\n",
       " 'highly': 689,\n",
       " 'accurate': 690,\n",
       " 'blessing': 691,\n",
       " 'visits': 692,\n",
       " 'translate': 693,\n",
       " 'obtaining': 694,\n",
       " 'bush': 695,\n",
       " 'cosmopolitan': 696,\n",
       " 'install': 697,\n",
       " 'underwent': 698,\n",
       " 'aware': 699,\n",
       " 'shocked': 700,\n",
       " 'breath': 701,\n",
       " 'dark': 702,\n",
       " 'chambers': 703,\n",
       " 'emission': 704,\n",
       " 'immorality': 705,\n",
       " 'ought': 706,\n",
       " 'chunk': 707,\n",
       " 'collectivized': 708,\n",
       " 'vodka': 709,\n",
       " 'calculations': 710,\n",
       " 'sleazy': 711,\n",
       " 'remote': 712,\n",
       " 'climax': 713,\n",
       " 'realistic': 714,\n",
       " 'gododdin': 715,\n",
       " 'barenakedino': 716,\n",
       " 'noh': 717,\n",
       " 'jail': 718,\n",
       " 'database': 719,\n",
       " 'pack': 720,\n",
       " 'chrysolite': 721,\n",
       " 'replacing': 722,\n",
       " 'anecdotal': 723,\n",
       " 'select': 724,\n",
       " 'mentioning': 725,\n",
       " 'castile': 726,\n",
       " 'remained': 727,\n",
       " 'confined': 728,\n",
       " 'daylight': 729,\n",
       " 'underestimate': 730,\n",
       " 'engendering': 731,\n",
       " 'contemporaries': 732,\n",
       " 'exploratory': 733,\n",
       " 'draw': 734,\n",
       " 'wave': 735,\n",
       " 'prophet': 736,\n",
       " 'skyrocket': 737,\n",
       " 'banks': 738,\n",
       " 'rata': 739,\n",
       " 'inland': 740,\n",
       " 'regions': 741,\n",
       " 'clients': 742,\n",
       " 'beheaded': 743,\n",
       " 'minor': 744,\n",
       " 'constitution': 745,\n",
       " 'tomato': 746,\n",
       " 'jets': 747,\n",
       " 'educated': 748,\n",
       " 'contraceptives': 749,\n",
       " 'referenced': 750,\n",
       " 'berman': 751,\n",
       " 'wide': 752,\n",
       " 'polluted': 753,\n",
       " 'typing': 754,\n",
       " 'tokugawa': 755,\n",
       " 'martello': 756,\n",
       " 'courses': 757,\n",
       " 'azure': 758,\n",
       " 'programmatic': 759,\n",
       " 'graceful': 760,\n",
       " 'nashville': 761,\n",
       " 'lane': 762,\n",
       " 'realizing': 763,\n",
       " 'volcanic': 764,\n",
       " 'lookalike': 765,\n",
       " 'regard': 766,\n",
       " 'enhanced': 767,\n",
       " 'venture': 768,\n",
       " 'chart': 769,\n",
       " 're': 770,\n",
       " 'evidently': 771,\n",
       " 'fathers': 772,\n",
       " 'fieri': 773,\n",
       " 'organisms': 774,\n",
       " 'confront': 775,\n",
       " 'hosted': 776,\n",
       " 'aging': 777,\n",
       " 'immediate': 778,\n",
       " 'scotland': 779,\n",
       " 'downfalls': 780,\n",
       " 'chateau': 781,\n",
       " 'sightseeing': 782,\n",
       " 'donor': 783,\n",
       " 'exam': 784,\n",
       " 'communicated': 785,\n",
       " 'extras': 786,\n",
       " 'media': 787,\n",
       " 'greenspan': 788,\n",
       " 'sales': 789,\n",
       " 'waimea': 790,\n",
       " 'picturesque': 791,\n",
       " 'answered': 792,\n",
       " 'compound': 793,\n",
       " 'offers': 794,\n",
       " 'advisory': 795,\n",
       " 'agency': 796,\n",
       " 'storm': 797,\n",
       " 'remember': 798,\n",
       " 'mari': 799,\n",
       " 'expelled': 800,\n",
       " 'safari': 801,\n",
       " 'were': 802,\n",
       " 'plays': 803,\n",
       " 'publicity': 804,\n",
       " 'administered': 805,\n",
       " 'significantly': 806,\n",
       " 'condition': 807,\n",
       " 'recent': 808,\n",
       " 'expected': 809,\n",
       " 'envisioned': 810,\n",
       " 'alterations': 811,\n",
       " 'contrasting': 812,\n",
       " 'couch': 813,\n",
       " 'stunt': 814,\n",
       " 'washington': 815,\n",
       " 'denominations': 816,\n",
       " 'compensated': 817,\n",
       " 'gathers': 818,\n",
       " 'proclaiming': 819,\n",
       " 'loggers': 820,\n",
       " 'images': 821,\n",
       " 'clarence': 822,\n",
       " 'scroll': 823,\n",
       " 'reluctant': 824,\n",
       " 'stephen': 825,\n",
       " 'lucrative': 826,\n",
       " 'anc': 827,\n",
       " 'o': 828,\n",
       " 'redeeming': 829,\n",
       " 'files': 830,\n",
       " 'associate': 831,\n",
       " 'participants': 832,\n",
       " 'unfortunately': 833,\n",
       " 'disclosure': 834,\n",
       " 'together': 835,\n",
       " 'documents': 836,\n",
       " 'iberian': 837,\n",
       " 'colorless': 838,\n",
       " 'troyes': 839,\n",
       " 'shockingly': 840,\n",
       " 'outcropping': 841,\n",
       " 'signal': 842,\n",
       " 'historical': 843,\n",
       " 'intellectual': 844,\n",
       " 'fetal': 845,\n",
       " 'voted': 846,\n",
       " 'fashion': 847,\n",
       " 'distressing': 848,\n",
       " 'gods': 849,\n",
       " 'gratitude': 850,\n",
       " 'other': 851,\n",
       " 'niche': 852,\n",
       " 'proposals': 853,\n",
       " 'thorn': 854,\n",
       " 'profile': 855,\n",
       " 'instance': 856,\n",
       " 'naturisme': 857,\n",
       " 'collar': 858,\n",
       " 'each': 859,\n",
       " 'jhora': 860,\n",
       " 'emerging': 861,\n",
       " 'unsure': 862,\n",
       " 'roller': 863,\n",
       " 'apologetic': 864,\n",
       " 'productivity': 865,\n",
       " 'makers': 866,\n",
       " 'aluminum': 867,\n",
       " 'download': 868,\n",
       " 'clammy': 869,\n",
       " 'riviyre': 870,\n",
       " 'charnock': 871,\n",
       " 'doing': 872,\n",
       " 'interview': 873,\n",
       " 'president': 874,\n",
       " 'outlet': 875,\n",
       " 'evidence': 876,\n",
       " 'collect': 877,\n",
       " 'lister': 878,\n",
       " 'detriment': 879,\n",
       " 'boasts': 880,\n",
       " 'three': 881,\n",
       " 'refugees': 882,\n",
       " 'doj': 883,\n",
       " 'lighthouse': 884,\n",
       " 'solvency': 885,\n",
       " 'fires': 886,\n",
       " 'curve': 887,\n",
       " 'duration': 888,\n",
       " 'vase': 889,\n",
       " 'communion': 890,\n",
       " 'realization': 891,\n",
       " 'cloister': 892,\n",
       " 'hawaiian': 893,\n",
       " 'comparability': 894,\n",
       " 'rates': 895,\n",
       " 'indulging': 896,\n",
       " 'midterm': 897,\n",
       " 'sleek': 898,\n",
       " 'fasted': 899,\n",
       " 'rose': 900,\n",
       " 'widened': 901,\n",
       " 'holistic': 902,\n",
       " 'television': 903,\n",
       " 'robert': 904,\n",
       " 'thank': 905,\n",
       " 'dunfermline': 906,\n",
       " 'opposition': 907,\n",
       " 'spreading': 908,\n",
       " 'decatur': 909,\n",
       " 'hips': 910,\n",
       " 'widely': 911,\n",
       " 'crops': 912,\n",
       " 'places': 913,\n",
       " 'cave': 914,\n",
       " 'anthology': 915,\n",
       " 'execute': 916,\n",
       " 'guesstimates': 917,\n",
       " 'scolds': 918,\n",
       " 'glimpse': 919,\n",
       " 'manual': 920,\n",
       " 'kilos': 921,\n",
       " 'consistent': 922,\n",
       " 'presenting': 923,\n",
       " 'pulitzer': 924,\n",
       " 'toilet': 925,\n",
       " 'eisner': 926,\n",
       " 'palma': 927,\n",
       " 'roadblock': 928,\n",
       " 'wwi': 929,\n",
       " 'aromatic': 930,\n",
       " 'bhuleshwar': 931,\n",
       " 'edging': 932,\n",
       " 'pirate': 933,\n",
       " 'hastings': 934,\n",
       " 'higher': 935,\n",
       " 'stunned': 936,\n",
       " 'affectionately': 937,\n",
       " 'sparse': 938,\n",
       " 'relevant': 939,\n",
       " 'taken': 940,\n",
       " 'gap': 941,\n",
       " 'leal': 942,\n",
       " 'establishing': 943,\n",
       " 'connection': 944,\n",
       " 'embarrassment': 945,\n",
       " 'landfill': 946,\n",
       " 'light': 947,\n",
       " 'wordsmithing': 948,\n",
       " 'enough': 949,\n",
       " 'gagas': 950,\n",
       " 'msn': 951,\n",
       " 'intensely': 952,\n",
       " 'silver': 953,\n",
       " 'undefeated': 954,\n",
       " 'flexibility': 955,\n",
       " 'substantive': 956,\n",
       " 'freezes': 957,\n",
       " 'exploded': 958,\n",
       " 'varieties': 959,\n",
       " 'predictable': 960,\n",
       " 'gold': 961,\n",
       " 'produce': 962,\n",
       " 'armed': 963,\n",
       " 'awarded': 964,\n",
       " 'nineteen': 965,\n",
       " 'reagent': 966,\n",
       " 'theaters': 967,\n",
       " 'abolished': 968,\n",
       " 'muck': 969,\n",
       " 'crimean': 970,\n",
       " 'sparkling': 971,\n",
       " 'agenda': 972,\n",
       " 'centers': 973,\n",
       " 'fgd': 974,\n",
       " 'focused': 975,\n",
       " 'bartlett': 976,\n",
       " 'gate': 977,\n",
       " 'surgery': 978,\n",
       " 'escape': 979,\n",
       " 'wolves': 980,\n",
       " 'glyph': 981,\n",
       " 'bitter': 982,\n",
       " 'literature': 983,\n",
       " 'aswan': 984,\n",
       " 'colonize': 985,\n",
       " 'north': 986,\n",
       " 'devotion': 987,\n",
       " 'breezily': 988,\n",
       " 'sharks': 989,\n",
       " 'sandstone': 990,\n",
       " 'replicate': 991,\n",
       " 'j': 992,\n",
       " 'choose': 993,\n",
       " 'turmoil': 994,\n",
       " 'desegregation': 995,\n",
       " 'rapier': 996,\n",
       " 'woman': 997,\n",
       " 'visitors': 998,\n",
       " 'corroborate': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52fd7d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('glove.6B.200d.txt', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5039a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 10611 words (256 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 200\n",
    "hits = 0\n",
    "misses = 0\n",
    "words_not_found = []\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        words_not_found.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "020651eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'troues',\n",
       " 'scafeld',\n",
       " 'casuality',\n",
       " 'itbased',\n",
       " 'ineptitudes',\n",
       " 'territoriy',\n",
       " 'reigninh',\n",
       " 'emepor',\n",
       " 'kingsferry',\n",
       " 'ahkenaten',\n",
       " 'ataterk',\n",
       " 'barenakedino',\n",
       " 'chrysolite',\n",
       " 'naturisme',\n",
       " 'jhora',\n",
       " 'riviyre',\n",
       " 'bhuleshwar',\n",
       " 'wordsmithing',\n",
       " 'gagas',\n",
       " 'capgains',\n",
       " 'hosue',\n",
       " 'iversons',\n",
       " 'harvelle',\n",
       " 'worksharing',\n",
       " 'nonproselytizing',\n",
       " 'inmotion',\n",
       " 'perestrelo',\n",
       " 'asssess',\n",
       " 'gaoas',\n",
       " 'mandrakes',\n",
       " 'restoorant',\n",
       " 'discothyques',\n",
       " 'vedr',\n",
       " 'disaffecting',\n",
       " 'federalinformationsystemcontrolsauditmanualis',\n",
       " 'montmarte',\n",
       " 'salesladies',\n",
       " 'inglethorp',\n",
       " 'unprepssessing',\n",
       " 'onardo',\n",
       " 'felicities',\n",
       " 'showbizzy',\n",
       " 'burnsian',\n",
       " 'ledfords',\n",
       " 'financerelated',\n",
       " 'andratx',\n",
       " 'katachi',\n",
       " 'bauerstein',\n",
       " 'cpis',\n",
       " 'hillend',\n",
       " 'citypalace',\n",
       " 'bsing',\n",
       " 'ptolomies',\n",
       " 'bernakedino',\n",
       " 'castanheiro',\n",
       " 'scafelf',\n",
       " 'mortifyingly',\n",
       " 'preambles',\n",
       " 'sabelhaus',\n",
       " 'disjointedly',\n",
       " 'czarek',\n",
       " 'nileometer',\n",
       " 'rulemakings',\n",
       " 'samothrakia',\n",
       " 'theimpressive',\n",
       " 'monumentalprotection',\n",
       " 'availalbe',\n",
       " 'zelon',\n",
       " 'syvres',\n",
       " 'zefat',\n",
       " 'workshared',\n",
       " 'motionlessly',\n",
       " 'patlecan',\n",
       " 'souveineers',\n",
       " 'tauted',\n",
       " 'diffferently',\n",
       " 'tengh',\n",
       " 'encumeada',\n",
       " 'sefat',\n",
       " 'lingett',\n",
       " 'bannisters',\n",
       " 'brittish',\n",
       " 'smegal',\n",
       " 'marlenheim',\n",
       " 'espetada',\n",
       " 'sarayy',\n",
       " 'crosethe',\n",
       " 'espalmador',\n",
       " 'bicurei',\n",
       " 'camees',\n",
       " 'clienteligible',\n",
       " 'loyala',\n",
       " 'ofcurrent',\n",
       " 'ofrequired',\n",
       " 'menidia',\n",
       " 'herdwick',\n",
       " 'suppy',\n",
       " 'unibasket',\n",
       " 'nonautomated',\n",
       " 'tehy',\n",
       " 'vreanna',\n",
       " 'pmsd',\n",
       " 'rajabai',\n",
       " 'everynow',\n",
       " 'erlenborn',\n",
       " 'neccesary',\n",
       " 'cityhall',\n",
       " 'clintonas',\n",
       " 'tragea',\n",
       " 'javis',\n",
       " 'krewski',\n",
       " 'overmechanical',\n",
       " 'wealthies',\n",
       " 'computerrelated',\n",
       " 'madeirans',\n",
       " 'fasulye',\n",
       " 'barogue',\n",
       " 'mailstream',\n",
       " 'dubbawya',\n",
       " 'palmaria',\n",
       " 'curros',\n",
       " 'interlaboratory',\n",
       " 'ownable',\n",
       " 'thedegree',\n",
       " 'caleornia',\n",
       " 'dictatorially',\n",
       " 'bedesten',\n",
       " 'vandemeyer',\n",
       " 'tadminster',\n",
       " 'fwi',\n",
       " 'complicatedly',\n",
       " 'eupalinos',\n",
       " 'mccalpinmaria',\n",
       " 'proserous',\n",
       " 'postaward',\n",
       " 'thirasia',\n",
       " 'alonissos',\n",
       " 'freiras',\n",
       " 'czesiek',\n",
       " 'supinely',\n",
       " 'incase',\n",
       " 'threestep',\n",
       " 'punditus',\n",
       " 'apalrc',\n",
       " 'lusadas',\n",
       " 'stramongate',\n",
       " 'archeabacteria',\n",
       " 'lasnny',\n",
       " 'gambolling',\n",
       " 'nonexchange',\n",
       " 'nasire',\n",
       " 'tarare',\n",
       " 'gauve',\n",
       " 'madrile',\n",
       " 'returnus',\n",
       " 'mysidopsis',\n",
       " 'campings',\n",
       " 'differant',\n",
       " 'kulesi',\n",
       " 'knowledgebased',\n",
       " 'ceter',\n",
       " 'defeaat',\n",
       " 'microhockey',\n",
       " 'massabielle',\n",
       " 'strees',\n",
       " 'heftman',\n",
       " 'postpayment',\n",
       " 'counterevidence',\n",
       " 'ceteau',\n",
       " 'whitebelly',\n",
       " 'atat',\n",
       " 'unpompous',\n",
       " 'gofundme',\n",
       " 'missenhardt',\n",
       " 'wagonheim',\n",
       " 'heand',\n",
       " 'kizartmas',\n",
       " 'mailstreams',\n",
       " 'caletta',\n",
       " 'probononet',\n",
       " 'nepdg',\n",
       " 'Ï…rt',\n",
       " 'levadas',\n",
       " 'wonking',\n",
       " 'valueable',\n",
       " 'brodkeys',\n",
       " 'reestimate',\n",
       " 'morethan',\n",
       " 'bhansi',\n",
       " 'atechnical',\n",
       " 'ssaturday',\n",
       " 'mutahir',\n",
       " 'cathedrale',\n",
       " 'hamzy',\n",
       " 'fengari',\n",
       " 'beryllina',\n",
       " 'tetanic',\n",
       " 'riph',\n",
       " 'groupof',\n",
       " 'resultsoriented',\n",
       " 'barnam',\n",
       " 'reppublica',\n",
       " 'busineses',\n",
       " 'pices',\n",
       " 'panzar',\n",
       " 'disintermediating',\n",
       " 'afterthefact',\n",
       " 'castlerigg',\n",
       " 'diso',\n",
       " 'worldaid',\n",
       " 'mytilini',\n",
       " 'ofiice',\n",
       " 'pippens',\n",
       " 'presidentas',\n",
       " 'corstophine',\n",
       " 'croseover',\n",
       " 'keleter',\n",
       " 'overstayer',\n",
       " 'lalley',\n",
       " 'louisian',\n",
       " 'vezir',\n",
       " 'egus',\n",
       " 'huaisheng',\n",
       " 'battistoni',\n",
       " 'hersheimmer',\n",
       " 'suggesetions',\n",
       " 'kelase',\n",
       " 'adrin',\n",
       " 'adversisers',\n",
       " 'rique',\n",
       " 'smelledof',\n",
       " 'deitiesinegyptianmythologyandthis',\n",
       " 'nontransportation',\n",
       " 'bridgeopening',\n",
       " 'idpa',\n",
       " 'meydane',\n",
       " 'melodio',\n",
       " 'workshare',\n",
       " 'nkow',\n",
       " 'preservationalists',\n",
       " 'recultivate',\n",
       " 'uncopied',\n",
       " 'redhanded',\n",
       " 'crotoy',\n",
       " 'kutchins',\n",
       " 'melroseabbey',\n",
       " 'eliat',\n",
       " 'conspiracism',\n",
       " 'fiveyear',\n",
       " 'furniure',\n",
       " 'acondition',\n",
       " 'pollentia',\n",
       " 'alsacien',\n",
       " 'cityart']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7c11fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    #trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f66b79f",
   "metadata": {},
   "source": [
    "### cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "61a94039",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sequences_input = keras.Input(shape=(200,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x = layers.Conv1D(128, 3, activation=\"relu\")(embedded_sequences)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling1D()(x)\n",
    "x = layers.Conv1D(128, 3, activation=\"relu\")(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model1 = Model(inputs=int_sequences_input, outputs=x)\n",
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7469ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 9s 69ms/step - loss: 1.1081 - accuracy: 0.3504 - val_loss: 1.1000 - val_accuracy: 0.3597\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 8s 67ms/step - loss: 1.0600 - accuracy: 0.4406 - val_loss: 1.0830 - val_accuracy: 0.3888\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 8s 68ms/step - loss: 0.9484 - accuracy: 0.5586 - val_loss: 1.1096 - val_accuracy: 0.4064\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 8s 68ms/step - loss: 0.7171 - accuracy: 0.6974 - val_loss: 1.2747 - val_accuracy: 0.3514\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 8s 68ms/step - loss: 0.4452 - accuracy: 0.8316 - val_loss: 1.6545 - val_accuracy: 0.3534\n"
     ]
    }
   ],
   "source": [
    "cnn = model1.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "30841440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_pred = np.round(model1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e781969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.3245997088791849\n",
      "F1-score [0.2893401  0.38365651 0.36802664]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.24      0.29       703\n",
      "           1       0.36      0.42      0.38       667\n",
      "           2       0.43      0.32      0.37       691\n",
      "\n",
      "   micro avg       0.38      0.32      0.35      2061\n",
      "   macro avg       0.38      0.33      0.35      2061\n",
      "weighted avg       0.38      0.32      0.35      2061\n",
      " samples avg       0.32      0.32      0.32      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, cnn_pred))\n",
    "print('F1-score %s' % f1_score(y_test, cnn_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7661e8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(200,), dtype=\"int64\") \n",
    "x   =  embedding_layer(input)\n",
    "#x   =  Dropout(0.2)(x)\n",
    "x   =  Conv1D(100, 3, padding='valid',activation='relu', strides=1)(x)\n",
    "x   =  GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=input, outputs=x)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5905dc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 7s 51ms/step - loss: 1.1211 - accuracy: 0.3379 - val_loss: 1.1012 - val_accuracy: 0.3649\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 1.0676 - accuracy: 0.4229 - val_loss: 1.1070 - val_accuracy: 0.3493\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 6s 50ms/step - loss: 0.9807 - accuracy: 0.5259 - val_loss: 1.2045 - val_accuracy: 0.3233\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.8145 - accuracy: 0.6392 - val_loss: 1.4019 - val_accuracy: 0.3035\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 6s 49ms/step - loss: 0.6145 - accuracy: 0.7512 - val_loss: 1.6440 - val_accuracy: 0.3004\n"
     ]
    }
   ],
   "source": [
    "cnn = model.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4ef2be96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "cnn_pred = np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8c529a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.23726346433770015\n",
      "F1-score [0.20141343 0.22857143 0.33381503]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.16      0.20       703\n",
      "           1       0.24      0.22      0.23       667\n",
      "           2       0.33      0.33      0.33       691\n",
      "\n",
      "   micro avg       0.29      0.24      0.26      2061\n",
      "   macro avg       0.28      0.24      0.25      2061\n",
      "weighted avg       0.28      0.24      0.25      2061\n",
      " samples avg       0.24      0.24      0.24      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, cnn_pred))\n",
    "print('F1-score %s' % f1_score(y_test, cnn_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, cnn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf30d7",
   "metadata": {},
   "source": [
    "### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e707bfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "121/121 [==============================] - 24s 183ms/step - loss: 1.0789 - accuracy: 0.4008 - val_loss: 1.0737 - val_accuracy: 0.4179\n",
      "Epoch 2/3\n",
      "121/121 [==============================] - 22s 180ms/step - loss: 0.8924 - accuracy: 0.5958 - val_loss: 1.1739 - val_accuracy: 0.3836\n",
      "Epoch 3/3\n",
      "121/121 [==============================] - 22s 179ms/step - loss: 0.6359 - accuracy: 0.7450 - val_loss: 1.4714 - val_accuracy: 0.3462\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(200,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x   =  LSTM(100, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x   =  GlobalMaxPool1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "lstm_model = Model(inputs=int_sequences_input, outputs=x)\n",
    "lstm_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "lstm = lstm_model.fit(X_train, y_train, epochs=3,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "61528a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 3s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = np.round(lstm_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44e2647f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.2547307132459971\n",
      "F1-score [0.11084337 0.20204082 0.45238095]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.07      0.11       703\n",
      "           1       0.32      0.15      0.20       667\n",
      "           2       0.38      0.55      0.45       691\n",
      "\n",
      "   micro avg       0.37      0.25      0.30      2061\n",
      "   macro avg       0.35      0.25      0.26      2061\n",
      "weighted avg       0.35      0.25      0.25      2061\n",
      " samples avg       0.25      0.25      0.25      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, lstm_pred))\n",
    "print('F1-score %s' % f1_score(y_test, lstm_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b49021bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(200,))\n",
    "x = embedding_layer(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = Bidirectional(LSTM(200, return_sequences=True))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "# Add a classifier\n",
    "x = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model2 = keras.Model(inputs, outputs=x)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "83acf08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 263s 2s/step - loss: 0.9254 - accuracy: 0.5292 - val_loss: 1.7437 - val_accuracy: 0.2048\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 250s 2s/step - loss: 0.7356 - accuracy: 0.6187 - val_loss: 1.9202 - val_accuracy: 0.1746\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 279s 2s/step - loss: 0.6226 - accuracy: 0.6473 - val_loss: 2.7513 - val_accuracy: 0.1809\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 285s 2s/step - loss: 0.5849 - accuracy: 0.6535 - val_loss: 3.1468 - val_accuracy: 0.1892\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 237s 2s/step - loss: 0.5667 - accuracy: 0.6623 - val_loss: 3.5272 - val_accuracy: 0.1902\n"
     ]
    }
   ],
   "source": [
    "lstm = model2.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2e9a9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 19s 272ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = np.round(model2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5dfb9188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.1348859776807375\n",
      "F1-score [0.20416966 0.14343272 0.08584475]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.20      0.20       703\n",
      "           1       0.16      0.13      0.14       667\n",
      "           2       0.12      0.07      0.09       691\n",
      "\n",
      "   micro avg       0.17      0.13      0.15      2061\n",
      "   macro avg       0.16      0.13      0.14      2061\n",
      "weighted avg       0.16      0.13      0.14      2061\n",
      " samples avg       0.13      0.13      0.13      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, pred))\n",
    "print('F1-score %s' % f1_score(y_test, pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fdd1fdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d332b35b80>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lstm.history['loss'], label='loss', marker = 'o')\n",
    "plt.plot(lstm.history['val_loss'], label = 'val_loss', marker = 'o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf1d77c",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e47bde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now sequence must be 300 to fit with fastText\n",
    "max_features = len(text1)+2\n",
    "sequence_length = 150\n",
    "\n",
    "\n",
    "def custom_slpit(input_data):\n",
    "    return tf.strings.split(input_data)\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    vocabulary = text1,\n",
    "    output_mode=\"int\",\n",
    "    ngrams = None,\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "#commented because we passed a vocabulary\n",
    "#vectorize_layer.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238897e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p = vectorize_layer(x_train_p)\n",
    "X_test_p = vectorize_layer(x_test_p)\n",
    "X_train_h = vectorize_layer(x_train_h)\n",
    "X_test_h = vectorize_layer(x_test_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fe80220",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack((X_train_p,X_train_h))\n",
    "X_test = np.hstack((X_test_p,X_test_h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c304d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4809, 300)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3ba31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert y to OHE \n",
    "y_train = to_categorical(y_train, 3)\n",
    "y_test  = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "167c8ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip -q crawl-300d-2M.vec.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2c4ada1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1999996 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('crawl-300d-2M.vec', encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4d4cf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorize_layer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2368842f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 10517 words (350 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 300\n",
    "hits = 0\n",
    "misses = 0\n",
    "words_not_found = []\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        words_not_found.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8d27a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'camees',\n",
       " 'nepdg',\n",
       " 'thirasia',\n",
       " 'lusadas',\n",
       " 'dinard',\n",
       " 'monumentalprotection',\n",
       " 'castanheiro',\n",
       " 'ptolemies',\n",
       " 'rosenblatt',\n",
       " 'tarpley',\n",
       " 'keizo',\n",
       " 'selimiye',\n",
       " 'recultivate',\n",
       " 'kulesi',\n",
       " 'richelieu',\n",
       " 'larut',\n",
       " 'adrin',\n",
       " 'pmsd',\n",
       " 'bossi',\n",
       " 'jhora',\n",
       " 'freiras',\n",
       " 'morant',\n",
       " 'workshared',\n",
       " 'dunnes',\n",
       " 'hcfa',\n",
       " 'crotoy',\n",
       " 'marlenheim',\n",
       " 'tsim',\n",
       " 'burnsian',\n",
       " 'afterthefact',\n",
       " 'huguenots',\n",
       " 'michiko',\n",
       " 'smegal',\n",
       " 'nahariya',\n",
       " 'palestrina',\n",
       " 'ptolomies',\n",
       " 'corstorphine',\n",
       " 'madeirans',\n",
       " 'jamus',\n",
       " 'tramuntana',\n",
       " 'frankenheimer',\n",
       " 'dubbawya',\n",
       " 'fwi',\n",
       " 'krewski',\n",
       " 'meriwether',\n",
       " 'esquivel',\n",
       " 'loyala',\n",
       " 'langmuir',\n",
       " 'tarare',\n",
       " 'crose',\n",
       " 'czesiek',\n",
       " 'bicurei',\n",
       " 'wanniski',\n",
       " 'nonproselytizing',\n",
       " 'wachter',\n",
       " 'tadminster',\n",
       " 'missenhardt',\n",
       " 'aila',\n",
       " 'mailstreams',\n",
       " 'reigninh',\n",
       " 'shuger',\n",
       " 'vrenna',\n",
       " 'federalinformationsystemcontrolsauditmanualis',\n",
       " 'lambros',\n",
       " 'formentor',\n",
       " 'eisner',\n",
       " 'ssaturday',\n",
       " 'zmuda',\n",
       " 'trianon',\n",
       " 'chowpatty',\n",
       " 'patlecan',\n",
       " 'ofrequired',\n",
       " 'ahkenaten',\n",
       " 'pippens',\n",
       " 'hsia',\n",
       " 'nonautomated',\n",
       " 'kutchins',\n",
       " 'mysidopsis',\n",
       " 'defeaat',\n",
       " 'samothrakia',\n",
       " 'harvelle',\n",
       " 'parameswara',\n",
       " 'ujong',\n",
       " 'borsig',\n",
       " 'naturisme',\n",
       " 'bedesten',\n",
       " 'chagnon',\n",
       " 'fengari',\n",
       " 'bhuleshwar',\n",
       " 'bettelheim',\n",
       " 'lumbini',\n",
       " 'srivijaya',\n",
       " 'aurangzeb',\n",
       " 'aicpa',\n",
       " 'curros',\n",
       " 'melroseabbey',\n",
       " 'stramongate',\n",
       " 'emepor',\n",
       " 'harrer',\n",
       " 'sabelhaus',\n",
       " 'iversons',\n",
       " 'bonapartists',\n",
       " 'baryshnikov',\n",
       " 'exley',\n",
       " 'haussmann',\n",
       " 'brodkeys',\n",
       " 'perestrelo',\n",
       " 'kotter',\n",
       " 'reestimate',\n",
       " 'tzfat',\n",
       " 'louisian',\n",
       " 'pyrgos',\n",
       " 'kalinga',\n",
       " 'vezir',\n",
       " 'madrile',\n",
       " 'usepa',\n",
       " 'haveman',\n",
       " 'msba',\n",
       " 'zefat',\n",
       " 'blois',\n",
       " 'landsburg',\n",
       " 'javis',\n",
       " 'ataterk',\n",
       " 'berbera',\n",
       " 'boskin',\n",
       " 'keleter',\n",
       " 'mccalpinmaria',\n",
       " 'meydane',\n",
       " 'dejima',\n",
       " 'apalrc',\n",
       " 'bernakedino',\n",
       " 'unpompous',\n",
       " 'huaisheng',\n",
       " 'worldaid',\n",
       " 'nasire',\n",
       " 'resultsoriented',\n",
       " 'smelledof',\n",
       " 'mutahir',\n",
       " 'theimpressive',\n",
       " 'ledfords',\n",
       " 'encumeada',\n",
       " 'carmo',\n",
       " 'kizartmas',\n",
       " 'panzar',\n",
       " 'mutahi',\n",
       " 'battistoni',\n",
       " 'restoorant',\n",
       " 'yanomamo',\n",
       " 'girgis',\n",
       " 'manzanares',\n",
       " 'croseover',\n",
       " 'furniure',\n",
       " 'manacor',\n",
       " 'blencathra',\n",
       " 'barogue',\n",
       " 'kakutani',\n",
       " 'nezu',\n",
       " 'tancred',\n",
       " 'bendahara',\n",
       " 'andratx',\n",
       " 'russert',\n",
       " 'tegh',\n",
       " 'bridgeopening',\n",
       " 'citypalace',\n",
       " 'voth',\n",
       " 'pfitzner',\n",
       " 'tengh',\n",
       " 'ombo',\n",
       " 'iolani',\n",
       " 'kentridge',\n",
       " 'cpis',\n",
       " 'unprepssessing',\n",
       " 'maintenon',\n",
       " 'flodden',\n",
       " 'gauve',\n",
       " 'tragea',\n",
       " 'lasnny',\n",
       " 'pitre',\n",
       " 'minoans',\n",
       " 'montluc',\n",
       " 'kelase',\n",
       " 'filipa',\n",
       " 'osmin',\n",
       " 'eupalinos',\n",
       " 'corstophine',\n",
       " 'caleornia',\n",
       " 'hillend',\n",
       " 'sefat',\n",
       " 'heftman',\n",
       " 'samothrace',\n",
       " 'presidentas',\n",
       " 'czarek',\n",
       " 'itbased',\n",
       " 'geveden',\n",
       " 'wenner',\n",
       " 'mayar',\n",
       " 'balearics',\n",
       " 'postaward',\n",
       " 'eliat',\n",
       " 'cucci',\n",
       " 'obuchi',\n",
       " 'barnam',\n",
       " 'capgains',\n",
       " 'weicker',\n",
       " 'gpra',\n",
       " 'pedder',\n",
       " 'unibasket',\n",
       " 'probononet',\n",
       " 'returnus',\n",
       " 'scafelf',\n",
       " 'geffen',\n",
       " 'suggesetions',\n",
       " 'xiaoping',\n",
       " 'stephanopoulos',\n",
       " 'brahmanic',\n",
       " 'miramax',\n",
       " 'clienteligible',\n",
       " 'nonexchange',\n",
       " 'ceteau',\n",
       " 'preservationalists',\n",
       " 'montmarte',\n",
       " 'zelon',\n",
       " 'curnin',\n",
       " 'nabatean',\n",
       " 'fasulye',\n",
       " 'archeabacteria',\n",
       " 'blankley',\n",
       " 'nefertari',\n",
       " 'menidia',\n",
       " 'lesvos',\n",
       " 'erlenborn',\n",
       " 'yagoda',\n",
       " 'asssess',\n",
       " 'akko',\n",
       " 'lalley',\n",
       " 'mytilini',\n",
       " 'onardo',\n",
       " 'cowgate',\n",
       " 'gododdin',\n",
       " 'masr',\n",
       " 'fhwa',\n",
       " 'discothyques',\n",
       " 'herrnstein',\n",
       " 'crosethe',\n",
       " 'cityart',\n",
       " 'inglethorp',\n",
       " 'ibizan',\n",
       " 'troues',\n",
       " 'allenby',\n",
       " 'cpas',\n",
       " 'wagonheim',\n",
       " 'alonissos',\n",
       " 'wealthies',\n",
       " 'merrion',\n",
       " 'borker',\n",
       " 'vreanna',\n",
       " 'souveineers',\n",
       " 'greuze',\n",
       " 'massabielle',\n",
       " 'hersheimmer',\n",
       " 'knowledgebased',\n",
       " 'aelia',\n",
       " 'microhockey',\n",
       " 'hurriya',\n",
       " 'cyprinodon',\n",
       " 'surowiecki',\n",
       " 'tonelson',\n",
       " 'vandemeyer',\n",
       " 'croteau',\n",
       " 'lvov',\n",
       " 'scafeld',\n",
       " 'ovitz',\n",
       " 'dionysos',\n",
       " 'disaffecting',\n",
       " 'gaoas',\n",
       " 'bhansi',\n",
       " 'queensferry',\n",
       " 'castlerigg',\n",
       " 'sarayy',\n",
       " 'computerrelated',\n",
       " 'pollentia',\n",
       " 'cocomo',\n",
       " 'financerelated',\n",
       " 'egus',\n",
       " 'diffferently',\n",
       " 'threestep',\n",
       " 'curral',\n",
       " 'beryllina',\n",
       " 'Ï…rt',\n",
       " 'rajabai',\n",
       " 'palmaria',\n",
       " 'overmechanical',\n",
       " 'punditus',\n",
       " 'savonarola',\n",
       " 'proserous',\n",
       " 'liggett',\n",
       " 'adversisers',\n",
       " 'deitiesinegyptianmythologyandthis',\n",
       " 'territoriy',\n",
       " 'barenakedino',\n",
       " 'beaubourg',\n",
       " 'nontransportation',\n",
       " 'suharto',\n",
       " 'raskolnikov',\n",
       " 'clintonas',\n",
       " 'vedr',\n",
       " 'mulhouse',\n",
       " 'nileometer',\n",
       " 'lydians',\n",
       " 'reppublica',\n",
       " 'caletta',\n",
       " 'norquist',\n",
       " 'capitolina',\n",
       " 'philipsburg',\n",
       " 'yemenite',\n",
       " 'akrotiri',\n",
       " 'mauryas',\n",
       " 'adbul',\n",
       " 'melodio',\n",
       " 'riviyre',\n",
       " 'rijksmuseum',\n",
       " 'trenchtown',\n",
       " 'mrinal',\n",
       " 'tuileries',\n",
       " 'kinneret',\n",
       " 'bauerstein',\n",
       " 'hamzy',\n",
       " 'greyfriars',\n",
       " 'syvres',\n",
       " 'francesc',\n",
       " 'lingett',\n",
       " 'theban',\n",
       " 'theodosius',\n",
       " 'espalmador',\n",
       " 'ptolemaic',\n",
       " 'kleiman',\n",
       " 'royko',\n",
       " 'hoysala',\n",
       " 'fcic',\n",
       " 'ramseys',\n",
       " 'pelee',\n",
       " 'rehnquist',\n",
       " 'riph',\n",
       " 'whitebelly',\n",
       " 'charnock',\n",
       " 'tsfat',\n",
       " 'esna',\n",
       " 'kingsferry']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0db4802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebbbc3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 6s 47ms/step - loss: 1.1328 - accuracy: 0.3179 - val_loss: 1.1307 - val_accuracy: 0.3264\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 6s 46ms/step - loss: 0.9554 - accuracy: 0.5841 - val_loss: 1.1599 - val_accuracy: 0.3181\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 6s 46ms/step - loss: 0.8416 - accuracy: 0.6639 - val_loss: 1.2242 - val_accuracy: 0.3274\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 6s 47ms/step - loss: 0.7345 - accuracy: 0.7315 - val_loss: 1.2920 - val_accuracy: 0.3150\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 6s 46ms/step - loss: 0.6164 - accuracy: 0.8082 - val_loss: 1.3226 - val_accuracy: 0.3160\n"
     ]
    }
   ],
   "source": [
    "input = keras.Input(shape=(embedding_dim,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(input)\n",
    "x = Conv1D(128, 3, activation=\"relu\")(embedded_sequences)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "#x = Conv1D(128, 3, activation=\"relu\")(x)\n",
    "#x = GlobalMaxPooling1D()(x)\n",
    "#x = Conv1D(128, 3, activation=\"relu\")(x)\n",
    "#x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "m = Model(inputs=input, outputs=x)\n",
    "m.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "c = m.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a863c66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "pr = np.round(m.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26536ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.16642406598738477\n",
      "F1-score [0.20754717 0.11848825 0.28178694]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.17      0.21       703\n",
      "           1       0.19      0.09      0.12       667\n",
      "           2       0.35      0.24      0.28       691\n",
      "\n",
      "   micro avg       0.27      0.17      0.21      2061\n",
      "   macro avg       0.26      0.17      0.20      2061\n",
      "weighted avg       0.27      0.17      0.20      2061\n",
      " samples avg       0.56      0.17      0.17      2061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, pr))\n",
    "print('F1-score %s' % f1_score(y_test, pr, average=None, zero_division = 1))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,pr,zero_division = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6406f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 6s 45ms/step - loss: 1.1126 - accuracy: 0.3345 - val_loss: 1.0984 - val_accuracy: 0.3586\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 5s 40ms/step - loss: 1.0946 - accuracy: 0.3694 - val_loss: 1.1002 - val_accuracy: 0.3150\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 5s 40ms/step - loss: 1.0550 - accuracy: 0.4297 - val_loss: 1.1283 - val_accuracy: 0.3264\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 5s 39ms/step - loss: 0.9868 - accuracy: 0.5173 - val_loss: 1.1606 - val_accuracy: 0.3306\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 5s 39ms/step - loss: 0.8662 - accuracy: 0.6054 - val_loss: 1.2906 - val_accuracy: 0.3420\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(embedding_dim,), dtype=\"int64\") \n",
    "x   =  embedding_layer(input)\n",
    "#x   =  Dropout(0.2)(x)\n",
    "x   =  Conv1D(100, 3, padding='valid',activation='relu', strides=1)(x)\n",
    "x   =  GlobalMaxPooling1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(32, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "m1 = Model(inputs=input, outputs=x)\n",
    "m1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "c1 = m1.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db6fd393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 1s 12ms/step\n"
     ]
    }
   ],
   "source": [
    "pr1 = np.round(m1.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36fb8ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.18680252304706454\n",
      "F1-score [0.25671141 0.2503962  0.17370892]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.22      0.26       703\n",
      "           1       0.27      0.24      0.25       667\n",
      "           2       0.46      0.11      0.17       691\n",
      "\n",
      "   micro avg       0.31      0.19      0.23      2061\n",
      "   macro avg       0.35      0.19      0.23      2061\n",
      "weighted avg       0.35      0.19      0.23      2061\n",
      " samples avg       0.58      0.19      0.19      2061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, pr1))\n",
    "print('F1-score %s' % f1_score(y_test, pr1, average=None, zero_division = 1))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,pr1,zero_division = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8162be9f",
   "metadata": {},
   "source": [
    "### lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2531c715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "121/121 [==============================] - 26s 200ms/step - loss: 1.1014 - accuracy: 0.3400 - val_loss: 1.0944 - val_accuracy: 0.3680\n",
      "Epoch 2/5\n",
      "121/121 [==============================] - 22s 184ms/step - loss: 1.0798 - accuracy: 0.4006 - val_loss: 1.0708 - val_accuracy: 0.4116\n",
      "Epoch 3/5\n",
      "121/121 [==============================] - 23s 186ms/step - loss: 1.0283 - accuracy: 0.4858 - val_loss: 1.0593 - val_accuracy: 0.4220\n",
      "Epoch 4/5\n",
      "121/121 [==============================] - 22s 186ms/step - loss: 0.9709 - accuracy: 0.5334 - val_loss: 1.0518 - val_accuracy: 0.4356\n",
      "Epoch 5/5\n",
      "121/121 [==============================] - 23s 189ms/step - loss: 0.8810 - accuracy: 0.6036 - val_loss: 1.1224 - val_accuracy: 0.4137\n"
     ]
    }
   ],
   "source": [
    "int_sequences_input = keras.Input(shape=(embedding_dim,), dtype=\"int64\")\n",
    "embedded_sequences = embedding_layer(int_sequences_input)\n",
    "x   =  LSTM(100, return_sequences=True,name='lstm_layer')(embedded_sequences)\n",
    "x   =  GlobalMaxPool1D()(x)\n",
    "x   =  Dense(64, activation=\"relu\")(x)\n",
    "x   =  Dropout(0.2)(x)\n",
    "x   =  Dense(3, activation=\"softmax\")(x)\n",
    "lstm_model = Model(inputs=int_sequences_input, outputs=x)\n",
    "lstm_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "lstm = lstm_model.fit(X_train, y_train, epochs=5,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec652453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 5s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_pred = np.round(lstm_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05580519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.21057738961669092\n",
      "F1-score [0.22042467 0.07088608 0.45343511]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.16      0.22       703\n",
      "           1       0.23      0.04      0.07       667\n",
      "           2       0.48      0.43      0.45       691\n",
      "\n",
      "   micro avg       0.42      0.21      0.28      2061\n",
      "   macro avg       0.36      0.21      0.25      2061\n",
      "weighted avg       0.36      0.21      0.25      2061\n",
      " samples avg       0.21      0.21      0.21      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, lstm_pred))\n",
    "print('F1-score %s' % f1_score(y_test, lstm_pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test, lstm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11e05596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "121/121 [==============================] - 105s 812ms/step - loss: 1.1016 - accuracy: 0.3387 - val_loss: 1.0982 - val_accuracy: 0.3680\n",
      "Epoch 2/10\n",
      "121/121 [==============================] - 82s 678ms/step - loss: 1.0983 - accuracy: 0.3408 - val_loss: 1.0996 - val_accuracy: 0.3649\n",
      "Epoch 3/10\n",
      "121/121 [==============================] - 81s 674ms/step - loss: 1.0956 - accuracy: 0.3585 - val_loss: 1.1022 - val_accuracy: 0.3628\n",
      "Epoch 4/10\n",
      "121/121 [==============================] - 92s 763ms/step - loss: 1.0889 - accuracy: 0.3811 - val_loss: 1.1215 - val_accuracy: 0.3191\n",
      "Epoch 5/10\n",
      "121/121 [==============================] - 88s 727ms/step - loss: 1.0791 - accuracy: 0.4047 - val_loss: 1.1282 - val_accuracy: 0.2703\n",
      "Epoch 6/10\n",
      "121/121 [==============================] - 86s 712ms/step - loss: 1.0638 - accuracy: 0.4203 - val_loss: 1.1572 - val_accuracy: 0.2723\n",
      "Epoch 7/10\n",
      "121/121 [==============================] - 90s 740ms/step - loss: 1.0342 - accuracy: 0.4474 - val_loss: 1.1996 - val_accuracy: 0.2474\n",
      "Epoch 8/10\n",
      "121/121 [==============================] - 86s 712ms/step - loss: 1.0102 - accuracy: 0.4596 - val_loss: 1.2468 - val_accuracy: 0.2464\n",
      "Epoch 9/10\n",
      "121/121 [==============================] - 86s 709ms/step - loss: 0.9705 - accuracy: 0.5019 - val_loss: 1.3573 - val_accuracy: 0.2256\n",
      "Epoch 10/10\n",
      "121/121 [==============================] - 84s 697ms/step - loss: 0.9279 - accuracy: 0.5191 - val_loss: 1.4505 - val_accuracy: 0.2328\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(embedding_dim,))\n",
    "# Embed each integer in a 128-dimensional vector\n",
    "x = embedding_layer(inputs)\n",
    "# Add 2 bidirectional LSTMs\n",
    "x = Bidirectional(LSTM(100, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(64))(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "# Add a classifier\n",
    "x = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model2 = keras.Model(inputs, outputs=x)\n",
    "model2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "lstm2 = model2.fit(X_train, y_train, epochs=10,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b9c2dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 14s 189ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = np.round(model2.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2de13ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.07423580786026202\n",
      "F1-score [0.16727941 0.0944206  0.042007  ]\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.13      0.17       703\n",
      "           1       0.17      0.07      0.09       667\n",
      "           2       0.11      0.03      0.04       691\n",
      "\n",
      "   micro avg       0.19      0.07      0.11      2061\n",
      "   macro avg       0.17      0.07      0.10      2061\n",
      "weighted avg       0.17      0.07      0.10      2061\n",
      " samples avg       0.07      0.07      0.07      2061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eleon\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy %s' % accuracy_score(y_test, pred))\n",
    "print('F1-score %s' % f1_score(y_test, pred, average=None))\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ff856f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26a6dcbb100>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lstm2.history['loss'], label='loss', marker = 'o')\n",
    "plt.plot(lstm2.history['val_loss'], label = 'val_loss', marker = 'o')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f36e200",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
